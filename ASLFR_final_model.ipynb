{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook trains the final model of my solution\n",
        "\n",
        "><p><a href=\"https://colab.research.google.com/github/shlomoron/Google---American-Sign-Language-Fingerspelling-Recognition-12th-place-solution/blob/main/ASLFR_final_model.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>"
      ],
      "metadata": {
        "id": "eheBJR-WHqPd"
      },
      "id": "eheBJR-WHqPd"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "5e16il68WboC"
      },
      "id": "5e16il68WboC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "def set_seeds(seed=SEED):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "set_seeds()"
      ],
      "metadata": {
        "id": "qUzrgUNFWj9K"
      },
      "id": "qUzrgUNFWj9K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "\n",
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "!pip install cached-property\n",
        "from cached_property import cached_property\n",
        "\n",
        "!pip install fastparquet\n",
        "import fastparquet\n",
        "\n",
        "!pip install Levenshtein\n",
        "import Levenshtein as lev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jA5kStlXBah",
        "outputId": "019d4a89-6441-4c0b-a60a-691e2956e68e"
      },
      "id": "1jA5kStlXBah",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2023.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (1.23.5)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.7.0 fastparquet-2023.7.0\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data paths and imports\n",
        "[ctc_tpu](https://www.kaggle.com/datasets/shlomoron/ctc-tpu) contains an implementation of CTC for TensorFlow.  \n",
        "[aslfr_light](https://www.kaggle.com/datasets/shlomoron/aslfr-light) contains two needed files from the much larger [competition dataset](https://www.kaggle.com/competitions/asl-fingerspelling/data).  \n",
        "The [TFRecord dataset](https://www.kaggle.com/datasets/shlomoron/aslfr-tfrecords) contains the training data as TFRecords and is imported straight to the TPU.\n"
      ],
      "metadata": {
        "id": "NBn8hGJyIZ4m"
      },
      "id": "NBn8hGJyIZ4m"
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder='/content/input'\n",
        "working_folder='/content'\n",
        "\n",
        "try:\n",
        "  os.mkdir(input_folder)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "ctc_tpu_path = 'gs://kds-56377fe3e755931e5dec0abf56fc91724117fbe7bab3e27b74e37f3e'\n",
        "!gsutil -m cp -r  $ctc_tpu_path $input_folder/ctc-tpu\n",
        "\n",
        "aslfr_light_folder_name = 'asl-fingerspelling'\n",
        "try:\n",
        "  os.mkdir(os.path.join(input_folder, aslfr_light_folder_name))\n",
        "except:\n",
        "  pass\n",
        "\n",
        "aslfr_light_bucket = 'kds-0edb6d00755af6434e157bf0f17ca3102a6722fdba4325c7c11b0e8c'\n",
        "aslfr_light_path = f'gs://{aslfr_light_bucket}'\n",
        "!gsutil -m cp -r $aslfr_light_path $input_folder/asl-fingerspelling\n",
        "shutil.copytree(f'{input_folder}/{aslfr_light_folder_name}/{aslfr_light_bucket}',\n",
        "                f'{input_folder}/{aslfr_light_folder_name}', dirs_exist_ok=True)\n",
        "\n",
        "tfrecords_path = 'gs://kds-4104ecb783277dae764d8a7e543344b63bd14d4a90cc61b85b9c2307'\n",
        "\n",
        "aslfr_MEANs_STDs_folder_name = 'aslfr_MEANs_STDs'\n",
        "try:\n",
        "  os.mkdir(os.path.join(input_folder, aslfr_MEANs_STDs_folder_name))\n",
        "except:\n",
        "  pass\n",
        "aslfr_MEANs_STDs_bucket = 'kds-6aa19d9b7a0929191862354c0121926a98e0c2a5828fe9d275ca75d3'\n",
        "aslfr_MEANs_STDs_path = f'gs://{aslfr_MEANs_STDs_bucket}'\n",
        "!gsutil -m cp -r $aslfr_MEANs_STDs_path $input_folder/aslfr_MEANs_STDs\n",
        "shutil.copytree(f'{input_folder}/{aslfr_MEANs_STDs_folder_name}/{aslfr_MEANs_STDs_bucket}',\n",
        "                f'{input_folder}/{aslfr_MEANs_STDs_folder_name}', dirs_exist_ok=True)\n",
        "\n",
        "base_model_Levs_as_TFRecords_path = 'gs://kds-551195264551b6e3f80b0534289a47e2c7bac4b71f6d2109e3314e08'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmX4frJLHrwM",
        "outputId": "115fa639-0f85-4cfb-8a88-d70a5dcc0475"
      },
      "id": "tmX4frJLHrwM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://kds-56377fe3e755931e5dec0abf56fc91724117fbe7bab3e27b74e37f3e/CTC_TPU.py...\n",
            "/ [0/1 files][    0.0 B/ 56.1 KiB]   0% Done                                    \r/ [1/1 files][ 56.1 KiB/ 56.1 KiB] 100% Done                                    \r\n",
            "Operation completed over 1 objects/56.1 KiB.                                     \n",
            "Copying gs://kds-0edb6d00755af6434e157bf0f17ca3102a6722fdba4325c7c11b0e8c/character_to_prediction_index.json...\n",
            "Copying gs://kds-0edb6d00755af6434e157bf0f17ca3102a6722fdba4325c7c11b0e8c/train.csv...\n",
            "- [2/2 files][  5.0 MiB/  5.0 MiB] 100% Done                                    \n",
            "Operation completed over 2 objects/5.0 MiB.                                      \n",
            "Copying gs://kds-6aa19d9b7a0929191862354c0121926a98e0c2a5828fe9d275ca75d3/MEANs.p...\n",
            "Copying gs://kds-6aa19d9b7a0929191862354c0121926a98e0c2a5828fe9d275ca75d3/STDs.p...\n",
            "/ [2/2 files][  5.1 KiB/  5.1 KiB] 100% Done                                    \n",
            "Operation completed over 2 objects/5.1 KiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define where the output is saved\n",
        "\n",
        "It is best to save Colab output to a mounted Google drive, but giving public notebook access to your drive can be risky, so the default here is saving to the local disk of the colab session. If you have familiarized yourself with the code here and feel at ease with granting such access, you can unmark the second part in this cell and define the appropriate path to a folder in your drive (the folder that you create a path to should exist already- in this example, content/drive/MyDrive/kaggle/ASLFR already exist on my drive)"
      ],
      "metadata": {
        "id": "-WEnYx871lDY"
      },
      "id": "-WEnYx871lDY"
    },
    {
      "cell_type": "code",
      "source": [
        "save_folder = '/content/save'\n",
        "try:\n",
        "  os.mkdir(save_folder)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_folder_name = 'final_model'\n",
        "ASLFR_folder = '/content/drive/MyDrive/kaggle/ASLFR'\n",
        "save_folder = os.path.join(ASLFR_folder, save_folder_name)\n",
        "try:\n",
        "  os.mkdir(save_folder)\n",
        "except:\n",
        "  pass\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se27jvKI1kjB",
        "outputId": "a8da641e-b792-436e-d2ea-a053b0d28f3e"
      },
      "id": "Se27jvKI1kjB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the ctc loss function"
      ],
      "metadata": {
        "id": "4N6D4BhvKpvE"
      },
      "id": "4N6D4BhvKpvE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ee8ad9a"
      },
      "outputs": [],
      "source": [
        "# copy our file into the working directory (make sure it has .py suffix)\n",
        "copyfile(src = f\"{input_folder}/ctc-tpu/CTC_TPU.py\", dst = f\"{working_folder}//CTC_TPU.py\")\n",
        "\n",
        "# import all our functions\n",
        "from CTC_TPU import classic_ctc_loss"
      ],
      "id": "7ee8ad9a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TPU boilerplate code"
      ],
      "metadata": {
        "id": "PmjWoS83K69m"
      },
      "id": "PmjWoS83K69m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ac1c922",
        "outputId": "5abc02e2-0bfb-4c34-cbd7-fe41b9aa63f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on TPU\n",
            "REPLICAS:  8\n",
            "<tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 object at 0x796073d19f00>\n"
          ]
        }
      ],
      "source": [
        "# Configure Strategy. Assume TPU...if not set default for GPU\n",
        "tpu = None\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=None)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"on TPU\")\n",
        "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(strategy)"
      ],
      "id": "0ac1c922"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Landmarks indices"
      ],
      "metadata": {
        "id": "IxHa678pLbgw"
      },
      "id": "IxHa678pLbgw"
    },
    {
      "cell_type": "code",
      "source": [
        "NOSE_old=[\n",
        "    1,2,98,327\n",
        "]\n",
        "LNOSE_old = [98]\n",
        "RNOSE_old = [327]\n",
        "LIP_old = [ 0,\n",
        "    61, 185, 40, 39, 37, 267, 269, 270, 409,\n",
        "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
        "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
        "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
        "]\n",
        "LLIP_old = [84,181,91,146,61,185,40,39,37,87,178,88,95,78,191,80,81,82]\n",
        "RLIP_old = [314,405,321,375,291,409,270,269,267,317,402,318,324,308,415,310,311,312]\n",
        "\n",
        "FACE_old = LIP_old+NOSE_old\n",
        "FACE_old.sort()\n",
        "\n",
        "LPOSE_old = [11, 13, 15, 17, 19, 21, 23]\n",
        "RPOSE_old = [12, 14, 16, 18, 20, 22, 24]\n",
        "POSE_old = LPOSE_old + RPOSE_old\n",
        "\n",
        "X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_face_{i}' for i in FACE_old] + [f'x_pose_{i}' for i in POSE_old]\n",
        "Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_face_{i}' for i in FACE_old] + [f'y_pose_{i}' for i in POSE_old]\n",
        "\n",
        "SEL_COLS = X + Y\n",
        "\n",
        "print('SEL_COLS size:' + str(len(SEL_COLS)))\n",
        "\n",
        "SEL_COLS_x = [x for x in SEL_COLS if 'x' in x]\n",
        "NOSE = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and int(x.split('_')[-1]) in NOSE_old]\n",
        "LNOSE = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and int(x.split('_')[-1]) in LNOSE_old]\n",
        "RNOSE = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and int(x.split('_')[-1]) in RNOSE_old]\n",
        "LIP = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and int(x.split('_')[-1]) in LIP_old]\n",
        "LLIP = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and int(x.split('_')[-1]) in LLIP_old]\n",
        "RLIP = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and int(x.split('_')[-1]) in RLIP_old]\n",
        "FACE = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and int(x.split('_')[-1]) in FACE_old]\n",
        "\n",
        "LPOSE = [i for i, x in enumerate(SEL_COLS_x) if 'pose' in x and int(x.split('_')[-1]) in LPOSE_old]\n",
        "RPOSE = [i for i, x in enumerate(SEL_COLS_x) if 'pose' in x and int(x.split('_')[-1]) in RPOSE_old]\n",
        "POSE = [i for i, x in enumerate(SEL_COLS_x) if 'pose' in x and int(x.split('_')[-1]) in POSE_old]\n",
        "\n",
        "LHAND = [i for i, x in enumerate(SEL_COLS_x) if 'left_hand' in x]\n",
        "RHAND = [i for i, x in enumerate(SEL_COLS_x) if 'right_hand' in x]\n",
        "\n",
        "POINT_LANDMARKS = FACE+RHAND+LHAND+RPOSE+LPOSE\n",
        "\n",
        "norm_point = [i for i, x in enumerate(SEL_COLS_x) if 'face' in x and x.split('_')[-1] == '17'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FulpKI6Lat2",
        "outputId": "7b738e39-1915-4f50-9118-ab231691b4b7"
      },
      "id": "4FulpKI6Lat2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEL_COLS size:200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config and stuff"
      ],
      "metadata": {
        "id": "O-CPgz1mMwt2"
      },
      "id": "O-CPgz1mMwt2"
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "\n",
        "ROWS_PER_FRAME = int(len(SEL_COLS)/2)\n",
        "PAD = 0.\n",
        "NUM_NODES = len(POINT_LANDMARKS)\n",
        "CHANNELS = 6*NUM_NODES\n",
        "print(\"Number of landmarks: \" + str(NUM_NODES))\n",
        "print(\"Number of features: \" + str(CHANNELS))\n",
        "pad_token = 'P'\n",
        "pad_token_idx = 59\n",
        "\n",
        "\n",
        "with open (f\"{input_folder}/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    char_to_num = json.load(f)\n",
        "\n",
        "char_to_num[pad_token] = pad_token_idx\n",
        "num_to_char = {j:i for i,j in char_to_num.items()}\n",
        "\n",
        "inpdir = f\"{input_folder}/asl-fingerspelling\"\n",
        "df = pd.read_csv(f'{inpdir}/train.csv')\n",
        "\n",
        "tffiles = df.file_id.map(lambda x: f'{tfrecords_path}/tfds/{x}.tfrecord').unique()\n",
        "tffiles_levs = df.file_id.map(lambda x: f'{base_model_Levs_as_TFRecords_path}/tfds/{x}.tfrecord').unique()\n",
        "\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=list(char_to_num.keys()),\n",
        "        values=list(char_to_num.values()),\n",
        "    ),\n",
        "    default_value=tf.constant(-1),\n",
        "    name=\"class_weight\"\n",
        ")\n",
        "\n",
        "MAX_LEN = 340\n",
        "batch_size = 64*4\n",
        "dim = 384\n",
        "val_len = int(0.05 * len(tffiles))\n",
        "cache = True\n",
        "SHUFFLE = -1\n",
        "\n",
        "if DEBUG:\n",
        "  MAX_LEN = 64\n",
        "  batch_size = 16\n",
        "  dim=48\n",
        "  val_len = 1\n",
        "  cache = False\n",
        "  SHUFFLE = 50\n",
        "\n",
        "print(\"Val len: \" + str(val_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh6aK2BTMYvu",
        "outputId": "7c80825f-1bf7-45e8-915d-6dff5105ddf2"
      },
      "id": "Jh6aK2BTMYvu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of landmarks: 100\n",
            "Number of features: 600\n",
            "Val len: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentations functions"
      ],
      "metadata": {
        "id": "mTdjlI5lNU9u"
      },
      "id": "mTdjlI5lNU9u"
    },
    {
      "cell_type": "code",
      "source": [
        "def interp1d_(x, target_len, method='random'):\n",
        "    length = tf.shape(x)[1]\n",
        "    target_len = tf.maximum(1,target_len)\n",
        "    if method == 'random':\n",
        "        if tf.random.uniform(()) < 0.33:\n",
        "            x = tf.image.resize(x, (target_len,tf.shape(x)[1]),'bilinear')\n",
        "        else:\n",
        "            if tf.random.uniform(()) < 0.5:\n",
        "                x = tf.image.resize(x, (target_len,tf.shape(x)[1]),'bicubic')\n",
        "            else:\n",
        "                x = tf.image.resize(x, (target_len,tf.shape(x)[1]),'nearest')\n",
        "    else:\n",
        "        x = tf.image.resize(x, (target_len,tf.shape(x)[1]),method)\n",
        "    return x\n",
        "\n",
        "def flip_lr(x):\n",
        "    x,y,z = tf.unstack(x, axis=-1)\n",
        "    x = 1-x\n",
        "    new_x = tf.stack([x,y,z], -1)\n",
        "    new_x = tf.transpose(new_x, [1,0,2])\n",
        "    lhand = tf.gather(new_x, LHAND, axis=0)\n",
        "    rhand = tf.gather(new_x, RHAND, axis=0)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LHAND)[...,None], rhand)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RHAND)[...,None], lhand)\n",
        "    llip = tf.gather(new_x, LLIP, axis=0)\n",
        "    rlip = tf.gather(new_x, RLIP, axis=0)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LLIP)[...,None], rlip)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RLIP)[...,None], llip)\n",
        "    lpose = tf.gather(new_x, LPOSE, axis=0)\n",
        "    rpose = tf.gather(new_x, RPOSE, axis=0)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LPOSE)[...,None], rpose)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RPOSE)[...,None], lpose)\n",
        "    lnose = tf.gather(new_x, LNOSE, axis=0)\n",
        "    rnose = tf.gather(new_x, RNOSE, axis=0)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(LNOSE)[...,None], rnose)\n",
        "    new_x = tf.tensor_scatter_nd_update(new_x, tf.constant(RNOSE)[...,None], lnose)\n",
        "    new_x = tf.transpose(new_x, [1,0,2])\n",
        "    return new_x\n",
        "\n",
        "def resample(x, rate=(0.8,1.2)):\n",
        "    rate = tf.random.uniform((), rate[0], rate[1])\n",
        "    length = tf.shape(x)[0]\n",
        "    new_size = tf.cast(rate*tf.cast(length,tf.float32), tf.int32)\n",
        "    new_x = interp1d_(x, new_size)\n",
        "    return new_x\n",
        "\n",
        "def spatial_random_affine(xyz,\n",
        "    scale  = (0.8,1.2),\n",
        "    shear = (-0.15,0.15),\n",
        "    shift  = (-0.1,0.1),\n",
        "    degree = (-30,30),\n",
        "):\n",
        "    center = tf.constant([0.5,0.5])\n",
        "    if scale is not None:\n",
        "        scale = tf.random.uniform((),*scale)\n",
        "        xyz = scale*xyz\n",
        "\n",
        "    if shear is not None:\n",
        "        xy = xyz[...,:2]\n",
        "        z = xyz[...,2:]\n",
        "        shear_x = shear_y = tf.random.uniform((),*shear)\n",
        "        if tf.random.uniform(()) < 0.5:\n",
        "            shear_x = 0.\n",
        "        else:\n",
        "            shear_y = 0.\n",
        "        shear_mat = tf.identity([\n",
        "            [1.,shear_x],\n",
        "            [shear_y,1.]\n",
        "        ])\n",
        "        xy = xy @ shear_mat\n",
        "        center = center + [shear_y, shear_x]\n",
        "        xyz = tf.concat([xy,z], axis=-1)\n",
        "\n",
        "    if degree is not None:\n",
        "        xy = xyz[...,:2]\n",
        "        z = xyz[...,2:]\n",
        "        xy -= center\n",
        "        degree = tf.random.uniform((),*degree)\n",
        "        radian = degree/180*np.pi\n",
        "        c = tf.math.cos(radian)\n",
        "        s = tf.math.sin(radian)\n",
        "        rotate_mat = tf.identity([\n",
        "            [c,s],\n",
        "            [-s, c],\n",
        "        ])\n",
        "        xy = xy @ rotate_mat\n",
        "        xy = xy + center\n",
        "        xyz = tf.concat([xy,z], axis=-1)\n",
        "\n",
        "    if shift is not None:\n",
        "        shift = tf.random.uniform((),*shift)\n",
        "        xyz = xyz + shift\n",
        "\n",
        "    return xyz\n",
        "\n",
        "def temporal_mask(x, size=(0.2,0.4), mask_value=float('nan')):\n",
        "    l = tf.shape(x)[0]\n",
        "    mask_size = tf.random.uniform((), *size)\n",
        "    mask_size = tf.cast(tf.cast(l, tf.float32) * mask_size, tf.int32)\n",
        "    mask_offset = tf.random.uniform((), 0, l, dtype=tf.int32)\n",
        "    mask_start = mask_offset\n",
        "    mask_end = tf.clip_by_value(mask_offset+mask_size,0,l)\n",
        "    x = tf.tensor_scatter_nd_update(x,tf.range(mask_start, mask_end)[...,None],tf.fill([mask_end - mask_start,ROWS_PER_FRAME,3],mask_value))\n",
        "    if mask_offset+mask_size>l:\n",
        "      mask_start = 0\n",
        "      mask_end = mask_offset+mask_size - l\n",
        "      x = tf.tensor_scatter_nd_update(x,tf.range(mask_start, mask_end)[...,None],tf.fill([mask_end - mask_start,ROWS_PER_FRAME,3],mask_value))\n",
        "    return x\n",
        "\n",
        "def spatial_mask(x, size=(0.2,0.4), mask_value=float('nan')):\n",
        "    mask_size_x = tf.random.uniform((), *size)\n",
        "    mask_size_y = tf.random.uniform((), *size)\n",
        "    mask_offset_x = tf.random.uniform(())\n",
        "    mask_offset_y = tf.random.uniform(())\n",
        "    mask_x = ((mask_offset_x<x[...,0]) & (x[...,0] < mask_offset_x + mask_size_x)) | ((0<=x[...,0]) & (x[...,0] < mask_offset_x + mask_size_x -1))\n",
        "    mask_y = ((mask_offset_y<x[...,1]) & (x[...,1] < mask_offset_y + mask_size_y)) | ((0<=x[...,1]) & (x[...,1] < mask_offset_y + mask_size_y -1))\n",
        "    mask = mask_x & mask_y\n",
        "    x = tf.where(mask[...,None], mask_value, x)\n",
        "    return x\n",
        "\n",
        "def augment_fn(x, always=False, max_len=None):\n",
        "    if tf.random.uniform(())<0.8 or always:\n",
        "        x = resample(x, (0.5,1.5))\n",
        "    if tf.random.uniform(())<0.5 or always:\n",
        "        x = flip_lr(x)\n",
        "    if tf.random.uniform(())<0.75 or always:\n",
        "        x = spatial_random_affine(x)\n",
        "    if tf.random.uniform(())<0.5 or always:\n",
        "        x = temporal_mask(x)\n",
        "    if tf.random.uniform(())<0.5 or always:\n",
        "        x = spatial_mask(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Oqtue0luNMwJ"
      },
      "id": "Oqtue0luNMwJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "qOFVKmlDN3on"
      },
      "id": "qOFVKmlDN3on"
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_nan_mean(x, axis=0, keepdims=False):\n",
        "    return tf_nan_sum(x, axis=axis, keepdims=keepdims) / tf_nan_count(x, axis=axis, keepdims=keepdims)\n",
        "\n",
        "def tf_nan_std(x, center=None, axis=0, keepdims=False):\n",
        "    if center is None:\n",
        "        center = tf_nan_mean(x, axis=axis,  keepdims=True)\n",
        "    d = x - center\n",
        "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis, keepdims=keepdims))\n",
        "\n",
        "def tf_nan_sum(x, axis=0, keepdims=False):\n",
        "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis, keepdims=keepdims)\n",
        "\n",
        "def tf_nan_count(x, axis=0, keepdims=False):\n",
        "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis, keepdims=keepdims)\n",
        "\n",
        "def combine_datasets(x, y):\n",
        "  x['lev'] = y['lev']\n",
        "  return x"
      ],
      "metadata": {
        "id": "lCxTiZjbN5Rp"
      },
      "id": "lCxTiZjbN5Rp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decode"
      ],
      "metadata": {
        "id": "TWiyFlvbnjqx"
      },
      "id": "TWiyFlvbnjqx"
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_tfrec(record_bytes):\n",
        "    schema = {}\n",
        "    schema[\"frames\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
        "    schema[\"phrase\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
        "    features = tf.io.parse_single_example(record_bytes, schema)\n",
        "\n",
        "    frames = tf.sparse.to_dense(features[\"frames\"])\n",
        "    frames = tf.transpose(tf.reshape(frames,(-1, 2, int(len(SEL_COLS)/2))),[0, 2, 1])\n",
        "    phrase = tf.cast(tf.sparse.to_dense(features[\"phrase\"]), tf.int32)\n",
        "\n",
        "    out = {}\n",
        "    out['coordinates']  = frames\n",
        "    out['phrase'] = phrase\n",
        "    return out\n",
        "\n",
        "def decode_tfrec_levs(record_bytes):\n",
        "    schema = {}\n",
        "    schema[\"lev\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
        "    features = tf.io.parse_single_example(record_bytes, schema)\n",
        "    lev = tf.cast(tf.sparse.to_dense(features[\"lev\"]), tf.float32)\n",
        "    out = {}\n",
        "    out['lev']  = lev\n",
        "    return out"
      ],
      "metadata": {
        "id": "7za7bTbHPPAH"
      },
      "id": "7za7bTbHPPAH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "JiuLp91QpHee"
      },
      "id": "JiuLp91QpHee"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_continue(inputs, point_landmarks, max_len):\n",
        "    if tf.rank(inputs) == 3:\n",
        "        x = inputs[None,...]\n",
        "    else:\n",
        "        x = inputs\n",
        "\n",
        "    mean = tf_nan_mean(tf.gather(x, [norm_point], axis=2), axis=[1,2], keepdims=True)\n",
        "    mean = tf.where(tf.math.is_nan(mean), tf.constant(0.5,x.dtype), mean)\n",
        "    x = tf.gather(x, point_landmarks, axis=2)\n",
        "    std = tf_nan_std(x, center=mean, axis=[1,2], keepdims=True)\n",
        "    x = (x - mean)/std\n",
        "\n",
        "    length = tf.shape(x)[1]\n",
        "\n",
        "    x = x[...,:2]\n",
        "    dx = tf.cond(tf.shape(x)[1]>1,lambda:tf.pad(x[:,1:] - x[:,:-1], [[0,0],[0,1],[0,0],[0,0]]),lambda:tf.zeros_like(x))\n",
        "    dx2 = tf.cond(tf.shape(x)[1]>2,lambda:tf.pad(x[:,2:] - x[:,:-2], [[0,0],[0,2],[0,0],[0,0]]),lambda:tf.zeros_like(x))\n",
        "\n",
        "    x = tf.concat([\n",
        "        tf.reshape(x, (-1,length,len(point_landmarks), 2)),\n",
        "        tf.reshape(dx, (-1,length,len(point_landmarks), 2)),\n",
        "        tf.reshape(dx2, (-1,length,len(point_landmarks), 2)),\n",
        "    ], axis = -1)\n",
        "\n",
        "    if max_len is not None and tf.shape(x)[1] > max_len:\n",
        "        x = tf.image.resize(x[0], (max_len, tf.shape(x)[2]))\n",
        "        x = x[None]\n",
        "\n",
        "    x = tf.concat([\n",
        "        tf.reshape(x, (-1,tf.shape(x)[1],6*len(point_landmarks))),\n",
        "    ], axis = -1)\n",
        "    return tf.cast(x, tf.float32)\n",
        "\n",
        "def normalize(x, MEANs, STDs):\n",
        "  x = (x-MEANs)/STDs\n",
        "  return x\n",
        "\n",
        "def remove_nans(x):\n",
        "  x = tf.where(tf.math.is_nan(x),tf.constant(0.,x.dtype),x)\n",
        "  return x\n",
        "\n",
        "def preprocess(x, point_landmarks, max_len, MEANs, STDs, augment=False):\n",
        "    coord = x['coordinates']\n",
        "    coord = tf.concat([coord, tf.zeros(( tf.shape(coord)[0],  tf.shape(coord)[1], 1))], axis = -1)\n",
        "    if augment:\n",
        "        coord = augment_fn(coord, max_len=max_len)\n",
        "    coord = tf.ensure_shape(coord, (None,ROWS_PER_FRAME,3))\n",
        "    coord = preprocess_continue(coord, point_landmarks, max_len)[0]\n",
        "    coord = normalize(coord, MEANs, STDs)\n",
        "    coord = remove_nans(coord)\n",
        "    return coord, x['phrase']"
      ],
      "metadata": {
        "id": "TpdA_IVfpKuM"
      },
      "id": "TpdA_IVfpKuM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter\n",
        "The first model (this) uses filter_by_length. The second model would use filter_by_lev."
      ],
      "metadata": {
        "id": "ZwS8b2mZo-Wo"
      },
      "id": "ZwS8b2mZo-Wo"
    },
    {
      "cell_type": "code",
      "source": [
        "RHAND_IDX = [i for i, x in enumerate(SEL_COLS_x) if 'right' in x]\n",
        "LHAND_IDX = [i for i, x in enumerate(SEL_COLS_x) if 'left' in x]\n",
        "def f1(): return True\n",
        "def f2(): return False\n",
        "def filter_by_length(x):\n",
        "    frames = x['coordinates']\n",
        "    phrase = x['phrase']\n",
        "    rhand_landmarks = tf.gather(frames, RHAND_IDX, axis=1)\n",
        "    lhand_landmarks = tf.gather(frames, LHAND_IDX, axis=1)\n",
        "    r_nonan = tf.math.reduce_sum(tf.cast(~tf.math.is_nan(rhand_landmarks[:, 0, 0]), tf.int64))\n",
        "    l_nonan = tf.math.reduce_sum(tf.cast(~tf.math.is_nan(lhand_landmarks[:, 0, 0]), tf.int64))\n",
        "    no_nan = tf.math.maximum(r_nonan, l_nonan)\n",
        "    return tf.cond(2*tf.shape(phrase)[0]<tf.cast(no_nan, tf.int32), true_fn=f1, false_fn=f2)\n",
        "\n",
        "def filter_by_lev(x, treshold):\n",
        "    lev = x['lev']\n",
        "    return tf.cond(lev>treshold, true_fn=f1, false_fn=f2)"
      ],
      "metadata": {
        "id": "WrR2d4G_pAd6"
      },
      "id": "WrR2d4G_pAd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define sets\n",
        "**val_files_filtered** set checks the loss and Levenshtein distance on the filtered validation set (same distribution as the train set).  \n",
        "**val_files_unfiltered** checks the loss and Levenshtein distance on the validation set, unfiltered (different distribution than the train set, similar distribution to the leaderboard set).  \n",
        "**sub_train_files** checks the Levenshtein distance on a small part of the train set. The Levenshtein distance is the metric, so it is helpful to know how much the train set overfit it compared to the validation set, but it takes a long time to calculate, so we only do it for a small part of the train set."
      ],
      "metadata": {
        "id": "KZf8M8brp1bh"
      },
      "id": "KZf8M8brp1bh"
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [i for i in range(len(tffiles))]\n",
        "val_files_filtered_indices = indices[:val_len]\n",
        "val_files_unfiltered_indices = indices[:val_len]\n",
        "\n",
        "if DEBUG:\n",
        "  train_files_indices = indices[val_len:val_len+1]\n",
        "  sub_train_files_indices = indices[val_len:val_len+1]\n",
        "else:\n",
        "  train_files_indices = indices[val_len:]\n",
        "  sub_train_files_indices = indices[val_len:val_len+3]"
      ],
      "metadata": {
        "id": "qzhLQ3DMBn22"
      },
      "id": "qzhLQ3DMBn22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load MEANs and STDs"
      ],
      "metadata": {
        "id": "mhQ5Vy9M3h6B"
      },
      "id": "mhQ5Vy9M3h6B"
    },
    {
      "cell_type": "code",
      "source": [
        "MEANs = pickle.load(open(f\"{input_folder}/aslfr_MEANs_STDs/MEANs.p\", \"rb\"))\n",
        "STDs = pickle.load(open(f\"{input_folder}/aslfr_MEANs_STDs/STDs.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "NTPYJavZ3nFB"
      },
      "id": "NTPYJavZ3nFB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get dataset function"
      ],
      "metadata": {
        "id": "TpZC14Dutkh3"
      },
      "id": "TpZC14Dutkh3"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tfrec_dataset(tfrecords_indices, MEANs = MEANs, STDs = STDs, point_landmarks = POINT_LANDMARKS, batch_size=64, max_len=64, drop_remainder=False,\n",
        "                      augment=False, shuffle=False,to_filter = False, cache = False):\n",
        "    # Initialize dataset with TFRecords\n",
        "    ds = tf.data.TFRecordDataset(tffiles[tfrecords_indices], num_parallel_reads=tf.data.AUTOTUNE, compression_type = 'GZIP').prefetch(tf.data.AUTOTUNE)\n",
        "    ds = ds.map(decode_tfrec, tf.data.AUTOTUNE)\n",
        "    ds_levs = tf.data.TFRecordDataset(tffiles_levs[tfrecords_indices], num_parallel_reads=tf.data.AUTOTUNE, compression_type = 'GZIP').prefetch(tf.data.AUTOTUNE)\n",
        "    ds_levs = ds_levs.map(decode_tfrec_levs, tf.data.AUTOTUNE)\n",
        "\n",
        "    ds = tf.data.Dataset.zip((ds, ds_levs))\n",
        "    ds = ds.map(combine_datasets, tf.data.AUTOTUNE)\n",
        "\n",
        "    if to_filter:\n",
        "        #ds = ds.filter(filter_by_length)\n",
        "        ds = ds.filter(lambda x: filter_by_lev(x, 0.2))\n",
        "\n",
        "    if DEBUG:\n",
        "        ds = ds.take(64)\n",
        "\n",
        "    if cache:\n",
        "        ds = ds.cache()\n",
        "    if shuffle:\n",
        "        if shuffle == -1:\n",
        "            samples_num = ds.reduce(0, lambda x,_: x+1).numpy()\n",
        "            ds = ds.shuffle(samples_num, reshuffle_each_iteration = True)\n",
        "        else:\n",
        "            ds = ds.shuffle(shuffle, reshuffle_each_iteration = True)\n",
        "\n",
        "    ds = ds.map(lambda x: preprocess(x, point_landmarks, max_len, MEANs, STDs, augment=augment), tf.data.AUTOTUNE)\n",
        "\n",
        "    if batch_size:\n",
        "        ds = ds.padded_batch(batch_size, padding_values=(PAD, pad_token_idx), padded_shapes=([max_len,CHANNELS],[64]), drop_remainder=drop_remainder)\n",
        "\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle == -1:\n",
        "      return ds, samples_num\n",
        "    return ds"
      ],
      "metadata": {
        "id": "aCSYXOxYto2h"
      },
      "id": "aCSYXOxYto2h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get datasets"
      ],
      "metadata": {
        "id": "sj1k6e7qVBjh"
      },
      "id": "sj1k6e7qVBjh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ca9c10",
        "outputId": "9f20eb19-28f8-4f1a-a763-cf9e099d6852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59884\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([256, 340, 600]), TensorShape([256, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_dataset, num_train = get_tfrec_dataset(train_files_indices, batch_size=batch_size, max_len=MAX_LEN, drop_remainder=True,\n",
        "                                        augment=True, shuffle=-1, to_filter = True, cache = cache)\n",
        "sub_train_dataset = get_tfrec_dataset(sub_train_files_indices, batch_size=batch_size, max_len=MAX_LEN, drop_remainder=True,\n",
        "                                        shuffle=False, to_filter = True, cache = cache)\n",
        "\n",
        "val_dataset_filtered = get_tfrec_dataset(val_files_filtered_indices, batch_size=batch_size, max_len=MAX_LEN, drop_remainder=True,\n",
        "                                        shuffle=False, to_filter = True, cache = cache)\n",
        "val_dataset_unfiltered = get_tfrec_dataset(val_files_unfiltered_indices, batch_size=batch_size, max_len=MAX_LEN, drop_remainder=True,\n",
        "                                        shuffle=False, to_filter = False, cache = cache)\n",
        "\n",
        "print(num_train)\n",
        "INPUT_SHAPE = [MAX_LEN, CHANNELS]\n",
        "batch = next(iter(val_dataset_filtered))\n",
        "batch[0].shape, batch[1].shape"
      ],
      "id": "56ca9c10"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model layers"
      ],
      "metadata": {
        "id": "l7LXor2TVFFI"
      },
      "id": "l7LXor2TVFFI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd973a07"
      },
      "outputs": [],
      "source": [
        "#Copied from previous comp 1st place model: https://www.kaggle.com/code/hoyso48/1st-place-solution-training\n",
        "class ECA(tf.keras.layers.Layer):\n",
        "    def __init__(self, kernel_size=5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n",
        "        nn = tf.expand_dims(nn, -1)\n",
        "        nn = self.conv(nn)\n",
        "        nn = tf.squeeze(nn, -1)\n",
        "        nn = tf.nn.sigmoid(nn)\n",
        "        nn = nn[:,None,:]\n",
        "        return inputs * nn\n",
        "\n",
        "class CausalDWConv1D(tf.keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "        kernel_size=17,\n",
        "        dilation_rate=1,\n",
        "        use_bias=False,\n",
        "        depthwise_initializer='glorot_uniform',\n",
        "        name='', **kwargs):\n",
        "        super().__init__(name=name,**kwargs)\n",
        "        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n",
        "        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n",
        "                            kernel_size,\n",
        "                            strides=1,\n",
        "                            dilation_rate=dilation_rate,\n",
        "                            padding='valid',\n",
        "                            use_bias=use_bias,\n",
        "                            depthwise_initializer=depthwise_initializer,\n",
        "                            name=name + '_dwconv')\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.causal_pad(inputs)\n",
        "        x = self.dw_conv(x)\n",
        "        return x\n",
        "\n",
        "def Conv1DBlock(channel_size,\n",
        "          kernel_size,\n",
        "          dilation_rate=1,\n",
        "          drop_rate=0.0,\n",
        "          expand_ratio=2,\n",
        "          se_ratio=0.25,\n",
        "          activation='swish',\n",
        "          name=None):\n",
        "    '''\n",
        "    efficient conv1d block, @hoyso48\n",
        "    '''\n",
        "    if name is None:\n",
        "        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n",
        "    # Expansion phase\n",
        "    def apply(inputs):\n",
        "        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n",
        "        channels_expand = channels_in * expand_ratio\n",
        "\n",
        "        skip = inputs\n",
        "\n",
        "        x = tf.keras.layers.Dense(\n",
        "            channels_expand,\n",
        "            use_bias=True,\n",
        "            activation=activation,\n",
        "            name=name + '_expand_conv')(inputs)\n",
        "\n",
        "        # Depthwise Convolution\n",
        "        x = CausalDWConv1D(kernel_size,\n",
        "            dilation_rate=dilation_rate,\n",
        "            use_bias=False,\n",
        "            name=name + '_dwconv')(x)\n",
        "\n",
        "        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n",
        "\n",
        "        x  = ECA()(x)\n",
        "\n",
        "        x = tf.keras.layers.Dense(\n",
        "            channel_size,\n",
        "            use_bias=True,\n",
        "            name=name + '_project_conv')(x)\n",
        "\n",
        "        if drop_rate > 0:\n",
        "            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n",
        "\n",
        "        if (channels_in == channel_size):\n",
        "            x = tf.keras.layers.add([x, skip], name=name + '_add')\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.scale = self.dim ** -0.5\n",
        "        self.num_heads = num_heads\n",
        "        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n",
        "        self.drop1 = tf.keras.layers.Dropout(dropout)\n",
        "        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        qkv = self.qkv(inputs)\n",
        "        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n",
        "        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n",
        "\n",
        "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask[:, None, None, :]\n",
        "\n",
        "        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n",
        "        attn = self.drop1(attn)\n",
        "\n",
        "        x = attn @ v\n",
        "        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def TransformerBlock(dim=256, num_heads=6, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n",
        "    def apply(inputs):\n",
        "        x = inputs\n",
        "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n",
        "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
        "        x = tf.keras.layers.Add()([inputs, x])\n",
        "        attn_out = x\n",
        "\n",
        "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n",
        "        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n",
        "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
        "        x = tf.keras.layers.Add()([attn_out, x])\n",
        "        return x\n",
        "    return apply\n",
        "\n",
        "def positional_encoding(maxlen, num_hid):\n",
        "        depth = num_hid/2\n",
        "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
        "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
        "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
        "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
        "        pos_encoding = tf.concat(\n",
        "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
        "          axis=-1)\n",
        "        return pos_encoding\n",
        "\n",
        "class LateDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.rate = rate\n",
        "        self.start_step = start_step\n",
        "        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super().build(input_shape)\n",
        "        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n",
        "        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = tf.cond(self._train_counter < self.start_step, lambda:inputs, lambda:self.dropout(inputs, training=training))\n",
        "        if training:\n",
        "            self._train_counter.assign_add(1)\n",
        "        return x"
      ],
      "id": "dd973a07"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcO-AkYQSk-0",
        "outputId": "a9e56565-0ac1-4e81-fe66-b06b920137c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train: 59884\n",
            "batch_size: 256\n",
            "steps_per_epoch: 233\n",
            "dropout_step: 3495\n"
          ]
        }
      ],
      "source": [
        "steps_per_epoch = num_train//batch_size\n",
        "print(\"num_train: \" + str(num_train))\n",
        "print(\"batch_size: \" + str(batch_size))\n",
        "print(\"steps_per_epoch: \" + str(steps_per_epoch))\n",
        "\n",
        "dropout_start_epoch = 15\n",
        "\n",
        "dropout_step = dropout_start_epoch * steps_per_epoch\n",
        "print(\"dropout_step: \" + str(dropout_step))"
      ],
      "id": "gcO-AkYQSk-0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57fec44d"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(labels, logits):\n",
        "    label_length = tf.reduce_sum(tf.cast(labels != pad_token_idx, tf.int32), axis=-1)\n",
        "    logit_length = tf.ones(tf.shape(logits)[0], dtype=tf.int32) * tf.shape(logits)[1]\n",
        "\n",
        "    loss = classic_ctc_loss(\n",
        "            labels=labels,\n",
        "            logits=logits,\n",
        "            label_length=label_length,\n",
        "            logit_length=logit_length,\n",
        "            blank_index=pad_token_idx,\n",
        "        )\n",
        "    loss = tf.reduce_mean(loss)\n",
        "    return loss"
      ],
      "id": "57fec44d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f772936",
        "outputId": "63c0a47e-f280-48c2-d0df-d40789bec39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim: 384\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 340, 600)]   0           []                               \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, 340, 600)     0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " stem_conv (Dense)              (None, 340, 384)     230400      ['masking[0][0]']                \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 340, 384)     1536        ['stem_conv[0][0]']              \n",
            "                                                                                                  \n",
            " 1_expand_conv (Dense)          (None, 340, 768)     295680      ['stem_bn[0][0]']                \n",
            "                                                                                                  \n",
            " 1_dwconv (CausalDWConv1D)      (None, 340, 768)     8448        ['1_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 1_bn (BatchNormalization)      (None, 340, 768)     3072        ['1_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca (ECA)                      (None, 340, 768)     5           ['1_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 1_project_conv (Dense)         (None, 340, 384)     295296      ['eca[0][0]']                    \n",
            "                                                                                                  \n",
            " 1_drop (Dropout)               (None, 340, 384)     0           ['1_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 1_add (Add)                    (None, 340, 384)     0           ['1_drop[0][0]',                 \n",
            "                                                                  'stem_bn[0][0]']                \n",
            "                                                                                                  \n",
            " 2_expand_conv (Dense)          (None, 340, 768)     295680      ['1_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 2_dwconv (CausalDWConv1D)      (None, 340, 768)     5376        ['2_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 2_bn (BatchNormalization)      (None, 340, 768)     3072        ['2_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_1 (ECA)                    (None, 340, 768)     5           ['2_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 2_project_conv (Dense)         (None, 340, 384)     295296      ['eca_1[0][0]']                  \n",
            "                                                                                                  \n",
            " 2_drop (Dropout)               (None, 340, 384)     0           ['2_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 2_add (Add)                    (None, 340, 384)     0           ['2_drop[0][0]',                 \n",
            "                                                                  '1_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 3_expand_conv (Dense)          (None, 340, 768)     295680      ['2_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 3_dwconv (CausalDWConv1D)      (None, 340, 768)     2304        ['3_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 3_bn (BatchNormalization)      (None, 340, 768)     3072        ['3_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_2 (ECA)                    (None, 340, 768)     5           ['3_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 3_project_conv (Dense)         (None, 340, 384)     295296      ['eca_2[0][0]']                  \n",
            "                                                                                                  \n",
            " 3_drop (Dropout)               (None, 340, 384)     0           ['3_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 3_add (Add)                    (None, 340, 384)     0           ['3_drop[0][0]',                 \n",
            "                                                                  '2_add[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 340, 384)    0           ['3_add[0][0]']                  \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 340, 384)    768         ['tf.__operators__.add[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_self_attention (Mul  (None, 340, 384)    589824      ['layer_normalization[0][0]']    \n",
            " tiHeadSelfAttention)                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 340, 384)     0           ['multi_head_self_attention[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 340, 384)     0           ['tf.__operators__.add[0][0]',   \n",
            "                                                                  'dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 340, 384)    768         ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 340, 768)     294912      ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 340, 384)     294912      ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 340, 384)     0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 340, 384)     0           ['add[0][0]',                    \n",
            "                                                                  'dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " 4_expand_conv (Dense)          (None, 340, 768)     295680      ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " 4_dwconv (CausalDWConv1D)      (None, 340, 768)     8448        ['4_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 4_bn (BatchNormalization)      (None, 340, 768)     3072        ['4_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_3 (ECA)                    (None, 340, 768)     5           ['4_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 4_project_conv (Dense)         (None, 340, 384)     295296      ['eca_3[0][0]']                  \n",
            "                                                                                                  \n",
            " 4_drop (Dropout)               (None, 340, 384)     0           ['4_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 4_add (Add)                    (None, 340, 384)     0           ['4_drop[0][0]',                 \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " 5_expand_conv (Dense)          (None, 340, 768)     295680      ['4_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 5_dwconv (CausalDWConv1D)      (None, 340, 768)     5376        ['5_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 5_bn (BatchNormalization)      (None, 340, 768)     3072        ['5_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_4 (ECA)                    (None, 340, 768)     5           ['5_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 5_project_conv (Dense)         (None, 340, 384)     295296      ['eca_4[0][0]']                  \n",
            "                                                                                                  \n",
            " 5_drop (Dropout)               (None, 340, 384)     0           ['5_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 5_add (Add)                    (None, 340, 384)     0           ['5_drop[0][0]',                 \n",
            "                                                                  '4_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 6_expand_conv (Dense)          (None, 340, 768)     295680      ['5_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 6_dwconv (CausalDWConv1D)      (None, 340, 768)     2304        ['6_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 6_bn (BatchNormalization)      (None, 340, 768)     3072        ['6_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_5 (ECA)                    (None, 340, 768)     5           ['6_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 6_project_conv (Dense)         (None, 340, 384)     295296      ['eca_5[0][0]']                  \n",
            "                                                                                                  \n",
            " 6_drop (Dropout)               (None, 340, 384)     0           ['6_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 6_add (Add)                    (None, 340, 384)     0           ['6_drop[0][0]',                 \n",
            "                                                                  '5_add[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 340, 384)    768         ['6_add[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_self_attention_1 (M  (None, 340, 384)    589824      ['layer_normalization_2[0][0]']  \n",
            " ultiHeadSelfAttention)                                                                           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 340, 384)     0           ['multi_head_self_attention_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 340, 384)     0           ['6_add[0][0]',                  \n",
            "                                                                  'dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 340, 384)    768         ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 340, 768)     294912      ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 340, 384)     294912      ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 340, 384)     0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 340, 384)     0           ['add_2[0][0]',                  \n",
            "                                                                  'dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " 7_expand_conv (Dense)          (None, 340, 768)     295680      ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " 7_dwconv (CausalDWConv1D)      (None, 340, 768)     8448        ['7_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 7_bn (BatchNormalization)      (None, 340, 768)     3072        ['7_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_6 (ECA)                    (None, 340, 768)     5           ['7_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 7_project_conv (Dense)         (None, 340, 384)     295296      ['eca_6[0][0]']                  \n",
            "                                                                                                  \n",
            " 7_drop (Dropout)               (None, 340, 384)     0           ['7_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 7_add (Add)                    (None, 340, 384)     0           ['7_drop[0][0]',                 \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " 8_expand_conv (Dense)          (None, 340, 768)     295680      ['7_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 8_dwconv (CausalDWConv1D)      (None, 340, 768)     5376        ['8_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 8_bn (BatchNormalization)      (None, 340, 768)     3072        ['8_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_7 (ECA)                    (None, 340, 768)     5           ['8_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 8_project_conv (Dense)         (None, 340, 384)     295296      ['eca_7[0][0]']                  \n",
            "                                                                                                  \n",
            " 8_drop (Dropout)               (None, 340, 384)     0           ['8_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 8_add (Add)                    (None, 340, 384)     0           ['8_drop[0][0]',                 \n",
            "                                                                  '7_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 9_expand_conv (Dense)          (None, 340, 768)     295680      ['8_add[0][0]']                  \n",
            "                                                                                                  \n",
            " 9_dwconv (CausalDWConv1D)      (None, 340, 768)     2304        ['9_expand_conv[0][0]']          \n",
            "                                                                                                  \n",
            " 9_bn (BatchNormalization)      (None, 340, 768)     3072        ['9_dwconv[0][0]']               \n",
            "                                                                                                  \n",
            " eca_8 (ECA)                    (None, 340, 768)     5           ['9_bn[0][0]']                   \n",
            "                                                                                                  \n",
            " 9_project_conv (Dense)         (None, 340, 384)     295296      ['eca_8[0][0]']                  \n",
            "                                                                                                  \n",
            " 9_drop (Dropout)               (None, 340, 384)     0           ['9_project_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 9_add (Add)                    (None, 340, 384)     0           ['9_drop[0][0]',                 \n",
            "                                                                  '8_add[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 340, 384)    768         ['9_add[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_self_attention_2 (M  (None, 340, 384)    589824      ['layer_normalization_4[0][0]']  \n",
            " ultiHeadSelfAttention)                                                                           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 340, 384)     0           ['multi_head_self_attention_2[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 340, 384)     0           ['9_add[0][0]',                  \n",
            "                                                                  'dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 340, 384)    768         ['add_4[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 340, 768)     294912      ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 340, 384)     294912      ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 340, 384)     0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 340, 384)     0           ['add_4[0][0]',                  \n",
            "                                                                  'dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " 10_expand_conv (Dense)         (None, 340, 768)     295680      ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " 10_dwconv (CausalDWConv1D)     (None, 340, 768)     8448        ['10_expand_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 10_bn (BatchNormalization)     (None, 340, 768)     3072        ['10_dwconv[0][0]']              \n",
            "                                                                                                  \n",
            " eca_9 (ECA)                    (None, 340, 768)     5           ['10_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " 10_project_conv (Dense)        (None, 340, 384)     295296      ['eca_9[0][0]']                  \n",
            "                                                                                                  \n",
            " 10_drop (Dropout)              (None, 340, 384)     0           ['10_project_conv[0][0]']        \n",
            "                                                                                                  \n",
            " 10_add (Add)                   (None, 340, 384)     0           ['10_drop[0][0]',                \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " 11_expand_conv (Dense)         (None, 340, 768)     295680      ['10_add[0][0]']                 \n",
            "                                                                                                  \n",
            " 11_dwconv (CausalDWConv1D)     (None, 340, 768)     5376        ['11_expand_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 11_bn (BatchNormalization)     (None, 340, 768)     3072        ['11_dwconv[0][0]']              \n",
            "                                                                                                  \n",
            " eca_10 (ECA)                   (None, 340, 768)     5           ['11_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " 11_project_conv (Dense)        (None, 340, 384)     295296      ['eca_10[0][0]']                 \n",
            "                                                                                                  \n",
            " 11_drop (Dropout)              (None, 340, 384)     0           ['11_project_conv[0][0]']        \n",
            "                                                                                                  \n",
            " 11_add (Add)                   (None, 340, 384)     0           ['11_drop[0][0]',                \n",
            "                                                                  '10_add[0][0]']                 \n",
            "                                                                                                  \n",
            " 12_expand_conv (Dense)         (None, 340, 768)     295680      ['11_add[0][0]']                 \n",
            "                                                                                                  \n",
            " 12_dwconv (CausalDWConv1D)     (None, 340, 768)     2304        ['12_expand_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 12_bn (BatchNormalization)     (None, 340, 768)     3072        ['12_dwconv[0][0]']              \n",
            "                                                                                                  \n",
            " eca_11 (ECA)                   (None, 340, 768)     5           ['12_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " 12_project_conv (Dense)        (None, 340, 384)     295296      ['eca_11[0][0]']                 \n",
            "                                                                                                  \n",
            " 12_drop (Dropout)              (None, 340, 384)     0           ['12_project_conv[0][0]']        \n",
            "                                                                                                  \n",
            " 12_add (Add)                   (None, 340, 384)     0           ['12_drop[0][0]',                \n",
            "                                                                  '11_add[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 340, 384)    768         ['12_add[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_self_attention_3 (M  (None, 340, 384)    589824      ['layer_normalization_6[0][0]']  \n",
            " ultiHeadSelfAttention)                                                                           \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 340, 384)     0           ['multi_head_self_attention_3[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 340, 384)     0           ['12_add[0][0]',                 \n",
            "                                                                  'dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 340, 384)    768         ['add_6[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 340, 768)     294912      ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 340, 384)     294912      ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 340, 384)     0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 340, 384)     0           ['add_6[0][0]',                  \n",
            "                                                                  'dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " 13_expand_conv (Dense)         (None, 340, 768)     295680      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " 13_dwconv (CausalDWConv1D)     (None, 340, 768)     8448        ['13_expand_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 13_bn (BatchNormalization)     (None, 340, 768)     3072        ['13_dwconv[0][0]']              \n",
            "                                                                                                  \n",
            " eca_12 (ECA)                   (None, 340, 768)     5           ['13_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " 13_project_conv (Dense)        (None, 340, 384)     295296      ['eca_12[0][0]']                 \n",
            "                                                                                                  \n",
            " 13_drop (Dropout)              (None, 340, 384)     0           ['13_project_conv[0][0]']        \n",
            "                                                                                                  \n",
            " 13_add (Add)                   (None, 340, 384)     0           ['13_drop[0][0]',                \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " 14_expand_conv (Dense)         (None, 340, 768)     295680      ['13_add[0][0]']                 \n",
            "                                                                                                  \n",
            " 14_dwconv (CausalDWConv1D)     (None, 340, 768)     5376        ['14_expand_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 14_bn (BatchNormalization)     (None, 340, 768)     3072        ['14_dwconv[0][0]']              \n",
            "                                                                                                  \n",
            " eca_13 (ECA)                   (None, 340, 768)     5           ['14_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " 14_project_conv (Dense)        (None, 340, 384)     295296      ['eca_13[0][0]']                 \n",
            "                                                                                                  \n",
            " 14_drop (Dropout)              (None, 340, 384)     0           ['14_project_conv[0][0]']        \n",
            "                                                                                                  \n",
            " 14_add (Add)                   (None, 340, 384)     0           ['14_drop[0][0]',                \n",
            "                                                                  '13_add[0][0]']                 \n",
            "                                                                                                  \n",
            " 15_expand_conv (Dense)         (None, 340, 768)     295680      ['14_add[0][0]']                 \n",
            "                                                                                                  \n",
            " 15_dwconv (CausalDWConv1D)     (None, 340, 768)     2304        ['15_expand_conv[0][0]']         \n",
            "                                                                                                  \n",
            " 15_bn (BatchNormalization)     (None, 340, 768)     3072        ['15_dwconv[0][0]']              \n",
            "                                                                                                  \n",
            " eca_14 (ECA)                   (None, 340, 768)     5           ['15_bn[0][0]']                  \n",
            "                                                                                                  \n",
            " 15_project_conv (Dense)        (None, 340, 384)     295296      ['eca_14[0][0]']                 \n",
            "                                                                                                  \n",
            " 15_drop (Dropout)              (None, 340, 384)     0           ['15_project_conv[0][0]']        \n",
            "                                                                                                  \n",
            " 15_add (Add)                   (None, 340, 384)     0           ['15_drop[0][0]',                \n",
            "                                                                  '14_add[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 340, 384)    768         ['15_add[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_self_attention_4 (M  (None, 340, 384)    589824      ['layer_normalization_8[0][0]']  \n",
            " ultiHeadSelfAttention)                                                                           \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 340, 384)     0           ['multi_head_self_attention_4[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 340, 384)     0           ['15_add[0][0]',                 \n",
            "                                                                  'dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 340, 384)    768         ['add_8[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 340, 768)     294912      ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 340, 384)     294912      ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 340, 384)     0           ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 340, 384)     0           ['add_8[0][0]',                  \n",
            "                                                                  'dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " top_conv (Dense)               (None, 340, 768)     295680      ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " late_dropout (LateDropout)     (None, 340, 768)     1           ['top_conv[0][0]']               \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 340, 60)      46140       ['late_dropout[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 15,471,112\n",
            "Trainable params: 15,447,303\n",
            "Non-trainable params: 23,809\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def get_model(dim = 384, dropout_step=0):\n",
        "    with strategy.scope():\n",
        "        inp = tf.keras.Input(INPUT_SHAPE)\n",
        "        x = inp\n",
        "\n",
        "        x = tf.keras.layers.Masking(mask_value=0.0)(x)\n",
        "        x = tf.keras.layers.Dense(dim, use_bias=False,name='stem_conv')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n",
        "\n",
        "        x = Conv1DBlock(dim,11,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,7,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,3,drop_rate=0.2)(x)\n",
        "\n",
        "        x = x + positional_encoding(INPUT_SHAPE[0], dim)\n",
        "\n",
        "        x = TransformerBlock(dim,expand=2)(x)\n",
        "\n",
        "        x = Conv1DBlock(dim,11,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,7,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,3,drop_rate=0.2)(x)\n",
        "        x = TransformerBlock(dim,expand=2)(x)\n",
        "\n",
        "        x = Conv1DBlock(dim,11,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,7,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,3,drop_rate=0.2)(x)\n",
        "        x = TransformerBlock(dim,expand=2)(x)\n",
        "\n",
        "        x = Conv1DBlock(dim,11,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,7,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,3,drop_rate=0.2)(x)\n",
        "        x = TransformerBlock(dim,expand=2)(x)\n",
        "\n",
        "        x = Conv1DBlock(dim,11,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,7,drop_rate=0.2)(x)\n",
        "        x = Conv1DBlock(dim,3,drop_rate=0.2)(x)\n",
        "        x = TransformerBlock(dim,expand=2)(x)\n",
        "\n",
        "        x = tf.keras.layers.Dense(dim*2,activation='relu',name='top_conv')(x)\n",
        "        x = LateDropout(0.8, start_step=dropout_step)(x)\n",
        "        x = tf.keras.layers.Dense(len(char_to_num))(x)\n",
        "\n",
        "        model = tf.keras.Model(inp, x)\n",
        "\n",
        "        loss = CTCLoss\n",
        "\n",
        "        # Adam Optimizer\n",
        "        optimizer = tfa.optimizers.RectifiedAdam(sma_threshold=4.0)\n",
        "        optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=5)\n",
        "\n",
        "        model.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "        return model\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print('dim: ' + str(dim))\n",
        "\n",
        "model = get_model(dim = dim, dropout_step = dropout_step)\n",
        "model(batch[0])\n",
        "model.summary()"
      ],
      "id": "2f772936"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "756d47c1"
      },
      "outputs": [],
      "source": [
        "def num_to_char_fn(y):\n",
        "    return [num_to_char.get(x, \"\") for x in y]\n",
        "\n",
        "@tf.function()\n",
        "def decode_phrase(pred):\n",
        "    x = tf.argmax(pred, axis=1)\n",
        "    diff = tf.not_equal(x[:-1], x[1:])\n",
        "    adjacent_indices = tf.where(diff)[:, 0]\n",
        "    x = tf.gather(x, adjacent_indices)\n",
        "    mask = x != pad_token_idx\n",
        "    x = tf.boolean_mask(x, mask, axis=0)\n",
        "    return x\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    output_text = []\n",
        "    for result in pred:\n",
        "        result = \"\".join(num_to_char_fn(decode_phrase(result).numpy()))\n",
        "        output_text.append(result)\n",
        "    return output_text"
      ],
      "id": "756d47c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0493a587"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 1500\n",
        "N_WARMUP_EPOCHS = 5\n",
        "LR_MAX = 1e-3\n",
        "WD_RATIO = 0.05\n",
        "WARMUP_METHOD = \"exp\""
      ],
      "id": "0493a587"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecac0ec9"
      },
      "source": [
        "### Calculate the Levenshtein distance (the metric) during training- it takes a lot of time, so it's not done for each  epoch"
      ],
      "id": "ecac0ec9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f548f0e",
        "outputId": "c0d4ff84-aa95-4dcd-ac6c-29dbca8f52b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function Executor.__del__ at 0x7960f4514280>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n",
            "    self.wait()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n",
            "Exception ignored in: <function Executor.__del__ at 0x7960f4514280>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n",
            "    self.wait()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n",
            "Exception ignored in: <function Executor.__del__ at 0x7960f4514280>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n",
            "    self.wait()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"
          ]
        }
      ],
      "source": [
        "with open (f\"{input_folder}/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "\n",
        "val_set_filtered = [x for x in val_dataset_filtered]\n",
        "val_set_unfiltered = [x for x in val_dataset_unfiltered]\n",
        "sub_train_set_ = [x for x in sub_train_dataset]\n",
        "\n",
        "lev_dist_val_filtered = []\n",
        "lev_dist_val_unfiltered = []\n",
        "lev_dist_sub_train = []\n",
        "val_set_unfiltered_loss_list = []\n",
        "\n",
        "with open (f\"{input_folder}/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
        "    character_map = json.load(f)\n",
        "rev_character_map = {j:i for i,j in character_map.items()}\n",
        "\n",
        "class val_lev_callback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def on_epoch_end(self, epoch: int, logs=None):\n",
        "        val_set_unfiltered_loss = self.model.evaluate(val_dataset_unfiltered, verbose = 0)\n",
        "        val_set_unfiltered_loss_list.append(val_set_unfiltered_loss)\n",
        "        print('Val unfiltered loss: ' + str(val_set_unfiltered_loss))\n",
        "        if (epoch+1)%50 == 0:\n",
        "          lev_dist = calculate_lev(self.model, val_set_filtered)\n",
        "          print('Val filtered lev distance: '+str(lev_dist))\n",
        "          lev_dist_val_filtered.append(lev_dist)\n",
        "          lev_dist = calculate_lev(self.model, val_set_unfiltered)\n",
        "          print('Val unfiltered lev distance: '+str(lev_dist))\n",
        "          lev_dist_val_unfiltered.append(lev_dist)\n",
        "          lev_dist = calculate_lev(self.model, sub_train_set_)\n",
        "          print('Sub train lev distance: '+str(lev_dist))\n",
        "          lev_dist_sub_train.append(lev_dist)\n",
        "\n",
        "def calculate_lev(model, dataset):\n",
        "    preds = []\n",
        "    targets = []\n",
        "    scores = []\n",
        "    for batch_idx in range(len(dataset)):\n",
        "        preds_batch = model.predict(dataset[batch_idx][0], verbose = 0)\n",
        "        targets_batch = dataset[batch_idx][1]\n",
        "        for pred_idx in range(len(preds_batch)):\n",
        "            preds.append(\"\".join([rev_character_map.get(s, \"\") for s in decode_phrase(preds_batch[pred_idx]).numpy()]))\n",
        "            targets.append(\"\".join([rev_character_map.get(s, \"\") for s in targets_batch[pred_idx].numpy()]))\n",
        "\n",
        "    N = [len(phrase) for phrase in targets]\n",
        "    lev_dist = [lev.distance(preds[i], targets[i]) for i in range(len(targets))]\n",
        "    metric_result = (np.sum(N) - np.sum(lev_dist))/np.sum(N)\n",
        "    return metric_result\n"
      ],
      "id": "2f548f0e"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(f'{save_folder}/weights')\n",
        "except:\n",
        "  pass\n",
        "class save_model_callback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def on_epoch_end(self, epoch: int, logs=None):\n",
        "        if epoch == 3 or (epoch+1)%50 == 0:\n",
        "            self.model.save_weights(f\"{save_folder}/weights/model_epoch_{epoch}.h5\")"
      ],
      "metadata": {
        "id": "DWcdHQZHY82C"
      },
      "id": "DWcdHQZHY82C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning scheduler"
      ],
      "metadata": {
        "id": "p6DcPqI38vu3"
      },
      "id": "p6DcPqI38vu3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "56baebff",
        "outputId": "0ec4467a-92a3-40bf-f655-c095cec61467"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n",
        "\n",
        "    if current_step < num_warmup_steps:\n",
        "        if WARMUP_METHOD == 'log':\n",
        "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
        "        else:\n",
        "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
        "    else:\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n",
        "\n",
        "def plot_lr_schedule(lr_schedule, epochs):\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    plt.plot([None] + lr_schedule + [None])\n",
        "    # X Labels\n",
        "    x = np.arange(1, epochs + 1)\n",
        "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
        "    plt.xlim([1, epochs])\n",
        "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
        "\n",
        "    # Increase y-limit for better readability\n",
        "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
        "\n",
        "    # Title\n",
        "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
        "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
        "\n",
        "    # Plot Learning Rates\n",
        "    for x, val in enumerate(lr_schedule):\n",
        "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
        "            if x < len(lr_schedule) - 1:\n",
        "                if lr_schedule[x - 1] < val:\n",
        "                    ha = 'right'\n",
        "                else:\n",
        "                    ha = 'left'\n",
        "            elif x == 0:\n",
        "                ha = 'right'\n",
        "            else:\n",
        "                ha = 'left'\n",
        "            plt.plot(x + 1, val, 'o', color='black');\n",
        "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
        "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
        "\n",
        "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
        "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Learning rate for encoder\n",
        "LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n",
        "# Plot Learning Rate Schedule\n",
        "plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n",
        "# Learning Rate Callback\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n",
        "\n",
        "# Custom callback to update weight decay with learning rate\n",
        "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, wd_ratio=WD_RATIO):\n",
        "        self.step_counter = 0\n",
        "        self.wd_ratio = wd_ratio\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
        "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
      ],
      "id": "56baebff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f6558e0",
        "outputId": "290f2ad5-5783-4e27-e57b-0822e62c25a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "233/233 - 44s - loss: 19.4618 - val_loss: 12.0103 - lr: 9.2556e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.25e-04, weight decay: 4.63e-05\n",
            "Epoch 270/1500\n",
            "Val unfiltered loss: 15.968496322631836\n",
            "233/233 - 44s - loss: 19.4372 - val_loss: 11.9192 - lr: 9.2501e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.24e-04, weight decay: 4.62e-05\n",
            "Epoch 271/1500\n",
            "Val unfiltered loss: 16.119178771972656\n",
            "233/233 - 43s - loss: 19.3987 - val_loss: 12.1277 - lr: 9.2446e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.24e-04, weight decay: 4.62e-05\n",
            "Epoch 272/1500\n",
            "Val unfiltered loss: 16.149864196777344\n",
            "233/233 - 43s - loss: 19.3954 - val_loss: 12.0295 - lr: 9.2390e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.23e-04, weight decay: 4.62e-05\n",
            "Epoch 273/1500\n",
            "Val unfiltered loss: 15.939820289611816\n",
            "233/233 - 44s - loss: 19.3674 - val_loss: 12.0095 - lr: 9.2334e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.23e-04, weight decay: 4.61e-05\n",
            "Epoch 274/1500\n",
            "Val unfiltered loss: 15.645966529846191\n",
            "233/233 - 44s - loss: 19.2446 - val_loss: 11.8063 - lr: 9.2278e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.22e-04, weight decay: 4.61e-05\n",
            "Epoch 275/1500\n",
            "Val unfiltered loss: 16.046070098876953\n",
            "233/233 - 43s - loss: 19.2913 - val_loss: 12.0377 - lr: 9.2222e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.22e-04, weight decay: 4.61e-05\n",
            "Epoch 276/1500\n",
            "Val unfiltered loss: 16.188465118408203\n",
            "233/233 - 43s - loss: 19.2078 - val_loss: 12.2479 - lr: 9.2166e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.21e-04, weight decay: 4.61e-05\n",
            "Epoch 277/1500\n",
            "Val unfiltered loss: 15.726666450500488\n",
            "233/233 - 44s - loss: 19.3322 - val_loss: 11.7358 - lr: 9.2109e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.21e-04, weight decay: 4.60e-05\n",
            "Epoch 278/1500\n",
            "Val unfiltered loss: 16.052135467529297\n",
            "233/233 - 44s - loss: 19.1648 - val_loss: 12.0447 - lr: 9.2052e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.20e-04, weight decay: 4.60e-05\n",
            "Epoch 279/1500\n",
            "Val unfiltered loss: 15.742080688476562\n",
            "233/233 - 43s - loss: 19.1626 - val_loss: 11.8588 - lr: 9.1995e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.19e-04, weight decay: 4.60e-05\n",
            "Epoch 280/1500\n",
            "Val unfiltered loss: 16.0465087890625\n",
            "233/233 - 44s - loss: 19.3215 - val_loss: 12.1087 - lr: 9.1938e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 9.19e-04, weight decay: 4.59e-05\n",
            "Epoch 281/1500\n",
            "Val unfiltered loss: 15.929045677185059\n",
            "233/233 - 44s - loss: 19.2823 - val_loss: 11.9243 - lr: 9.1881e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.18e-04, weight decay: 4.59e-05\n",
            "Epoch 282/1500\n",
            "Val unfiltered loss: 16.01897430419922\n",
            "233/233 - 43s - loss: 19.2544 - val_loss: 11.9223 - lr: 9.1824e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.18e-04, weight decay: 4.59e-05\n",
            "Epoch 283/1500\n",
            "Val unfiltered loss: 16.13974952697754\n",
            "233/233 - 43s - loss: 19.1178 - val_loss: 12.0408 - lr: 9.1766e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.17e-04, weight decay: 4.59e-05\n",
            "Epoch 284/1500\n",
            "Val unfiltered loss: 15.951001167297363\n",
            "233/233 - 43s - loss: 19.1490 - val_loss: 11.9017 - lr: 9.1708e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.16e-04, weight decay: 4.58e-05\n",
            "Epoch 285/1500\n",
            "Val unfiltered loss: 15.994314193725586\n",
            "233/233 - 44s - loss: 19.1159 - val_loss: 11.9224 - lr: 9.1650e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.16e-04, weight decay: 4.58e-05\n",
            "Epoch 286/1500\n",
            "Val unfiltered loss: 15.785633087158203\n",
            "233/233 - 43s - loss: 19.1509 - val_loss: 11.9171 - lr: 9.1592e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.15e-04, weight decay: 4.58e-05\n",
            "Epoch 287/1500\n",
            "Val unfiltered loss: 15.978903770446777\n",
            "233/233 - 43s - loss: 19.0199 - val_loss: 11.9340 - lr: 9.1533e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.15e-04, weight decay: 4.57e-05\n",
            "Epoch 288/1500\n",
            "Val unfiltered loss: 15.936763763427734\n",
            "233/233 - 44s - loss: 19.1994 - val_loss: 11.9325 - lr: 9.1475e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.14e-04, weight decay: 4.57e-05\n",
            "Epoch 289/1500\n",
            "Val unfiltered loss: 16.156822204589844\n",
            "233/233 - 44s - loss: 19.0634 - val_loss: 12.0424 - lr: 9.1416e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.14e-04, weight decay: 4.57e-05\n",
            "Epoch 290/1500\n",
            "Val unfiltered loss: 15.9608736038208\n",
            "233/233 - 43s - loss: 19.0345 - val_loss: 11.8762 - lr: 9.1357e-04 - 43s/epoch - 184ms/step\n",
            "learning rate: 9.13e-04, weight decay: 4.56e-05\n",
            "Epoch 291/1500\n",
            "Val unfiltered loss: 16.469160079956055\n",
            "233/233 - 43s - loss: 19.0668 - val_loss: 12.1970 - lr: 9.1298e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.12e-04, weight decay: 4.56e-05\n",
            "Epoch 292/1500\n",
            "Val unfiltered loss: 15.974370956420898\n",
            "233/233 - 44s - loss: 19.0498 - val_loss: 11.6986 - lr: 9.1239e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.12e-04, weight decay: 4.56e-05\n",
            "Epoch 293/1500\n",
            "Val unfiltered loss: 16.371992111206055\n",
            "233/233 - 43s - loss: 19.0775 - val_loss: 12.2243 - lr: 9.1179e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.11e-04, weight decay: 4.56e-05\n",
            "Epoch 294/1500\n",
            "Val unfiltered loss: 16.33409309387207\n",
            "233/233 - 44s - loss: 19.1475 - val_loss: 12.0294 - lr: 9.1119e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 9.11e-04, weight decay: 4.55e-05\n",
            "Epoch 295/1500\n",
            "Val unfiltered loss: 16.029321670532227\n",
            "233/233 - 43s - loss: 18.9999 - val_loss: 11.9003 - lr: 9.1059e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.10e-04, weight decay: 4.55e-05\n",
            "Epoch 296/1500\n",
            "Val unfiltered loss: 15.750925064086914\n",
            "233/233 - 44s - loss: 18.9969 - val_loss: 11.8436 - lr: 9.0999e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.09e-04, weight decay: 4.55e-05\n",
            "Epoch 297/1500\n",
            "Val unfiltered loss: 15.958423614501953\n",
            "233/233 - 43s - loss: 18.9692 - val_loss: 11.8712 - lr: 9.0939e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.09e-04, weight decay: 4.54e-05\n",
            "Epoch 298/1500\n",
            "Val unfiltered loss: 16.12853240966797\n",
            "233/233 - 43s - loss: 18.9467 - val_loss: 11.9266 - lr: 9.0879e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.08e-04, weight decay: 4.54e-05\n",
            "Epoch 299/1500\n",
            "Val unfiltered loss: 15.923015594482422\n",
            "233/233 - 43s - loss: 19.0943 - val_loss: 11.7968 - lr: 9.0818e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.08e-04, weight decay: 4.54e-05\n",
            "Epoch 300/1500\n",
            "Val unfiltered loss: 16.067628860473633\n",
            "Val filtered lev distance: 0.8395660051957125\n",
            "Val unfiltered lev distance: 0.790760545461774\n",
            "Sub train lev distance: 0.8868064982265622\n",
            "233/233 - 118s - loss: 18.9433 - val_loss: 11.9275 - lr: 9.0757e-04 - 118s/epoch - 506ms/step\n",
            "learning rate: 9.07e-04, weight decay: 4.53e-05\n",
            "Epoch 301/1500\n",
            "Val unfiltered loss: 16.38291358947754\n",
            "233/233 - 43s - loss: 18.8875 - val_loss: 12.2105 - lr: 9.0696e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.06e-04, weight decay: 4.53e-05\n",
            "Epoch 302/1500\n",
            "Val unfiltered loss: 16.11339569091797\n",
            "233/233 - 45s - loss: 18.8706 - val_loss: 12.0050 - lr: 9.0635e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 9.06e-04, weight decay: 4.53e-05\n",
            "Epoch 303/1500\n",
            "Val unfiltered loss: 16.4355525970459\n",
            "233/233 - 44s - loss: 18.8984 - val_loss: 12.1525 - lr: 9.0574e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.05e-04, weight decay: 4.53e-05\n",
            "Epoch 304/1500\n",
            "Val unfiltered loss: 16.19171714782715\n",
            "233/233 - 44s - loss: 18.8738 - val_loss: 12.0931 - lr: 9.0513e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.05e-04, weight decay: 4.52e-05\n",
            "Epoch 305/1500\n",
            "Val unfiltered loss: 15.768539428710938\n",
            "233/233 - 43s - loss: 18.8946 - val_loss: 11.7804 - lr: 9.0451e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.04e-04, weight decay: 4.52e-05\n",
            "Epoch 306/1500\n",
            "Val unfiltered loss: 15.666180610656738\n",
            "233/233 - 43s - loss: 18.8745 - val_loss: 11.6207 - lr: 9.0389e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 9.03e-04, weight decay: 4.52e-05\n",
            "Epoch 307/1500\n",
            "Val unfiltered loss: 15.949756622314453\n",
            "233/233 - 44s - loss: 18.7911 - val_loss: 11.9060 - lr: 9.0327e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.03e-04, weight decay: 4.51e-05\n",
            "Epoch 308/1500\n",
            "Val unfiltered loss: 16.090089797973633\n",
            "233/233 - 44s - loss: 18.8430 - val_loss: 12.0518 - lr: 9.0265e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.02e-04, weight decay: 4.51e-05\n",
            "Epoch 309/1500\n",
            "Val unfiltered loss: 15.884119033813477\n",
            "233/233 - 44s - loss: 18.7751 - val_loss: 11.8677 - lr: 9.0202e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 9.01e-04, weight decay: 4.51e-05\n",
            "Epoch 310/1500\n",
            "Val unfiltered loss: 15.8250150680542\n",
            "233/233 - 43s - loss: 18.7899 - val_loss: 11.8223 - lr: 9.0140e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.01e-04, weight decay: 4.50e-05\n",
            "Epoch 311/1500\n",
            "Val unfiltered loss: 15.756948471069336\n",
            "233/233 - 44s - loss: 18.7595 - val_loss: 11.7503 - lr: 9.0077e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.00e-04, weight decay: 4.50e-05\n",
            "Epoch 312/1500\n",
            "Val unfiltered loss: 16.074352264404297\n",
            "233/233 - 43s - loss: 18.8108 - val_loss: 11.9649 - lr: 9.0014e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.00e-04, weight decay: 4.50e-05\n",
            "Epoch 313/1500\n",
            "Val unfiltered loss: 16.405595779418945\n",
            "233/233 - 43s - loss: 18.8216 - val_loss: 12.0887 - lr: 8.9951e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.99e-04, weight decay: 4.49e-05\n",
            "Epoch 314/1500\n",
            "Val unfiltered loss: 16.02229118347168\n",
            "233/233 - 44s - loss: 18.7625 - val_loss: 11.8676 - lr: 8.9888e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.98e-04, weight decay: 4.49e-05\n",
            "Epoch 315/1500\n",
            "Val unfiltered loss: 16.017589569091797\n",
            "233/233 - 43s - loss: 18.6932 - val_loss: 11.8688 - lr: 8.9824e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.98e-04, weight decay: 4.49e-05\n",
            "Epoch 316/1500\n",
            "Val unfiltered loss: 15.85189151763916\n",
            "233/233 - 44s - loss: 18.6752 - val_loss: 11.8803 - lr: 8.9761e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 8.97e-04, weight decay: 4.48e-05\n",
            "Epoch 317/1500\n",
            "Val unfiltered loss: 15.985617637634277\n",
            "233/233 - 43s - loss: 18.6490 - val_loss: 11.8375 - lr: 8.9697e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.96e-04, weight decay: 4.48e-05\n",
            "Epoch 318/1500\n",
            "Val unfiltered loss: 15.927355766296387\n",
            "233/233 - 43s - loss: 18.6237 - val_loss: 11.8903 - lr: 8.9633e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 8.96e-04, weight decay: 4.48e-05\n",
            "Epoch 319/1500\n",
            "Val unfiltered loss: 15.591552734375\n",
            "233/233 - 43s - loss: 18.6914 - val_loss: 11.6692 - lr: 8.9569e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.95e-04, weight decay: 4.48e-05\n",
            "Epoch 320/1500\n",
            "Val unfiltered loss: 16.202491760253906\n",
            "233/233 - 43s - loss: 18.6491 - val_loss: 12.0596 - lr: 8.9505e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.94e-04, weight decay: 4.47e-05\n",
            "Epoch 321/1500\n",
            "Val unfiltered loss: 16.380830764770508\n",
            "233/233 - 43s - loss: 18.6826 - val_loss: 12.1516 - lr: 8.9440e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.94e-04, weight decay: 4.47e-05\n",
            "Epoch 322/1500\n",
            "Val unfiltered loss: 16.148292541503906\n",
            "233/233 - 43s - loss: 18.6852 - val_loss: 12.0006 - lr: 8.9375e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.93e-04, weight decay: 4.47e-05\n",
            "Epoch 323/1500\n",
            "Val unfiltered loss: 16.274137496948242\n",
            "233/233 - 44s - loss: 18.6950 - val_loss: 12.1672 - lr: 8.9311e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 8.92e-04, weight decay: 4.46e-05\n",
            "Epoch 324/1500\n",
            "Val unfiltered loss: 16.142427444458008\n",
            "233/233 - 43s - loss: 18.6594 - val_loss: 12.0644 - lr: 8.9246e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.92e-04, weight decay: 4.46e-05\n",
            "Epoch 325/1500\n",
            "Val unfiltered loss: 15.91366195678711\n",
            "233/233 - 44s - loss: 18.6288 - val_loss: 11.8310 - lr: 8.9180e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.91e-04, weight decay: 4.46e-05\n",
            "Epoch 326/1500\n",
            "Val unfiltered loss: 16.302579879760742\n",
            "233/233 - 44s - loss: 18.5566 - val_loss: 12.1403 - lr: 8.9115e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.90e-04, weight decay: 4.45e-05\n",
            "Epoch 327/1500\n",
            "Val unfiltered loss: 15.925396919250488\n",
            "233/233 - 43s - loss: 18.5732 - val_loss: 11.9660 - lr: 8.9049e-04 - 43s/epoch - 184ms/step\n",
            "learning rate: 8.90e-04, weight decay: 4.45e-05\n",
            "Epoch 328/1500\n",
            "Val unfiltered loss: 16.18377113342285\n",
            "233/233 - 43s - loss: 18.6194 - val_loss: 12.0861 - lr: 8.8984e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.89e-04, weight decay: 4.45e-05\n",
            "Epoch 329/1500\n",
            "Val unfiltered loss: 16.08893585205078\n",
            "233/233 - 43s - loss: 18.5134 - val_loss: 11.9710 - lr: 8.8918e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.89e-04, weight decay: 4.44e-05\n",
            "Epoch 330/1500\n",
            "Val unfiltered loss: 16.074308395385742\n",
            "233/233 - 45s - loss: 18.4809 - val_loss: 11.9691 - lr: 8.8852e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 8.88e-04, weight decay: 4.44e-05\n",
            "Epoch 331/1500\n",
            "Val unfiltered loss: 15.9035005569458\n",
            "233/233 - 43s - loss: 18.4003 - val_loss: 11.7897 - lr: 8.8786e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.87e-04, weight decay: 4.44e-05\n",
            "Epoch 332/1500\n",
            "Val unfiltered loss: 15.929062843322754\n",
            "233/233 - 43s - loss: 18.4819 - val_loss: 11.8830 - lr: 8.8719e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.87e-04, weight decay: 4.43e-05\n",
            "Epoch 333/1500\n",
            "Val unfiltered loss: 16.0174503326416\n",
            "233/233 - 44s - loss: 18.4858 - val_loss: 11.9795 - lr: 8.8653e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.86e-04, weight decay: 4.43e-05\n",
            "Epoch 334/1500\n",
            "Val unfiltered loss: 16.24904441833496\n",
            "233/233 - 43s - loss: 18.4506 - val_loss: 12.0866 - lr: 8.8586e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 8.85e-04, weight decay: 4.43e-05\n",
            "Epoch 335/1500\n",
            "Val unfiltered loss: 16.078702926635742\n",
            "233/233 - 43s - loss: 18.4185 - val_loss: 12.0849 - lr: 8.8519e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.85e-04, weight decay: 4.42e-05\n",
            "Epoch 336/1500\n",
            "Val unfiltered loss: 15.945489883422852\n",
            "233/233 - 43s - loss: 18.4156 - val_loss: 11.9636 - lr: 8.8452e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.84e-04, weight decay: 4.42e-05\n",
            "Epoch 337/1500\n",
            "Val unfiltered loss: 15.728524208068848\n",
            "233/233 - 45s - loss: 18.4222 - val_loss: 11.5783 - lr: 8.8385e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 8.83e-04, weight decay: 4.42e-05\n",
            "Epoch 338/1500\n",
            "Val unfiltered loss: 16.115434646606445\n",
            "233/233 - 44s - loss: 18.3203 - val_loss: 12.0766 - lr: 8.8317e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.82e-04, weight decay: 4.41e-05\n",
            "Epoch 339/1500\n",
            "Val unfiltered loss: 16.067411422729492\n",
            "233/233 - 44s - loss: 18.2477 - val_loss: 11.8653 - lr: 8.8250e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.82e-04, weight decay: 4.41e-05\n",
            "Epoch 340/1500\n",
            "Val unfiltered loss: 16.348665237426758\n",
            "233/233 - 43s - loss: 18.3312 - val_loss: 12.0879 - lr: 8.8182e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.81e-04, weight decay: 4.41e-05\n",
            "Epoch 341/1500\n",
            "Val unfiltered loss: 16.14763069152832\n",
            "233/233 - 44s - loss: 18.3580 - val_loss: 12.0836 - lr: 8.8114e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.80e-04, weight decay: 4.40e-05\n",
            "Epoch 342/1500\n",
            "Val unfiltered loss: 16.143842697143555\n",
            "233/233 - 43s - loss: 18.4081 - val_loss: 11.9245 - lr: 8.8046e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.80e-04, weight decay: 4.40e-05\n",
            "Epoch 343/1500\n",
            "Val unfiltered loss: 16.013151168823242\n",
            "233/233 - 43s - loss: 18.3333 - val_loss: 11.9818 - lr: 8.7978e-04 - 43s/epoch - 184ms/step\n",
            "learning rate: 8.79e-04, weight decay: 4.40e-05\n",
            "Epoch 344/1500\n",
            "Val unfiltered loss: 16.0299129486084\n",
            "233/233 - 44s - loss: 18.3106 - val_loss: 11.9767 - lr: 8.7909e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 8.78e-04, weight decay: 4.39e-05\n",
            "Epoch 345/1500\n",
            "Val unfiltered loss: 15.917330741882324\n",
            "233/233 - 44s - loss: 18.2802 - val_loss: 11.7996 - lr: 8.7841e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.78e-04, weight decay: 4.39e-05\n",
            "Epoch 346/1500\n",
            "Val unfiltered loss: 15.775054931640625\n",
            "233/233 - 43s - loss: 18.2922 - val_loss: 11.8944 - lr: 8.7772e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.77e-04, weight decay: 4.39e-05\n",
            "Epoch 347/1500\n",
            "Val unfiltered loss: 15.857216835021973\n",
            "233/233 - 43s - loss: 18.3799 - val_loss: 11.9498 - lr: 8.7703e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.76e-04, weight decay: 4.38e-05\n",
            "Epoch 348/1500\n",
            "Val unfiltered loss: 15.863171577453613\n",
            "233/233 - 44s - loss: 18.3677 - val_loss: 11.8218 - lr: 8.7634e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.76e-04, weight decay: 4.38e-05\n",
            "Epoch 349/1500\n",
            "Val unfiltered loss: 15.889969825744629\n",
            "233/233 - 43s - loss: 18.3502 - val_loss: 11.8401 - lr: 8.7565e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.75e-04, weight decay: 4.37e-05\n",
            "Epoch 350/1500\n",
            "Val unfiltered loss: 15.965201377868652\n",
            "Val filtered lev distance: 0.8444997489466676\n",
            "Val unfiltered lev distance: 0.7953325647040115\n",
            "Sub train lev distance: 0.8971843937469896\n",
            "233/233 - 116s - loss: 18.2429 - val_loss: 11.9451 - lr: 8.7495e-04 - 116s/epoch - 497ms/step\n",
            "learning rate: 8.74e-04, weight decay: 4.37e-05\n",
            "Epoch 351/1500\n",
            "Val unfiltered loss: 15.838251113891602\n",
            "233/233 - 43s - loss: 18.2336 - val_loss: 11.7379 - lr: 8.7426e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.74e-04, weight decay: 4.37e-05\n",
            "Epoch 352/1500\n",
            "Val unfiltered loss: 15.972933769226074\n",
            "233/233 - 43s - loss: 18.1631 - val_loss: 11.8679 - lr: 8.7356e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.73e-04, weight decay: 4.36e-05\n",
            "Epoch 353/1500\n",
            "Val unfiltered loss: 16.20418930053711\n",
            "233/233 - 44s - loss: 18.1525 - val_loss: 12.2131 - lr: 8.7286e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.72e-04, weight decay: 4.36e-05\n",
            "Epoch 354/1500\n",
            "Val unfiltered loss: 16.278900146484375\n",
            "233/233 - 43s - loss: 18.1694 - val_loss: 12.0849 - lr: 8.7216e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.71e-04, weight decay: 4.36e-05\n",
            "Epoch 355/1500\n",
            "Val unfiltered loss: 16.115097045898438\n",
            "233/233 - 43s - loss: 18.1367 - val_loss: 11.8847 - lr: 8.7146e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.71e-04, weight decay: 4.35e-05\n",
            "Epoch 356/1500\n",
            "Val unfiltered loss: 15.988965034484863\n",
            "233/233 - 44s - loss: 18.1772 - val_loss: 11.8991 - lr: 8.7075e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.70e-04, weight decay: 4.35e-05\n",
            "Epoch 357/1500\n",
            "Val unfiltered loss: 15.871517181396484\n",
            "233/233 - 44s - loss: 18.1863 - val_loss: 11.7960 - lr: 8.7005e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.69e-04, weight decay: 4.35e-05\n",
            "Epoch 358/1500\n",
            "Val unfiltered loss: 16.212282180786133\n",
            "233/233 - 43s - loss: 18.1614 - val_loss: 11.9393 - lr: 8.6934e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.69e-04, weight decay: 4.34e-05\n",
            "Epoch 359/1500\n",
            "Val unfiltered loss: 16.257436752319336\n",
            "233/233 - 44s - loss: 18.1558 - val_loss: 12.0495 - lr: 8.6863e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.68e-04, weight decay: 4.34e-05\n",
            "Epoch 360/1500\n",
            "Val unfiltered loss: 16.123323440551758\n",
            "233/233 - 45s - loss: 18.1234 - val_loss: 11.9869 - lr: 8.6792e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 8.67e-04, weight decay: 4.34e-05\n",
            "Epoch 361/1500\n",
            "Val unfiltered loss: 16.397438049316406\n",
            "233/233 - 43s - loss: 18.0993 - val_loss: 12.1367 - lr: 8.6721e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.66e-04, weight decay: 4.33e-05\n",
            "Epoch 362/1500\n",
            "Val unfiltered loss: 16.208879470825195\n",
            "233/233 - 43s - loss: 18.0815 - val_loss: 11.9550 - lr: 8.6649e-04 - 43s/epoch - 184ms/step\n",
            "learning rate: 8.66e-04, weight decay: 4.33e-05\n",
            "Epoch 363/1500\n",
            "Val unfiltered loss: 16.125776290893555\n",
            "233/233 - 43s - loss: 18.0206 - val_loss: 11.9529 - lr: 8.6578e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.65e-04, weight decay: 4.33e-05\n",
            "Epoch 364/1500\n",
            "Val unfiltered loss: 16.349693298339844\n",
            "233/233 - 44s - loss: 18.0592 - val_loss: 12.2274 - lr: 8.6506e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.64e-04, weight decay: 4.32e-05\n",
            "Epoch 365/1500\n",
            "Val unfiltered loss: 16.13555335998535\n",
            "233/233 - 43s - loss: 18.1188 - val_loss: 11.9736 - lr: 8.6434e-04 - 43s/epoch - 184ms/step\n",
            "learning rate: 8.64e-04, weight decay: 4.32e-05\n",
            "Epoch 366/1500\n",
            "Val unfiltered loss: 16.085895538330078\n",
            "233/233 - 43s - loss: 18.0738 - val_loss: 11.9392 - lr: 8.6362e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.63e-04, weight decay: 4.31e-05\n",
            "Epoch 367/1500\n",
            "Val unfiltered loss: 16.0437068939209\n",
            "233/233 - 45s - loss: 18.0622 - val_loss: 12.0368 - lr: 8.6290e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 8.62e-04, weight decay: 4.31e-05\n",
            "Epoch 368/1500\n",
            "Val unfiltered loss: 16.109251022338867\n",
            "233/233 - 43s - loss: 18.0058 - val_loss: 12.0761 - lr: 8.6217e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.61e-04, weight decay: 4.31e-05\n",
            "Epoch 369/1500\n",
            "Val unfiltered loss: 15.982309341430664\n",
            "233/233 - 43s - loss: 17.9933 - val_loss: 11.8817 - lr: 8.6145e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.61e-04, weight decay: 4.30e-05\n",
            "Epoch 370/1500\n",
            "Val unfiltered loss: 16.066085815429688\n",
            "233/233 - 43s - loss: 17.9383 - val_loss: 11.9077 - lr: 8.6072e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.60e-04, weight decay: 4.30e-05\n",
            "Epoch 371/1500\n",
            "Val unfiltered loss: 16.153766632080078\n",
            "233/233 - 44s - loss: 17.9268 - val_loss: 12.0317 - lr: 8.5999e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.59e-04, weight decay: 4.30e-05\n",
            "Epoch 372/1500\n",
            "Val unfiltered loss: 16.058185577392578\n",
            "233/233 - 43s - loss: 17.9162 - val_loss: 11.9689 - lr: 8.5926e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 8.59e-04, weight decay: 4.29e-05\n",
            "Epoch 373/1500\n",
            "Val unfiltered loss: 15.948241233825684\n",
            "233/233 - 43s - loss: 17.9562 - val_loss: 11.9329 - lr: 8.5853e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.58e-04, weight decay: 4.29e-05\n",
            "Epoch 374/1500\n",
            "Val unfiltered loss: 16.193971633911133\n",
            "233/233 - 45s - loss: 17.9107 - val_loss: 11.9537 - lr: 8.5780e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 8.57e-04, weight decay: 4.29e-05\n",
            "Epoch 375/1500\n",
            "Val unfiltered loss: 16.085283279418945\n",
            "233/233 - 44s - loss: 17.8944 - val_loss: 11.8571 - lr: 8.5706e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.56e-04, weight decay: 4.28e-05\n",
            "Epoch 376/1500\n",
            "Val unfiltered loss: 15.913741111755371\n",
            "233/233 - 43s - loss: 17.8619 - val_loss: 11.8496 - lr: 8.5633e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.56e-04, weight decay: 4.28e-05\n",
            "Epoch 377/1500\n",
            "Val unfiltered loss: 15.893939018249512\n",
            "233/233 - 43s - loss: 17.7700 - val_loss: 11.8893 - lr: 8.5559e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.55e-04, weight decay: 4.27e-05\n",
            "Epoch 378/1500\n",
            "Val unfiltered loss: 15.537820816040039\n",
            "233/233 - 43s - loss: 17.7913 - val_loss: 11.5212 - lr: 8.5485e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.54e-04, weight decay: 4.27e-05\n",
            "Epoch 379/1500\n",
            "Val unfiltered loss: 15.811223983764648\n",
            "233/233 - 44s - loss: 17.8149 - val_loss: 11.8058 - lr: 8.5411e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.53e-04, weight decay: 4.27e-05\n",
            "Epoch 380/1500\n",
            "Val unfiltered loss: 16.111268997192383\n",
            "233/233 - 43s - loss: 17.8268 - val_loss: 11.8928 - lr: 8.5337e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.53e-04, weight decay: 4.26e-05\n",
            "Epoch 381/1500\n",
            "Val unfiltered loss: 15.735662460327148\n",
            "233/233 - 45s - loss: 17.7336 - val_loss: 11.5934 - lr: 8.5262e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 8.52e-04, weight decay: 4.26e-05\n",
            "Epoch 382/1500\n",
            "Val unfiltered loss: 15.981857299804688\n",
            "233/233 - 44s - loss: 17.7886 - val_loss: 11.7370 - lr: 8.5188e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.51e-04, weight decay: 4.26e-05\n",
            "Epoch 383/1500\n",
            "Val unfiltered loss: 15.878683090209961\n",
            "233/233 - 43s - loss: 17.7395 - val_loss: 11.8212 - lr: 8.5113e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.50e-04, weight decay: 4.25e-05\n",
            "Epoch 384/1500\n",
            "Val unfiltered loss: 16.06022071838379\n",
            "233/233 - 43s - loss: 17.7468 - val_loss: 11.8595 - lr: 8.5038e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.50e-04, weight decay: 4.25e-05\n",
            "Epoch 385/1500\n",
            "Val unfiltered loss: 16.4500789642334\n",
            "233/233 - 43s - loss: 17.7534 - val_loss: 12.1525 - lr: 8.4963e-04 - 43s/epoch - 184ms/step\n",
            "learning rate: 8.49e-04, weight decay: 4.24e-05\n",
            "Epoch 386/1500\n",
            "Val unfiltered loss: 16.140146255493164\n",
            "233/233 - 44s - loss: 17.9065 - val_loss: 11.8596 - lr: 8.4888e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.48e-04, weight decay: 4.24e-05\n",
            "Epoch 387/1500\n",
            "Val unfiltered loss: 16.31293487548828\n",
            "233/233 - 43s - loss: 17.8039 - val_loss: 12.0644 - lr: 8.4813e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.47e-04, weight decay: 4.24e-05\n",
            "Epoch 388/1500\n",
            "Val unfiltered loss: 16.391826629638672\n",
            "233/233 - 43s - loss: 17.7656 - val_loss: 12.0266 - lr: 8.4737e-04 - 43s/epoch - 184ms/step\n",
            "learning rate: 8.47e-04, weight decay: 4.23e-05\n",
            "Epoch 389/1500\n",
            "Val unfiltered loss: 16.285789489746094\n",
            "233/233 - 45s - loss: 17.7103 - val_loss: 12.1066 - lr: 8.4661e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 8.46e-04, weight decay: 4.23e-05\n",
            "Epoch 390/1500\n",
            "Val unfiltered loss: 16.06806755065918\n",
            "233/233 - 44s - loss: 17.7451 - val_loss: 11.9417 - lr: 8.4586e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.45e-04, weight decay: 4.23e-05\n",
            "Epoch 391/1500\n",
            "Val unfiltered loss: 15.865413665771484\n",
            "233/233 - 43s - loss: 17.7099 - val_loss: 11.7957 - lr: 8.4510e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.44e-04, weight decay: 4.22e-05\n",
            "Epoch 392/1500\n",
            "Val unfiltered loss: 15.81020736694336\n",
            "233/233 - 43s - loss: 17.6621 - val_loss: 11.7181 - lr: 8.4434e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.44e-04, weight decay: 4.22e-05\n",
            "Epoch 393/1500\n",
            "Val unfiltered loss: 16.446369171142578\n",
            "233/233 - 43s - loss: 17.6181 - val_loss: 12.1150 - lr: 8.4357e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.43e-04, weight decay: 4.21e-05\n",
            "Epoch 394/1500\n",
            "Val unfiltered loss: 16.484403610229492\n",
            "233/233 - 44s - loss: 17.6784 - val_loss: 12.0934 - lr: 8.4281e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.42e-04, weight decay: 4.21e-05\n",
            "Epoch 395/1500\n",
            "Val unfiltered loss: 16.248600006103516\n",
            "233/233 - 44s - loss: 17.6402 - val_loss: 12.1129 - lr: 8.4204e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 8.41e-04, weight decay: 4.21e-05\n",
            "Epoch 396/1500\n",
            "Val unfiltered loss: 16.098711013793945\n",
            "233/233 - 43s - loss: 17.6615 - val_loss: 11.9694 - lr: 8.4128e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.41e-04, weight decay: 4.20e-05\n",
            "Epoch 397/1500\n",
            "Val unfiltered loss: 15.933185577392578\n",
            "233/233 - 44s - loss: 17.5907 - val_loss: 11.7826 - lr: 8.4051e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.40e-04, weight decay: 4.20e-05\n",
            "Epoch 398/1500\n",
            "Val unfiltered loss: 16.506914138793945\n",
            "233/233 - 44s - loss: 17.5507 - val_loss: 12.2572 - lr: 8.3974e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.39e-04, weight decay: 4.19e-05\n",
            "Epoch 399/1500\n",
            "Val unfiltered loss: 16.19868278503418\n",
            "233/233 - 43s - loss: 17.4419 - val_loss: 11.8887 - lr: 8.3897e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.38e-04, weight decay: 4.19e-05\n",
            "Epoch 400/1500\n",
            "Val unfiltered loss: 16.343847274780273\n",
            "Val filtered lev distance: 0.8477306961818063\n",
            "Val unfiltered lev distance: 0.798075776249354\n",
            "Sub train lev distance: 0.9072995577352542\n",
            "233/233 - 115s - loss: 17.5194 - val_loss: 12.0116 - lr: 8.3819e-04 - 115s/epoch - 495ms/step\n",
            "learning rate: 8.37e-04, weight decay: 4.19e-05\n",
            "Epoch 401/1500\n",
            "Val unfiltered loss: 16.005739212036133\n",
            "233/233 - 44s - loss: 17.4897 - val_loss: 12.0387 - lr: 8.3742e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.37e-04, weight decay: 4.18e-05\n",
            "Epoch 402/1500\n",
            "Val unfiltered loss: 16.15684700012207\n",
            "233/233 - 44s - loss: 17.4964 - val_loss: 11.9744 - lr: 8.3664e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.36e-04, weight decay: 4.18e-05\n",
            "Epoch 403/1500\n",
            "Val unfiltered loss: 16.336015701293945\n",
            "233/233 - 45s - loss: 17.5180 - val_loss: 12.0564 - lr: 8.3586e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 8.35e-04, weight decay: 4.18e-05\n",
            "Epoch 404/1500\n",
            "Val unfiltered loss: 16.415233612060547\n",
            "233/233 - 44s - loss: 17.5353 - val_loss: 12.1046 - lr: 8.3509e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.34e-04, weight decay: 4.17e-05\n",
            "Epoch 405/1500\n",
            "Val unfiltered loss: 16.147945404052734\n",
            "233/233 - 44s - loss: 17.5352 - val_loss: 11.9642 - lr: 8.3430e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.34e-04, weight decay: 4.17e-05\n",
            "Epoch 406/1500\n",
            "Val unfiltered loss: 16.247047424316406\n",
            "233/233 - 44s - loss: 17.4891 - val_loss: 12.0106 - lr: 8.3352e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.33e-04, weight decay: 4.16e-05\n",
            "Epoch 407/1500\n",
            "Val unfiltered loss: 15.893036842346191\n",
            "233/233 - 43s - loss: 17.4559 - val_loss: 11.8867 - lr: 8.3274e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 8.32e-04, weight decay: 4.16e-05\n",
            "Epoch 408/1500\n",
            "Val unfiltered loss: 16.254745483398438\n",
            "233/233 - 44s - loss: 17.3513 - val_loss: 12.0257 - lr: 8.3195e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.31e-04, weight decay: 4.16e-05\n",
            "Epoch 409/1500\n",
            "Val unfiltered loss: 15.910533905029297\n",
            "233/233 - 44s - loss: 17.4588 - val_loss: 11.7263 - lr: 8.3117e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.30e-04, weight decay: 4.15e-05\n",
            "Epoch 410/1500\n",
            "Val unfiltered loss: 15.810141563415527\n",
            "233/233 - 45s - loss: 17.4126 - val_loss: 11.7644 - lr: 8.3038e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 8.30e-04, weight decay: 4.15e-05\n",
            "Epoch 411/1500\n",
            "Val unfiltered loss: 16.147050857543945\n",
            "233/233 - 43s - loss: 17.4269 - val_loss: 12.0380 - lr: 8.2959e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.29e-04, weight decay: 4.14e-05\n",
            "Epoch 412/1500\n",
            "Val unfiltered loss: 16.153593063354492\n",
            "233/233 - 44s - loss: 17.5304 - val_loss: 12.0034 - lr: 8.2880e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.28e-04, weight decay: 4.14e-05\n",
            "Epoch 413/1500\n",
            "Val unfiltered loss: 15.912195205688477\n",
            "233/233 - 44s - loss: 17.4974 - val_loss: 11.7742 - lr: 8.2801e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.27e-04, weight decay: 4.14e-05\n",
            "Epoch 414/1500\n",
            "Val unfiltered loss: 16.298307418823242\n",
            "233/233 - 44s - loss: 17.3986 - val_loss: 12.0299 - lr: 8.2721e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.26e-04, weight decay: 4.13e-05\n",
            "Epoch 415/1500\n",
            "Val unfiltered loss: 16.23346710205078\n",
            "233/233 - 44s - loss: 17.3601 - val_loss: 12.0942 - lr: 8.2642e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.26e-04, weight decay: 4.13e-05\n",
            "Epoch 416/1500\n",
            "Val unfiltered loss: 16.072471618652344\n",
            "233/233 - 44s - loss: 17.3003 - val_loss: 11.9131 - lr: 8.2562e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.25e-04, weight decay: 4.12e-05\n",
            "Epoch 417/1500\n",
            "Val unfiltered loss: 16.43756103515625\n",
            "233/233 - 44s - loss: 17.2785 - val_loss: 12.3043 - lr: 8.2482e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 8.24e-04, weight decay: 4.12e-05\n",
            "Epoch 418/1500\n",
            "Val unfiltered loss: 16.200212478637695\n",
            "233/233 - 44s - loss: 17.4069 - val_loss: 12.1083 - lr: 8.2402e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.23e-04, weight decay: 4.12e-05\n",
            "Epoch 419/1500\n",
            "Val unfiltered loss: 16.4027099609375\n",
            "233/233 - 44s - loss: 17.3068 - val_loss: 12.0974 - lr: 8.2322e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.22e-04, weight decay: 4.11e-05\n",
            "Epoch 420/1500\n",
            "Val unfiltered loss: 16.19025421142578\n",
            "233/233 - 43s - loss: 17.3119 - val_loss: 11.9829 - lr: 8.2242e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.22e-04, weight decay: 4.11e-05\n",
            "Epoch 421/1500\n",
            "Val unfiltered loss: 16.18756103515625\n",
            "233/233 - 43s - loss: 17.3302 - val_loss: 12.0823 - lr: 8.2162e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.21e-04, weight decay: 4.10e-05\n",
            "Epoch 422/1500\n",
            "Val unfiltered loss: 16.272689819335938\n",
            "233/233 - 44s - loss: 17.2765 - val_loss: 11.9634 - lr: 8.2081e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.20e-04, weight decay: 4.10e-05\n",
            "Epoch 423/1500\n",
            "Val unfiltered loss: 16.250133514404297\n",
            "233/233 - 44s - loss: 17.3381 - val_loss: 12.0883 - lr: 8.2001e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.19e-04, weight decay: 4.10e-05\n",
            "Epoch 424/1500\n",
            "Val unfiltered loss: 16.286996841430664\n",
            "233/233 - 45s - loss: 17.2553 - val_loss: 11.9841 - lr: 8.1920e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 8.18e-04, weight decay: 4.09e-05\n",
            "Epoch 425/1500\n",
            "Val unfiltered loss: 16.312341690063477\n",
            "233/233 - 44s - loss: 17.3428 - val_loss: 12.0979 - lr: 8.1839e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.18e-04, weight decay: 4.09e-05\n",
            "Epoch 426/1500\n",
            "Val unfiltered loss: 16.25296401977539\n",
            "233/233 - 44s - loss: 17.2041 - val_loss: 12.0909 - lr: 8.1758e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.17e-04, weight decay: 4.08e-05\n",
            "Epoch 427/1500\n",
            "Val unfiltered loss: 16.226343154907227\n",
            "233/233 - 43s - loss: 17.2624 - val_loss: 11.9712 - lr: 8.1676e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.16e-04, weight decay: 4.08e-05\n",
            "Epoch 428/1500\n",
            "Val unfiltered loss: 16.08213996887207\n",
            "233/233 - 44s - loss: 17.2260 - val_loss: 11.9346 - lr: 8.1595e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.15e-04, weight decay: 4.08e-05\n",
            "Epoch 429/1500\n",
            "Val unfiltered loss: 15.88092041015625\n",
            "233/233 - 44s - loss: 17.2753 - val_loss: 11.8122 - lr: 8.1514e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.14e-04, weight decay: 4.07e-05\n",
            "Epoch 430/1500\n",
            "Val unfiltered loss: 16.078556060791016\n",
            "233/233 - 44s - loss: 17.1944 - val_loss: 11.9326 - lr: 8.1432e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.14e-04, weight decay: 4.07e-05\n",
            "Epoch 431/1500\n",
            "Val unfiltered loss: 16.187240600585938\n",
            "233/233 - 44s - loss: 17.1600 - val_loss: 11.9617 - lr: 8.1350e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.13e-04, weight decay: 4.06e-05\n",
            "Epoch 432/1500\n",
            "Val unfiltered loss: 16.193103790283203\n",
            "233/233 - 45s - loss: 17.1256 - val_loss: 11.9906 - lr: 8.1268e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 8.12e-04, weight decay: 4.06e-05\n",
            "Epoch 433/1500\n",
            "Val unfiltered loss: 16.154796600341797\n",
            "233/233 - 44s - loss: 17.1498 - val_loss: 12.0705 - lr: 8.1186e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.11e-04, weight decay: 4.06e-05\n",
            "Epoch 434/1500\n",
            "Val unfiltered loss: 15.833365440368652\n",
            "233/233 - 43s - loss: 17.1186 - val_loss: 11.7604 - lr: 8.1104e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 8.10e-04, weight decay: 4.05e-05\n",
            "Epoch 435/1500\n",
            "Val unfiltered loss: 16.12786102294922\n",
            "233/233 - 43s - loss: 17.0246 - val_loss: 12.0424 - lr: 8.1022e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.09e-04, weight decay: 4.05e-05\n",
            "Epoch 436/1500\n",
            "Val unfiltered loss: 16.570106506347656\n",
            "233/233 - 44s - loss: 17.0519 - val_loss: 12.2596 - lr: 8.0939e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.09e-04, weight decay: 4.04e-05\n",
            "Epoch 437/1500\n",
            "Val unfiltered loss: 16.2298526763916\n",
            "233/233 - 43s - loss: 17.1663 - val_loss: 11.9973 - lr: 8.0857e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.08e-04, weight decay: 4.04e-05\n",
            "Epoch 438/1500\n",
            "Val unfiltered loss: 16.52202606201172\n",
            "233/233 - 43s - loss: 17.1064 - val_loss: 12.2503 - lr: 8.0774e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.07e-04, weight decay: 4.03e-05\n",
            "Epoch 439/1500\n",
            "Val unfiltered loss: 16.361473083496094\n",
            "233/233 - 45s - loss: 17.0614 - val_loss: 12.0055 - lr: 8.0691e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 8.06e-04, weight decay: 4.03e-05\n",
            "Epoch 440/1500\n",
            "Val unfiltered loss: 16.3033390045166\n",
            "233/233 - 44s - loss: 17.0283 - val_loss: 12.0602 - lr: 8.0608e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.05e-04, weight decay: 4.03e-05\n",
            "Epoch 441/1500\n",
            "Val unfiltered loss: 16.34052276611328\n",
            "233/233 - 43s - loss: 17.1035 - val_loss: 12.1728 - lr: 8.0525e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.04e-04, weight decay: 4.02e-05\n",
            "Epoch 442/1500\n",
            "Val unfiltered loss: 16.452360153198242\n",
            "233/233 - 43s - loss: 17.0883 - val_loss: 12.0788 - lr: 8.0442e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.04e-04, weight decay: 4.02e-05\n",
            "Epoch 443/1500\n",
            "Val unfiltered loss: 16.553936004638672\n",
            "233/233 - 44s - loss: 17.0326 - val_loss: 12.2746 - lr: 8.0358e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.03e-04, weight decay: 4.01e-05\n",
            "Epoch 444/1500\n",
            "Val unfiltered loss: 16.341686248779297\n",
            "233/233 - 43s - loss: 17.0519 - val_loss: 12.1902 - lr: 8.0275e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.02e-04, weight decay: 4.01e-05\n",
            "Epoch 445/1500\n",
            "Val unfiltered loss: 16.200864791870117\n",
            "233/233 - 43s - loss: 17.0869 - val_loss: 12.0226 - lr: 8.0191e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.01e-04, weight decay: 4.01e-05\n",
            "Epoch 446/1500\n",
            "Val unfiltered loss: 16.130908966064453\n",
            "233/233 - 45s - loss: 16.9324 - val_loss: 11.9995 - lr: 8.0107e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 8.00e-04, weight decay: 4.00e-05\n",
            "Epoch 447/1500\n",
            "Val unfiltered loss: 16.474424362182617\n",
            "233/233 - 44s - loss: 16.9408 - val_loss: 12.0810 - lr: 8.0023e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.99e-04, weight decay: 4.00e-05\n",
            "Epoch 448/1500\n",
            "Val unfiltered loss: 16.364242553710938\n",
            "233/233 - 44s - loss: 17.0419 - val_loss: 12.0739 - lr: 7.9939e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.99e-04, weight decay: 3.99e-05\n",
            "Epoch 449/1500\n",
            "Val unfiltered loss: 16.549699783325195\n",
            "233/233 - 43s - loss: 17.0064 - val_loss: 12.2952 - lr: 7.9855e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.98e-04, weight decay: 3.99e-05\n",
            "Epoch 450/1500\n",
            "Val unfiltered loss: 16.372695922851562\n",
            "Val filtered lev distance: 0.8482328028467265\n",
            "Val unfiltered lev distance: 0.8002425158032839\n",
            "Sub train lev distance: 0.9142619433375663\n",
            "233/233 - 118s - loss: 17.0278 - val_loss: 11.9710 - lr: 7.9770e-04 - 118s/epoch - 507ms/step\n",
            "learning rate: 7.97e-04, weight decay: 3.98e-05\n",
            "Epoch 451/1500\n",
            "Val unfiltered loss: 16.195341110229492\n",
            "233/233 - 44s - loss: 16.9751 - val_loss: 11.9517 - lr: 7.9686e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.96e-04, weight decay: 3.98e-05\n",
            "Epoch 452/1500\n",
            "Val unfiltered loss: 16.58395004272461\n",
            "233/233 - 43s - loss: 17.0310 - val_loss: 12.2974 - lr: 7.9601e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.95e-04, weight decay: 3.98e-05\n",
            "Epoch 453/1500\n",
            "Val unfiltered loss: 16.57988166809082\n",
            "233/233 - 44s - loss: 17.1192 - val_loss: 12.1974 - lr: 7.9517e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.94e-04, weight decay: 3.97e-05\n",
            "Epoch 454/1500\n",
            "Val unfiltered loss: 16.336530685424805\n",
            "233/233 - 45s - loss: 16.9756 - val_loss: 12.0588 - lr: 7.9432e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 7.93e-04, weight decay: 3.97e-05\n",
            "Epoch 455/1500\n",
            "Val unfiltered loss: 16.291221618652344\n",
            "233/233 - 43s - loss: 16.9143 - val_loss: 11.9644 - lr: 7.9347e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.93e-04, weight decay: 3.96e-05\n",
            "Epoch 456/1500\n",
            "Val unfiltered loss: 16.642539978027344\n",
            "233/233 - 44s - loss: 16.9526 - val_loss: 12.3244 - lr: 7.9262e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.92e-04, weight decay: 3.96e-05\n",
            "Epoch 457/1500\n",
            "Val unfiltered loss: 16.337230682373047\n",
            "233/233 - 44s - loss: 16.8914 - val_loss: 12.0275 - lr: 7.9176e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.91e-04, weight decay: 3.95e-05\n",
            "Epoch 458/1500\n",
            "Val unfiltered loss: 16.432971954345703\n",
            "233/233 - 44s - loss: 16.9066 - val_loss: 12.1886 - lr: 7.9091e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.90e-04, weight decay: 3.95e-05\n",
            "Epoch 459/1500\n",
            "Val unfiltered loss: 16.461254119873047\n",
            "233/233 - 43s - loss: 16.9002 - val_loss: 12.1569 - lr: 7.9005e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 7.89e-04, weight decay: 3.95e-05\n",
            "Epoch 460/1500\n",
            "Val unfiltered loss: 16.383371353149414\n",
            "233/233 - 44s - loss: 16.8676 - val_loss: 12.1451 - lr: 7.8920e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.88e-04, weight decay: 3.94e-05\n",
            "Epoch 461/1500\n",
            "Val unfiltered loss: 16.49348258972168\n",
            "233/233 - 45s - loss: 16.8650 - val_loss: 12.1941 - lr: 7.8834e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 7.87e-04, weight decay: 3.94e-05\n",
            "Epoch 462/1500\n",
            "Val unfiltered loss: 16.50718879699707\n",
            "233/233 - 44s - loss: 16.8739 - val_loss: 12.1654 - lr: 7.8748e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.87e-04, weight decay: 3.93e-05\n",
            "Epoch 463/1500\n",
            "Val unfiltered loss: 16.566682815551758\n",
            "233/233 - 44s - loss: 16.8295 - val_loss: 12.2231 - lr: 7.8662e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.86e-04, weight decay: 3.93e-05\n",
            "Epoch 464/1500\n",
            "Val unfiltered loss: 16.704675674438477\n",
            "233/233 - 44s - loss: 16.8206 - val_loss: 12.3277 - lr: 7.8576e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.85e-04, weight decay: 3.92e-05\n",
            "Epoch 465/1500\n",
            "Val unfiltered loss: 16.575279235839844\n",
            "233/233 - 43s - loss: 16.8647 - val_loss: 12.3413 - lr: 7.8490e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.84e-04, weight decay: 3.92e-05\n",
            "Epoch 466/1500\n",
            "Val unfiltered loss: 16.37716293334961\n",
            "233/233 - 43s - loss: 16.8040 - val_loss: 12.2922 - lr: 7.8403e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.83e-04, weight decay: 3.92e-05\n",
            "Epoch 467/1500\n",
            "Val unfiltered loss: 16.306255340576172\n",
            "233/233 - 44s - loss: 16.8770 - val_loss: 12.1735 - lr: 7.8317e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.82e-04, weight decay: 3.91e-05\n",
            "Epoch 468/1500\n",
            "Val unfiltered loss: 16.603761672973633\n",
            "233/233 - 44s - loss: 16.7488 - val_loss: 12.4224 - lr: 7.8230e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 7.81e-04, weight decay: 3.91e-05\n",
            "Epoch 469/1500\n",
            "Val unfiltered loss: 16.36577796936035\n",
            "233/233 - 43s - loss: 16.7460 - val_loss: 12.3238 - lr: 7.8143e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.81e-04, weight decay: 3.90e-05\n",
            "Epoch 470/1500\n",
            "Val unfiltered loss: 16.470840454101562\n",
            "233/233 - 44s - loss: 16.7805 - val_loss: 12.3384 - lr: 7.8056e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.80e-04, weight decay: 3.90e-05\n",
            "Epoch 471/1500\n",
            "Val unfiltered loss: 16.64118194580078\n",
            "233/233 - 44s - loss: 16.7303 - val_loss: 12.4610 - lr: 7.7969e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.79e-04, weight decay: 3.89e-05\n",
            "Epoch 472/1500\n",
            "Val unfiltered loss: 16.350858688354492\n",
            "233/233 - 43s - loss: 16.7779 - val_loss: 12.1564 - lr: 7.7882e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 7.78e-04, weight decay: 3.89e-05\n",
            "Epoch 473/1500\n",
            "Val unfiltered loss: 16.388776779174805\n",
            "233/233 - 44s - loss: 16.8092 - val_loss: 12.2350 - lr: 7.7795e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.77e-04, weight decay: 3.89e-05\n",
            "Epoch 474/1500\n",
            "Val unfiltered loss: 16.41853141784668\n",
            "233/233 - 44s - loss: 16.7328 - val_loss: 12.2047 - lr: 7.7707e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.76e-04, weight decay: 3.88e-05\n",
            "Epoch 475/1500\n",
            "Val unfiltered loss: 16.319692611694336\n",
            "233/233 - 43s - loss: 16.8413 - val_loss: 12.0349 - lr: 7.7620e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.75e-04, weight decay: 3.88e-05\n",
            "Epoch 476/1500\n",
            "Val unfiltered loss: 16.115726470947266\n",
            "233/233 - 45s - loss: 16.6911 - val_loss: 11.9826 - lr: 7.7532e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 7.74e-04, weight decay: 3.87e-05\n",
            "Epoch 477/1500\n",
            "Val unfiltered loss: 16.357370376586914\n",
            "233/233 - 44s - loss: 16.6676 - val_loss: 12.0995 - lr: 7.7445e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.74e-04, weight decay: 3.87e-05\n",
            "Epoch 478/1500\n",
            "Val unfiltered loss: 16.603961944580078\n",
            "233/233 - 44s - loss: 16.6367 - val_loss: 12.3694 - lr: 7.7357e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.73e-04, weight decay: 3.86e-05\n",
            "Epoch 479/1500\n",
            "Val unfiltered loss: 16.577695846557617\n",
            "233/233 - 44s - loss: 16.6203 - val_loss: 12.2846 - lr: 7.7269e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.72e-04, weight decay: 3.86e-05\n",
            "Epoch 480/1500\n",
            "Val unfiltered loss: 16.198028564453125\n",
            "233/233 - 44s - loss: 16.8444 - val_loss: 12.0493 - lr: 7.7181e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.71e-04, weight decay: 3.85e-05\n",
            "Epoch 481/1500\n",
            "Val unfiltered loss: 16.317363739013672\n",
            "233/233 - 44s - loss: 16.7451 - val_loss: 12.0721 - lr: 7.7092e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.70e-04, weight decay: 3.85e-05\n",
            "Epoch 482/1500\n",
            "Val unfiltered loss: 16.444252014160156\n",
            "233/233 - 43s - loss: 16.6018 - val_loss: 12.0602 - lr: 7.7004e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 7.69e-04, weight decay: 3.85e-05\n",
            "Epoch 483/1500\n",
            "Val unfiltered loss: 16.6920166015625\n",
            "233/233 - 45s - loss: 16.5665 - val_loss: 12.2180 - lr: 7.6915e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 7.68e-04, weight decay: 3.84e-05\n",
            "Epoch 484/1500\n",
            "Val unfiltered loss: 16.341169357299805\n",
            "233/233 - 44s - loss: 16.6188 - val_loss: 11.9490 - lr: 7.6827e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.67e-04, weight decay: 3.84e-05\n",
            "Epoch 485/1500\n",
            "Val unfiltered loss: 16.650991439819336\n",
            "233/233 - 44s - loss: 16.5691 - val_loss: 12.1608 - lr: 7.6738e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.66e-04, weight decay: 3.83e-05\n",
            "Epoch 486/1500\n",
            "Val unfiltered loss: 16.68885040283203\n",
            "233/233 - 43s - loss: 16.5130 - val_loss: 12.1691 - lr: 7.6649e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.66e-04, weight decay: 3.83e-05\n",
            "Epoch 487/1500\n",
            "Val unfiltered loss: 16.7001953125\n",
            "233/233 - 44s - loss: 16.5508 - val_loss: 12.4336 - lr: 7.6560e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.65e-04, weight decay: 3.82e-05\n",
            "Epoch 488/1500\n",
            "Val unfiltered loss: 16.81679344177246\n",
            "233/233 - 44s - loss: 16.5778 - val_loss: 12.3747 - lr: 7.6471e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.64e-04, weight decay: 3.82e-05\n",
            "Epoch 489/1500\n",
            "Val unfiltered loss: 16.786039352416992\n",
            "233/233 - 43s - loss: 16.5840 - val_loss: 12.6124 - lr: 7.6382e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.63e-04, weight decay: 3.81e-05\n",
            "Epoch 490/1500\n",
            "Val unfiltered loss: 16.872276306152344\n",
            "233/233 - 45s - loss: 16.6220 - val_loss: 12.4503 - lr: 7.6293e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 7.62e-04, weight decay: 3.81e-05\n",
            "Epoch 491/1500\n",
            "Val unfiltered loss: 17.305522918701172\n",
            "233/233 - 44s - loss: 16.5530 - val_loss: 12.6818 - lr: 7.6203e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.61e-04, weight decay: 3.81e-05\n",
            "Epoch 492/1500\n",
            "Val unfiltered loss: 16.92693328857422\n",
            "233/233 - 44s - loss: 16.5171 - val_loss: 12.5210 - lr: 7.6114e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.60e-04, weight decay: 3.80e-05\n",
            "Epoch 493/1500\n",
            "Val unfiltered loss: 16.14600944519043\n",
            "233/233 - 44s - loss: 16.5111 - val_loss: 12.0042 - lr: 7.6024e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.59e-04, weight decay: 3.80e-05\n",
            "Epoch 494/1500\n",
            "Val unfiltered loss: 16.668424606323242\n",
            "233/233 - 44s - loss: 16.5031 - val_loss: 12.1058 - lr: 7.5934e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.58e-04, weight decay: 3.79e-05\n",
            "Epoch 495/1500\n",
            "Val unfiltered loss: 16.54480743408203\n",
            "233/233 - 44s - loss: 16.5267 - val_loss: 12.1789 - lr: 7.5844e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.58e-04, weight decay: 3.79e-05\n",
            "Epoch 496/1500\n",
            "Val unfiltered loss: 16.56196403503418\n",
            "233/233 - 44s - loss: 16.5083 - val_loss: 12.4413 - lr: 7.5754e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.57e-04, weight decay: 3.78e-05\n",
            "Epoch 497/1500\n",
            "Val unfiltered loss: 16.576013565063477\n",
            "233/233 - 45s - loss: 16.4472 - val_loss: 12.2163 - lr: 7.5664e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 7.56e-04, weight decay: 3.78e-05\n",
            "Epoch 498/1500\n",
            "Val unfiltered loss: 16.827238082885742\n",
            "233/233 - 44s - loss: 16.4055 - val_loss: 12.4579 - lr: 7.5574e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.55e-04, weight decay: 3.77e-05\n",
            "Epoch 499/1500\n",
            "Val unfiltered loss: 16.37460708618164\n",
            "233/233 - 43s - loss: 16.5171 - val_loss: 12.1826 - lr: 7.5484e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 7.54e-04, weight decay: 3.77e-05\n",
            "Epoch 500/1500\n",
            "Val unfiltered loss: 16.618009567260742\n",
            "Val filtered lev distance: 0.8509179819678215\n",
            "Val unfiltered lev distance: 0.8022701069454936\n",
            "Sub train lev distance: 0.9226474580724263\n",
            "233/233 - 117s - loss: 16.4245 - val_loss: 12.5388 - lr: 7.5393e-04 - 117s/epoch - 501ms/step\n",
            "learning rate: 7.53e-04, weight decay: 3.77e-05\n",
            "Epoch 501/1500\n",
            "Val unfiltered loss: 16.57652473449707\n",
            "233/233 - 44s - loss: 16.4877 - val_loss: 12.2489 - lr: 7.5303e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.52e-04, weight decay: 3.76e-05\n",
            "Epoch 502/1500\n",
            "Val unfiltered loss: 16.652372360229492\n",
            "233/233 - 44s - loss: 16.3836 - val_loss: 12.2909 - lr: 7.5212e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.51e-04, weight decay: 3.76e-05\n",
            "Epoch 503/1500\n",
            "Val unfiltered loss: 16.475811004638672\n",
            "233/233 - 43s - loss: 16.4176 - val_loss: 12.3200 - lr: 7.5121e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.50e-04, weight decay: 3.75e-05\n",
            "Epoch 504/1500\n",
            "Val unfiltered loss: 16.553932189941406\n",
            "233/233 - 43s - loss: 16.3880 - val_loss: 12.3784 - lr: 7.5030e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.49e-04, weight decay: 3.75e-05\n",
            "Epoch 505/1500\n",
            "Val unfiltered loss: 16.35483169555664\n",
            "233/233 - 45s - loss: 16.4396 - val_loss: 12.1389 - lr: 7.4939e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 7.48e-04, weight decay: 3.74e-05\n",
            "Epoch 506/1500\n",
            "Val unfiltered loss: 16.153234481811523\n",
            "233/233 - 43s - loss: 16.4610 - val_loss: 12.0571 - lr: 7.4848e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.48e-04, weight decay: 3.74e-05\n",
            "Epoch 507/1500\n",
            "Val unfiltered loss: 16.42501449584961\n",
            "233/233 - 44s - loss: 16.4082 - val_loss: 12.1819 - lr: 7.4757e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.47e-04, weight decay: 3.73e-05\n",
            "Epoch 508/1500\n",
            "Val unfiltered loss: 16.5855655670166\n",
            "233/233 - 44s - loss: 16.3988 - val_loss: 12.2371 - lr: 7.4666e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.46e-04, weight decay: 3.73e-05\n",
            "Epoch 509/1500\n",
            "Val unfiltered loss: 16.57866859436035\n",
            "233/233 - 44s - loss: 16.3717 - val_loss: 12.1676 - lr: 7.4574e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.45e-04, weight decay: 3.72e-05\n",
            "Epoch 510/1500\n",
            "Val unfiltered loss: 16.492300033569336\n",
            "233/233 - 44s - loss: 16.2697 - val_loss: 12.0812 - lr: 7.4483e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.44e-04, weight decay: 3.72e-05\n",
            "Epoch 511/1500\n",
            "Val unfiltered loss: 16.729522705078125\n",
            "233/233 - 44s - loss: 16.2726 - val_loss: 12.4541 - lr: 7.4391e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.43e-04, weight decay: 3.71e-05\n",
            "Epoch 512/1500\n",
            "Val unfiltered loss: 16.59844970703125\n",
            "233/233 - 44s - loss: 16.2325 - val_loss: 12.2801 - lr: 7.4299e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.42e-04, weight decay: 3.71e-05\n",
            "Epoch 513/1500\n",
            "Val unfiltered loss: 17.334487915039062\n",
            "233/233 - 44s - loss: 16.2202 - val_loss: 12.7864 - lr: 7.4207e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.41e-04, weight decay: 3.71e-05\n",
            "Epoch 514/1500\n",
            "Val unfiltered loss: 17.070817947387695\n",
            "233/233 - 43s - loss: 16.3137 - val_loss: 12.5660 - lr: 7.4115e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 7.40e-04, weight decay: 3.70e-05\n",
            "Epoch 515/1500\n",
            "Val unfiltered loss: 16.750648498535156\n",
            "233/233 - 44s - loss: 16.2920 - val_loss: 12.3277 - lr: 7.4023e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 7.39e-04, weight decay: 3.70e-05\n",
            "Epoch 516/1500\n",
            "Val unfiltered loss: 16.61026382446289\n",
            "233/233 - 44s - loss: 16.2752 - val_loss: 12.2888 - lr: 7.3931e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.38e-04, weight decay: 3.69e-05\n",
            "Epoch 517/1500\n",
            "Val unfiltered loss: 16.881853103637695\n",
            "233/233 - 44s - loss: 16.2485 - val_loss: 12.1977 - lr: 7.3839e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.37e-04, weight decay: 3.69e-05\n",
            "Epoch 518/1500\n",
            "Val unfiltered loss: 16.84404945373535\n",
            "233/233 - 44s - loss: 16.2523 - val_loss: 12.3946 - lr: 7.3746e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.37e-04, weight decay: 3.68e-05\n",
            "Epoch 519/1500\n",
            "Val unfiltered loss: 17.065269470214844\n",
            "233/233 - 44s - loss: 16.2910 - val_loss: 12.5837 - lr: 7.3654e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.36e-04, weight decay: 3.68e-05\n",
            "Epoch 520/1500\n",
            "Val unfiltered loss: 16.558292388916016\n",
            "233/233 - 45s - loss: 16.3665 - val_loss: 12.1641 - lr: 7.3561e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 7.35e-04, weight decay: 3.67e-05\n",
            "Epoch 521/1500\n",
            "Val unfiltered loss: 16.789888381958008\n",
            "233/233 - 44s - loss: 16.2878 - val_loss: 12.5218 - lr: 7.3468e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.34e-04, weight decay: 3.67e-05\n",
            "Epoch 522/1500\n",
            "Val unfiltered loss: 16.626983642578125\n",
            "233/233 - 44s - loss: 16.2199 - val_loss: 12.1966 - lr: 7.3376e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 7.33e-04, weight decay: 3.66e-05\n",
            "Epoch 523/1500\n",
            "Val unfiltered loss: 16.94658088684082\n",
            "233/233 - 44s - loss: 16.2312 - val_loss: 12.4578 - lr: 7.3283e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.32e-04, weight decay: 3.66e-05\n",
            "Epoch 524/1500\n",
            "Val unfiltered loss: 17.04722785949707\n",
            "233/233 - 44s - loss: 16.2001 - val_loss: 12.4794 - lr: 7.3190e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.31e-04, weight decay: 3.65e-05\n",
            "Epoch 525/1500\n",
            "Val unfiltered loss: 16.872312545776367\n",
            "233/233 - 44s - loss: 16.2965 - val_loss: 12.4285 - lr: 7.3096e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.30e-04, weight decay: 3.65e-05\n",
            "Epoch 526/1500\n",
            "Val unfiltered loss: 16.80640411376953\n",
            "233/233 - 44s - loss: 16.2635 - val_loss: 12.5658 - lr: 7.3003e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.29e-04, weight decay: 3.65e-05\n",
            "Epoch 527/1500\n",
            "Val unfiltered loss: 16.600873947143555\n",
            "233/233 - 46s - loss: 16.2247 - val_loss: 12.2131 - lr: 7.2910e-04 - 46s/epoch - 195ms/step\n",
            "learning rate: 7.28e-04, weight decay: 3.64e-05\n",
            "Epoch 528/1500\n",
            "Val unfiltered loss: 16.49726676940918\n",
            "233/233 - 44s - loss: 16.2117 - val_loss: 12.3360 - lr: 7.2816e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.27e-04, weight decay: 3.64e-05\n",
            "Epoch 529/1500\n",
            "Val unfiltered loss: 16.723461151123047\n",
            "233/233 - 44s - loss: 16.1418 - val_loss: 12.3268 - lr: 7.2723e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.26e-04, weight decay: 3.63e-05\n",
            "Epoch 530/1500\n",
            "Val unfiltered loss: 16.587024688720703\n",
            "233/233 - 44s - loss: 16.1362 - val_loss: 12.2510 - lr: 7.2629e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.25e-04, weight decay: 3.63e-05\n",
            "Epoch 531/1500\n",
            "Val unfiltered loss: 16.780611038208008\n",
            "233/233 - 44s - loss: 16.1742 - val_loss: 12.3663 - lr: 7.2536e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 7.24e-04, weight decay: 3.62e-05\n",
            "Epoch 532/1500\n",
            "Val unfiltered loss: 16.482563018798828\n",
            "233/233 - 44s - loss: 16.1222 - val_loss: 12.2502 - lr: 7.2442e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.23e-04, weight decay: 3.62e-05\n",
            "Epoch 533/1500\n",
            "Val unfiltered loss: 16.71693992614746\n",
            "233/233 - 44s - loss: 16.0504 - val_loss: 12.4462 - lr: 7.2348e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.23e-04, weight decay: 3.61e-05\n",
            "Epoch 534/1500\n",
            "Val unfiltered loss: 16.97759246826172\n",
            "233/233 - 46s - loss: 16.1177 - val_loss: 12.5018 - lr: 7.2254e-04 - 46s/epoch - 195ms/step\n",
            "learning rate: 7.22e-04, weight decay: 3.61e-05\n",
            "Epoch 535/1500\n",
            "Val unfiltered loss: 16.6669921875\n",
            "233/233 - 44s - loss: 16.1012 - val_loss: 12.2374 - lr: 7.2160e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.21e-04, weight decay: 3.60e-05\n",
            "Epoch 536/1500\n",
            "Val unfiltered loss: 16.954681396484375\n",
            "233/233 - 44s - loss: 16.0778 - val_loss: 12.4729 - lr: 7.2065e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.20e-04, weight decay: 3.60e-05\n",
            "Epoch 537/1500\n",
            "Val unfiltered loss: 16.768970489501953\n",
            "233/233 - 44s - loss: 16.1607 - val_loss: 12.4291 - lr: 7.1971e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.19e-04, weight decay: 3.59e-05\n",
            "Epoch 538/1500\n",
            "Val unfiltered loss: 17.147241592407227\n",
            "233/233 - 44s - loss: 16.0697 - val_loss: 12.7490 - lr: 7.1877e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.18e-04, weight decay: 3.59e-05\n",
            "Epoch 539/1500\n",
            "Val unfiltered loss: 16.818092346191406\n",
            "233/233 - 44s - loss: 16.1061 - val_loss: 12.3140 - lr: 7.1782e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.17e-04, weight decay: 3.58e-05\n",
            "Epoch 540/1500\n",
            "Val unfiltered loss: 16.934797286987305\n",
            "233/233 - 44s - loss: 16.1067 - val_loss: 12.5991 - lr: 7.1687e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.16e-04, weight decay: 3.58e-05\n",
            "Epoch 541/1500\n",
            "Val unfiltered loss: 16.654218673706055\n",
            "233/233 - 44s - loss: 16.0923 - val_loss: 12.4844 - lr: 7.1593e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.15e-04, weight decay: 3.57e-05\n",
            "Epoch 542/1500\n",
            "Val unfiltered loss: 16.725263595581055\n",
            "233/233 - 45s - loss: 16.0656 - val_loss: 12.5271 - lr: 7.1498e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 7.14e-04, weight decay: 3.57e-05\n",
            "Epoch 543/1500\n",
            "Val unfiltered loss: 16.51811408996582\n",
            "233/233 - 44s - loss: 16.0051 - val_loss: 12.3543 - lr: 7.1403e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.13e-04, weight decay: 3.57e-05\n",
            "Epoch 544/1500\n",
            "Val unfiltered loss: 17.185504913330078\n",
            "233/233 - 44s - loss: 16.0475 - val_loss: 12.6138 - lr: 7.1308e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.12e-04, weight decay: 3.56e-05\n",
            "Epoch 545/1500\n",
            "Val unfiltered loss: 16.881103515625\n",
            "233/233 - 44s - loss: 15.9962 - val_loss: 12.4217 - lr: 7.1213e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.11e-04, weight decay: 3.56e-05\n",
            "Epoch 546/1500\n",
            "Val unfiltered loss: 17.391143798828125\n",
            "233/233 - 44s - loss: 15.9430 - val_loss: 12.9582 - lr: 7.1118e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.10e-04, weight decay: 3.55e-05\n",
            "Epoch 547/1500\n",
            "Val unfiltered loss: 16.63873863220215\n",
            "233/233 - 44s - loss: 16.0212 - val_loss: 12.2999 - lr: 7.1022e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.09e-04, weight decay: 3.55e-05\n",
            "Epoch 548/1500\n",
            "Val unfiltered loss: 16.929487228393555\n",
            "233/233 - 44s - loss: 15.9603 - val_loss: 12.4720 - lr: 7.0927e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.08e-04, weight decay: 3.54e-05\n",
            "Epoch 549/1500\n",
            "Val unfiltered loss: 16.85045051574707\n",
            "233/233 - 45s - loss: 15.9703 - val_loss: 12.4535 - lr: 7.0832e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 7.07e-04, weight decay: 3.54e-05\n",
            "Epoch 550/1500\n",
            "Val unfiltered loss: 16.66330909729004\n",
            "Val filtered lev distance: 0.8543017442748925\n",
            "Val unfiltered lev distance: 0.804754900011927\n",
            "Sub train lev distance: 0.9299382580899418\n",
            "233/233 - 120s - loss: 15.9728 - val_loss: 12.2257 - lr: 7.0736e-04 - 120s/epoch - 516ms/step\n",
            "learning rate: 7.06e-04, weight decay: 3.53e-05\n",
            "Epoch 551/1500\n",
            "Val unfiltered loss: 16.64301872253418\n",
            "233/233 - 44s - loss: 16.0101 - val_loss: 12.2915 - lr: 7.0640e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.05e-04, weight decay: 3.53e-05\n",
            "Epoch 552/1500\n",
            "Val unfiltered loss: 16.780010223388672\n",
            "233/233 - 44s - loss: 15.9120 - val_loss: 12.3911 - lr: 7.0545e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.04e-04, weight decay: 3.52e-05\n",
            "Epoch 553/1500\n",
            "Val unfiltered loss: 16.700666427612305\n",
            "233/233 - 44s - loss: 15.9111 - val_loss: 12.2692 - lr: 7.0449e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.04e-04, weight decay: 3.52e-05\n",
            "Epoch 554/1500\n",
            "Val unfiltered loss: 16.723283767700195\n",
            "233/233 - 43s - loss: 16.0018 - val_loss: 12.3029 - lr: 7.0353e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.03e-04, weight decay: 3.51e-05\n",
            "Epoch 555/1500\n",
            "Val unfiltered loss: 16.70018196105957\n",
            "233/233 - 43s - loss: 15.9187 - val_loss: 12.2706 - lr: 7.0257e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 7.02e-04, weight decay: 3.51e-05\n",
            "Epoch 556/1500\n",
            "Val unfiltered loss: 16.70952033996582\n",
            "233/233 - 44s - loss: 15.8744 - val_loss: 12.3253 - lr: 7.0161e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.01e-04, weight decay: 3.50e-05\n",
            "Epoch 557/1500\n",
            "Val unfiltered loss: 17.131200790405273\n",
            "233/233 - 44s - loss: 15.9125 - val_loss: 12.5982 - lr: 7.0065e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.00e-04, weight decay: 3.50e-05\n",
            "Epoch 558/1500\n",
            "Val unfiltered loss: 16.763019561767578\n",
            "233/233 - 45s - loss: 16.0252 - val_loss: 12.3221 - lr: 6.9968e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 6.99e-04, weight decay: 3.49e-05\n",
            "Epoch 559/1500\n",
            "Val unfiltered loss: 16.978899002075195\n",
            "233/233 - 44s - loss: 16.0406 - val_loss: 12.4186 - lr: 6.9872e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.98e-04, weight decay: 3.49e-05\n",
            "Epoch 560/1500\n",
            "Val unfiltered loss: 16.9957332611084\n",
            "233/233 - 44s - loss: 15.9362 - val_loss: 12.3935 - lr: 6.9775e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.97e-04, weight decay: 3.48e-05\n",
            "Epoch 561/1500\n",
            "Val unfiltered loss: 17.211694717407227\n",
            "233/233 - 44s - loss: 15.9785 - val_loss: 12.5245 - lr: 6.9679e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.96e-04, weight decay: 3.48e-05\n",
            "Epoch 562/1500\n",
            "Val unfiltered loss: 16.649017333984375\n",
            "233/233 - 43s - loss: 15.9644 - val_loss: 12.3072 - lr: 6.9582e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 6.95e-04, weight decay: 3.47e-05\n",
            "Epoch 563/1500\n",
            "Val unfiltered loss: 17.146484375\n",
            "233/233 - 44s - loss: 15.9479 - val_loss: 12.5111 - lr: 6.9485e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.94e-04, weight decay: 3.47e-05\n",
            "Epoch 564/1500\n",
            "Val unfiltered loss: 17.438251495361328\n",
            "233/233 - 44s - loss: 15.9269 - val_loss: 12.6023 - lr: 6.9389e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.93e-04, weight decay: 3.46e-05\n",
            "Epoch 565/1500\n",
            "Val unfiltered loss: 17.02764129638672\n",
            "233/233 - 45s - loss: 15.8778 - val_loss: 12.3760 - lr: 6.9292e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 6.92e-04, weight decay: 3.46e-05\n",
            "Epoch 566/1500\n",
            "Val unfiltered loss: 17.11488151550293\n",
            "233/233 - 44s - loss: 15.7431 - val_loss: 12.5887 - lr: 6.9195e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.91e-04, weight decay: 3.45e-05\n",
            "Epoch 567/1500\n",
            "Val unfiltered loss: 17.11603546142578\n",
            "233/233 - 44s - loss: 15.9031 - val_loss: 12.5269 - lr: 6.9098e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.90e-04, weight decay: 3.45e-05\n",
            "Epoch 568/1500\n",
            "Val unfiltered loss: 17.49407196044922\n",
            "233/233 - 44s - loss: 15.8332 - val_loss: 12.6509 - lr: 6.9001e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.89e-04, weight decay: 3.45e-05\n",
            "Epoch 569/1500\n",
            "Val unfiltered loss: 17.32561492919922\n",
            "233/233 - 44s - loss: 15.7940 - val_loss: 12.7476 - lr: 6.8903e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.88e-04, weight decay: 3.44e-05\n",
            "Epoch 570/1500\n",
            "Val unfiltered loss: 16.95258331298828\n",
            "233/233 - 44s - loss: 15.7514 - val_loss: 12.5000 - lr: 6.8806e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.87e-04, weight decay: 3.44e-05\n",
            "Epoch 571/1500\n",
            "Val unfiltered loss: 17.085844039916992\n",
            "233/233 - 44s - loss: 15.7770 - val_loss: 12.5314 - lr: 6.8709e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.86e-04, weight decay: 3.43e-05\n",
            "Epoch 572/1500\n",
            "Val unfiltered loss: 17.04851531982422\n",
            "233/233 - 45s - loss: 15.6970 - val_loss: 12.4866 - lr: 6.8611e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 6.85e-04, weight decay: 3.43e-05\n",
            "Epoch 573/1500\n",
            "Val unfiltered loss: 17.358238220214844\n",
            "233/233 - 44s - loss: 15.7104 - val_loss: 12.5735 - lr: 6.8514e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.84e-04, weight decay: 3.42e-05\n",
            "Epoch 574/1500\n",
            "Val unfiltered loss: 17.087125778198242\n",
            "233/233 - 44s - loss: 15.7485 - val_loss: 12.6826 - lr: 6.8416e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.83e-04, weight decay: 3.42e-05\n",
            "Epoch 575/1500\n",
            "Val unfiltered loss: 17.0822811126709\n",
            "233/233 - 44s - loss: 15.6472 - val_loss: 12.5004 - lr: 6.8318e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.82e-04, weight decay: 3.41e-05\n",
            "Epoch 576/1500\n",
            "Val unfiltered loss: 17.177806854248047\n",
            "233/233 - 44s - loss: 15.8015 - val_loss: 12.6187 - lr: 6.8220e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.81e-04, weight decay: 3.41e-05\n",
            "Epoch 577/1500\n",
            "Val unfiltered loss: 17.042043685913086\n",
            "233/233 - 44s - loss: 15.6904 - val_loss: 12.6980 - lr: 6.8123e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.80e-04, weight decay: 3.40e-05\n",
            "Epoch 578/1500\n",
            "Val unfiltered loss: 17.47408676147461\n",
            "233/233 - 43s - loss: 15.7229 - val_loss: 12.7637 - lr: 6.8025e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 6.79e-04, weight decay: 3.40e-05\n",
            "Epoch 579/1500\n",
            "Val unfiltered loss: 16.862255096435547\n",
            "233/233 - 45s - loss: 15.7596 - val_loss: 12.4086 - lr: 6.7927e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 6.78e-04, weight decay: 3.39e-05\n",
            "Epoch 580/1500\n",
            "Val unfiltered loss: 16.984943389892578\n",
            "233/233 - 44s - loss: 15.6730 - val_loss: 12.4800 - lr: 6.7828e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.77e-04, weight decay: 3.39e-05\n",
            "Epoch 581/1500\n",
            "Val unfiltered loss: 17.033296585083008\n",
            "233/233 - 44s - loss: 15.6693 - val_loss: 12.5027 - lr: 6.7730e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.76e-04, weight decay: 3.38e-05\n",
            "Epoch 582/1500\n",
            "Val unfiltered loss: 17.104393005371094\n",
            "233/233 - 43s - loss: 15.6864 - val_loss: 12.6190 - lr: 6.7632e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 6.75e-04, weight decay: 3.38e-05\n",
            "Epoch 583/1500\n",
            "Val unfiltered loss: 17.130260467529297\n",
            "233/233 - 44s - loss: 15.6328 - val_loss: 12.5578 - lr: 6.7534e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.74e-04, weight decay: 3.37e-05\n",
            "Epoch 584/1500\n",
            "Val unfiltered loss: 17.338716506958008\n",
            "233/233 - 44s - loss: 15.6108 - val_loss: 12.5448 - lr: 6.7435e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.73e-04, weight decay: 3.37e-05\n",
            "Epoch 585/1500\n",
            "Val unfiltered loss: 16.94642448425293\n",
            "233/233 - 44s - loss: 15.6765 - val_loss: 12.4184 - lr: 6.7337e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.72e-04, weight decay: 3.36e-05\n",
            "Epoch 586/1500\n",
            "Val unfiltered loss: 17.325565338134766\n",
            "233/233 - 44s - loss: 15.6013 - val_loss: 12.7327 - lr: 6.7238e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.71e-04, weight decay: 3.36e-05\n",
            "Epoch 587/1500\n",
            "Val unfiltered loss: 17.03126335144043\n",
            "233/233 - 45s - loss: 15.6183 - val_loss: 12.4658 - lr: 6.7139e-04 - 45s/epoch - 195ms/step\n",
            "learning rate: 6.70e-04, weight decay: 3.35e-05\n",
            "Epoch 588/1500\n",
            "Val unfiltered loss: 16.999656677246094\n",
            "233/233 - 44s - loss: 15.7188 - val_loss: 12.4289 - lr: 6.7041e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.69e-04, weight decay: 3.35e-05\n",
            "Epoch 589/1500\n",
            "Val unfiltered loss: 16.985841751098633\n",
            "233/233 - 44s - loss: 15.6563 - val_loss: 12.4443 - lr: 6.6942e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.68e-04, weight decay: 3.34e-05\n",
            "Epoch 590/1500\n",
            "Val unfiltered loss: 16.9305419921875\n",
            "233/233 - 44s - loss: 15.6223 - val_loss: 12.4129 - lr: 6.6843e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.67e-04, weight decay: 3.34e-05\n",
            "Epoch 591/1500\n",
            "Val unfiltered loss: 17.097339630126953\n",
            "233/233 - 43s - loss: 15.6616 - val_loss: 12.4753 - lr: 6.6744e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 6.66e-04, weight decay: 3.33e-05\n",
            "Epoch 592/1500\n",
            "Val unfiltered loss: 16.908912658691406\n",
            "233/233 - 43s - loss: 15.5889 - val_loss: 12.3094 - lr: 6.6645e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 6.65e-04, weight decay: 3.33e-05\n",
            "Epoch 593/1500\n",
            "Val unfiltered loss: 16.93695831298828\n",
            "233/233 - 44s - loss: 15.6091 - val_loss: 12.5752 - lr: 6.6546e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.64e-04, weight decay: 3.32e-05\n",
            "Epoch 594/1500\n",
            "Val unfiltered loss: 16.967329025268555\n",
            "233/233 - 45s - loss: 15.6313 - val_loss: 12.5441 - lr: 6.6447e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 6.63e-04, weight decay: 3.32e-05\n",
            "Epoch 595/1500\n",
            "Val unfiltered loss: 16.73492431640625\n",
            "233/233 - 43s - loss: 15.5617 - val_loss: 12.4030 - lr: 6.6347e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 6.62e-04, weight decay: 3.31e-05\n",
            "Epoch 596/1500\n",
            "Val unfiltered loss: 17.033985137939453\n",
            "233/233 - 43s - loss: 15.5559 - val_loss: 12.5405 - lr: 6.6248e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 6.61e-04, weight decay: 3.31e-05\n",
            "Epoch 597/1500\n",
            "Val unfiltered loss: 17.406631469726562\n",
            "233/233 - 44s - loss: 15.5920 - val_loss: 12.7198 - lr: 6.6149e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.60e-04, weight decay: 3.30e-05\n",
            "Epoch 598/1500\n",
            "Val unfiltered loss: 17.170034408569336\n",
            "233/233 - 44s - loss: 15.5204 - val_loss: 12.4670 - lr: 6.6049e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.59e-04, weight decay: 3.30e-05\n",
            "Epoch 599/1500\n",
            "Val unfiltered loss: 17.296499252319336\n",
            "233/233 - 44s - loss: 15.4580 - val_loss: 12.6326 - lr: 6.5950e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.59e-04, weight decay: 3.29e-05\n",
            "Epoch 600/1500\n",
            "Val unfiltered loss: 16.814985275268555\n",
            "Val filtered lev distance: 0.8549566660117449\n",
            "Val unfiltered lev distance: 0.8061066274400668\n",
            "Sub train lev distance: 0.9353680430879713\n",
            "233/233 - 117s - loss: 15.5270 - val_loss: 12.2900 - lr: 6.5850e-04 - 117s/epoch - 502ms/step\n",
            "learning rate: 6.58e-04, weight decay: 3.29e-05\n",
            "Epoch 601/1500\n",
            "Val unfiltered loss: 17.142257690429688\n",
            "233/233 - 44s - loss: 15.5823 - val_loss: 12.6037 - lr: 6.5750e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.57e-04, weight decay: 3.28e-05\n",
            "Epoch 602/1500\n",
            "Val unfiltered loss: 17.26957130432129\n",
            "233/233 - 45s - loss: 15.5086 - val_loss: 12.7709 - lr: 6.5651e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 6.56e-04, weight decay: 3.28e-05\n",
            "Epoch 603/1500\n",
            "Val unfiltered loss: 17.434030532836914\n",
            "233/233 - 44s - loss: 15.5245 - val_loss: 12.8320 - lr: 6.5551e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.55e-04, weight decay: 3.27e-05\n",
            "Epoch 604/1500\n",
            "Val unfiltered loss: 17.080686569213867\n",
            "233/233 - 44s - loss: 15.5058 - val_loss: 12.6899 - lr: 6.5451e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.54e-04, weight decay: 3.27e-05\n",
            "Epoch 605/1500\n",
            "Val unfiltered loss: 16.869834899902344\n",
            "233/233 - 44s - loss: 15.5046 - val_loss: 12.4396 - lr: 6.5351e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.53e-04, weight decay: 3.26e-05\n",
            "Epoch 606/1500\n",
            "Val unfiltered loss: 16.997514724731445\n",
            "233/233 - 44s - loss: 15.3994 - val_loss: 12.5938 - lr: 6.5251e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.52e-04, weight decay: 3.26e-05\n",
            "Epoch 607/1500\n",
            "Val unfiltered loss: 17.093313217163086\n",
            "233/233 - 44s - loss: 15.4433 - val_loss: 12.7086 - lr: 6.5151e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.51e-04, weight decay: 3.25e-05\n",
            "Epoch 608/1500\n",
            "Val unfiltered loss: 17.19835090637207\n",
            "233/233 - 44s - loss: 15.5498 - val_loss: 12.5810 - lr: 6.5051e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.50e-04, weight decay: 3.25e-05\n",
            "Epoch 609/1500\n",
            "Val unfiltered loss: 17.196857452392578\n",
            "233/233 - 44s - loss: 15.4202 - val_loss: 12.7389 - lr: 6.4950e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.49e-04, weight decay: 3.24e-05\n",
            "Epoch 610/1500\n",
            "Val unfiltered loss: 17.3961238861084\n",
            "233/233 - 44s - loss: 15.4064 - val_loss: 12.6148 - lr: 6.4850e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.47e-04, weight decay: 3.24e-05\n",
            "Epoch 611/1500\n",
            "Val unfiltered loss: 17.446796417236328\n",
            "233/233 - 44s - loss: 15.4429 - val_loss: 12.8977 - lr: 6.4750e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.46e-04, weight decay: 3.23e-05\n",
            "Epoch 612/1500\n",
            "Val unfiltered loss: 17.17755699157715\n",
            "233/233 - 44s - loss: 15.5156 - val_loss: 12.7217 - lr: 6.4649e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.45e-04, weight decay: 3.23e-05\n",
            "Epoch 613/1500\n",
            "Val unfiltered loss: 17.115373611450195\n",
            "233/233 - 44s - loss: 15.4743 - val_loss: 12.6751 - lr: 6.4549e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.44e-04, weight decay: 3.22e-05\n",
            "Epoch 614/1500\n",
            "Val unfiltered loss: 17.19157600402832\n",
            "233/233 - 44s - loss: 15.4321 - val_loss: 12.6374 - lr: 6.4448e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.43e-04, weight decay: 3.22e-05\n",
            "Epoch 615/1500\n",
            "Val unfiltered loss: 17.07016372680664\n",
            "233/233 - 44s - loss: 15.3973 - val_loss: 12.5572 - lr: 6.4348e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.42e-04, weight decay: 3.21e-05\n",
            "Epoch 616/1500\n",
            "Val unfiltered loss: 17.445066452026367\n",
            "233/233 - 44s - loss: 15.3897 - val_loss: 12.6711 - lr: 6.4247e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.41e-04, weight decay: 3.21e-05\n",
            "Epoch 617/1500\n",
            "Val unfiltered loss: 17.000043869018555\n",
            "233/233 - 44s - loss: 15.3738 - val_loss: 12.4489 - lr: 6.4146e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.40e-04, weight decay: 3.20e-05\n",
            "Epoch 618/1500\n",
            "Val unfiltered loss: 17.114933013916016\n",
            "233/233 - 44s - loss: 15.3438 - val_loss: 12.4882 - lr: 6.4045e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.39e-04, weight decay: 3.20e-05\n",
            "Epoch 619/1500\n",
            "Val unfiltered loss: 17.140562057495117\n",
            "233/233 - 44s - loss: 15.3925 - val_loss: 12.6446 - lr: 6.3945e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.38e-04, weight decay: 3.19e-05\n",
            "Epoch 620/1500\n",
            "Val unfiltered loss: 17.39745330810547\n",
            "233/233 - 44s - loss: 15.3768 - val_loss: 12.6508 - lr: 6.3844e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.37e-04, weight decay: 3.19e-05\n",
            "Epoch 621/1500\n",
            "Val unfiltered loss: 17.397249221801758\n",
            "233/233 - 44s - loss: 15.3336 - val_loss: 12.6252 - lr: 6.3743e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.36e-04, weight decay: 3.18e-05\n",
            "Epoch 622/1500\n",
            "Val unfiltered loss: 17.40443229675293\n",
            "233/233 - 44s - loss: 15.3322 - val_loss: 12.5743 - lr: 6.3642e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.35e-04, weight decay: 3.18e-05\n",
            "Epoch 623/1500\n",
            "Val unfiltered loss: 17.144359588623047\n",
            "233/233 - 44s - loss: 15.2903 - val_loss: 12.5182 - lr: 6.3540e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.34e-04, weight decay: 3.17e-05\n",
            "Epoch 624/1500\n",
            "Val unfiltered loss: 17.18986701965332\n",
            "233/233 - 44s - loss: 15.2563 - val_loss: 12.4564 - lr: 6.3439e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.33e-04, weight decay: 3.17e-05\n",
            "Epoch 625/1500\n",
            "Val unfiltered loss: 17.178062438964844\n",
            "233/233 - 43s - loss: 15.3026 - val_loss: 12.5696 - lr: 6.3338e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 6.32e-04, weight decay: 3.16e-05\n",
            "Epoch 626/1500\n",
            "Val unfiltered loss: 17.584083557128906\n",
            "233/233 - 44s - loss: 15.2203 - val_loss: 12.6062 - lr: 6.3237e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.31e-04, weight decay: 3.16e-05\n",
            "Epoch 627/1500\n",
            "Val unfiltered loss: 17.3870849609375\n",
            "233/233 - 44s - loss: 15.3161 - val_loss: 12.6675 - lr: 6.3135e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.30e-04, weight decay: 3.15e-05\n",
            "Epoch 628/1500\n",
            "Val unfiltered loss: 17.706811904907227\n",
            "233/233 - 44s - loss: 15.2703 - val_loss: 12.8096 - lr: 6.3034e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.29e-04, weight decay: 3.15e-05\n",
            "Epoch 629/1500\n",
            "Val unfiltered loss: 17.23636245727539\n",
            "233/233 - 44s - loss: 15.2639 - val_loss: 12.4881 - lr: 6.2932e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.28e-04, weight decay: 3.14e-05\n",
            "Epoch 630/1500\n",
            "Val unfiltered loss: 17.18474578857422\n",
            "233/233 - 45s - loss: 15.3019 - val_loss: 12.5160 - lr: 6.2831e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 6.27e-04, weight decay: 3.14e-05\n",
            "Epoch 631/1500\n",
            "Val unfiltered loss: 17.0468692779541\n",
            "233/233 - 44s - loss: 15.2300 - val_loss: 12.6152 - lr: 6.2729e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.26e-04, weight decay: 3.13e-05\n",
            "Epoch 632/1500\n",
            "Val unfiltered loss: 17.361286163330078\n",
            "233/233 - 44s - loss: 15.2096 - val_loss: 12.6811 - lr: 6.2628e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.25e-04, weight decay: 3.13e-05\n",
            "Epoch 633/1500\n",
            "Val unfiltered loss: 16.928308486938477\n",
            "233/233 - 44s - loss: 15.2075 - val_loss: 12.4429 - lr: 6.2526e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.24e-04, weight decay: 3.12e-05\n",
            "Epoch 634/1500\n",
            "Val unfiltered loss: 17.149812698364258\n",
            "233/233 - 44s - loss: 15.2263 - val_loss: 12.6912 - lr: 6.2424e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.23e-04, weight decay: 3.12e-05\n",
            "Epoch 635/1500\n",
            "Val unfiltered loss: 17.228246688842773\n",
            "233/233 - 44s - loss: 15.2903 - val_loss: 12.6719 - lr: 6.2323e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.22e-04, weight decay: 3.11e-05\n",
            "Epoch 636/1500\n",
            "Val unfiltered loss: 17.11354637145996\n",
            "233/233 - 44s - loss: 15.1642 - val_loss: 12.5720 - lr: 6.2221e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.21e-04, weight decay: 3.11e-05\n",
            "Epoch 637/1500\n",
            "Val unfiltered loss: 17.322160720825195\n",
            "233/233 - 45s - loss: 15.2013 - val_loss: 12.7028 - lr: 6.2119e-04 - 45s/epoch - 195ms/step\n",
            "learning rate: 6.20e-04, weight decay: 3.10e-05\n",
            "Epoch 638/1500\n",
            "Val unfiltered loss: 17.189334869384766\n",
            "233/233 - 44s - loss: 15.2286 - val_loss: 12.5447 - lr: 6.2017e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.19e-04, weight decay: 3.10e-05\n",
            "Epoch 639/1500\n",
            "Val unfiltered loss: 17.122495651245117\n",
            "233/233 - 43s - loss: 15.2373 - val_loss: 12.5956 - lr: 6.1915e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 6.18e-04, weight decay: 3.09e-05\n",
            "Epoch 640/1500\n",
            "Val unfiltered loss: 17.00314712524414\n",
            "233/233 - 45s - loss: 15.1525 - val_loss: 12.4914 - lr: 6.1813e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 6.17e-04, weight decay: 3.09e-05\n",
            "Epoch 641/1500\n",
            "Val unfiltered loss: 17.576631546020508\n",
            "233/233 - 44s - loss: 15.1482 - val_loss: 12.7349 - lr: 6.1711e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.16e-04, weight decay: 3.08e-05\n",
            "Epoch 642/1500\n",
            "Val unfiltered loss: 17.605737686157227\n",
            "233/233 - 44s - loss: 15.1568 - val_loss: 12.7815 - lr: 6.1608e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.15e-04, weight decay: 3.08e-05\n",
            "Epoch 643/1500\n",
            "Val unfiltered loss: 17.39211082458496\n",
            "233/233 - 44s - loss: 15.1926 - val_loss: 12.8516 - lr: 6.1506e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.14e-04, weight decay: 3.07e-05\n",
            "Epoch 644/1500\n",
            "Val unfiltered loss: 17.412031173706055\n",
            "233/233 - 45s - loss: 15.1582 - val_loss: 12.6880 - lr: 6.1404e-04 - 45s/epoch - 195ms/step\n",
            "learning rate: 6.13e-04, weight decay: 3.07e-05\n",
            "Epoch 645/1500\n",
            "Val unfiltered loss: 17.21881675720215\n",
            "233/233 - 44s - loss: 15.1957 - val_loss: 12.7196 - lr: 6.1302e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.12e-04, weight decay: 3.06e-05\n",
            "Epoch 646/1500\n",
            "Val unfiltered loss: 17.341718673706055\n",
            "233/233 - 43s - loss: 15.1982 - val_loss: 12.6928 - lr: 6.1199e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 6.11e-04, weight decay: 3.05e-05\n",
            "Epoch 647/1500\n",
            "Val unfiltered loss: 17.246625900268555\n",
            "233/233 - 44s - loss: 15.1227 - val_loss: 12.7474 - lr: 6.1097e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.10e-04, weight decay: 3.05e-05\n",
            "Epoch 648/1500\n",
            "Val unfiltered loss: 17.36536979675293\n",
            "233/233 - 44s - loss: 15.0933 - val_loss: 12.7202 - lr: 6.0994e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.09e-04, weight decay: 3.04e-05\n",
            "Epoch 649/1500\n",
            "Val unfiltered loss: 17.21240997314453\n",
            "233/233 - 44s - loss: 15.0416 - val_loss: 12.5436 - lr: 6.0892e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.08e-04, weight decay: 3.04e-05\n",
            "Epoch 650/1500\n",
            "Val unfiltered loss: 17.222043991088867\n",
            "Val filtered lev distance: 0.8567904468749318\n",
            "Val unfiltered lev distance: 0.8074384765236751\n",
            "Sub train lev distance: 0.9420895914524675\n",
            "233/233 - 120s - loss: 15.1179 - val_loss: 12.6728 - lr: 6.0789e-04 - 120s/epoch - 516ms/step\n",
            "learning rate: 6.07e-04, weight decay: 3.03e-05\n",
            "Epoch 651/1500\n",
            "Val unfiltered loss: 17.444272994995117\n",
            "233/233 - 44s - loss: 15.0551 - val_loss: 12.7756 - lr: 6.0687e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.06e-04, weight decay: 3.03e-05\n",
            "Epoch 652/1500\n",
            "Val unfiltered loss: 17.36356544494629\n",
            "233/233 - 45s - loss: 15.0493 - val_loss: 12.7020 - lr: 6.0584e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 6.05e-04, weight decay: 3.02e-05\n",
            "Epoch 653/1500\n",
            "Val unfiltered loss: 17.312929153442383\n",
            "233/233 - 44s - loss: 15.0468 - val_loss: 12.6518 - lr: 6.0481e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.04e-04, weight decay: 3.02e-05\n",
            "Epoch 654/1500\n",
            "Val unfiltered loss: 17.577186584472656\n",
            "233/233 - 44s - loss: 15.0211 - val_loss: 12.9767 - lr: 6.0378e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.03e-04, weight decay: 3.01e-05\n",
            "Epoch 655/1500\n",
            "Val unfiltered loss: 17.370229721069336\n",
            "233/233 - 44s - loss: 15.0457 - val_loss: 12.6799 - lr: 6.0276e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.02e-04, weight decay: 3.01e-05\n",
            "Epoch 656/1500\n",
            "Val unfiltered loss: 16.82586669921875\n",
            "233/233 - 44s - loss: 15.0607 - val_loss: 12.4517 - lr: 6.0173e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.01e-04, weight decay: 3.00e-05\n",
            "Epoch 657/1500\n",
            "Val unfiltered loss: 17.567716598510742\n",
            "233/233 - 44s - loss: 15.0666 - val_loss: 12.8734 - lr: 6.0070e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.00e-04, weight decay: 3.00e-05\n",
            "Epoch 658/1500\n",
            "Val unfiltered loss: 17.51129913330078\n",
            "233/233 - 44s - loss: 15.0379 - val_loss: 12.7904 - lr: 5.9967e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.99e-04, weight decay: 2.99e-05\n",
            "Epoch 659/1500\n",
            "Val unfiltered loss: 17.20946502685547\n",
            "233/233 - 45s - loss: 15.0584 - val_loss: 12.5987 - lr: 5.9864e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 5.98e-04, weight decay: 2.99e-05\n",
            "Epoch 660/1500\n",
            "Val unfiltered loss: 17.69966697692871\n",
            "233/233 - 44s - loss: 15.1255 - val_loss: 12.9466 - lr: 5.9761e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.97e-04, weight decay: 2.98e-05\n",
            "Epoch 661/1500\n",
            "Val unfiltered loss: 17.301959991455078\n",
            "233/233 - 44s - loss: 15.0397 - val_loss: 12.7349 - lr: 5.9658e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.96e-04, weight decay: 2.98e-05\n",
            "Epoch 662/1500\n",
            "Val unfiltered loss: 17.456462860107422\n",
            "233/233 - 44s - loss: 15.0080 - val_loss: 12.6999 - lr: 5.9555e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.95e-04, weight decay: 2.97e-05\n",
            "Epoch 663/1500\n",
            "Val unfiltered loss: 17.58364486694336\n",
            "233/233 - 44s - loss: 15.0369 - val_loss: 12.8288 - lr: 5.9452e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.93e-04, weight decay: 2.97e-05\n",
            "Epoch 664/1500\n",
            "Val unfiltered loss: 17.492502212524414\n",
            "233/233 - 44s - loss: 14.9456 - val_loss: 12.8291 - lr: 5.9348e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.92e-04, weight decay: 2.96e-05\n",
            "Epoch 665/1500\n",
            "Val unfiltered loss: 17.522178649902344\n",
            "233/233 - 44s - loss: 15.0137 - val_loss: 12.7082 - lr: 5.9245e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.91e-04, weight decay: 2.96e-05\n",
            "Epoch 666/1500\n",
            "Val unfiltered loss: 17.56009292602539\n",
            "233/233 - 45s - loss: 15.0523 - val_loss: 12.7891 - lr: 5.9142e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 5.90e-04, weight decay: 2.95e-05\n",
            "Epoch 667/1500\n",
            "Val unfiltered loss: 17.58557891845703\n",
            "233/233 - 44s - loss: 15.0803 - val_loss: 12.9759 - lr: 5.9039e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.89e-04, weight decay: 2.95e-05\n",
            "Epoch 668/1500\n",
            "Val unfiltered loss: 17.524906158447266\n",
            "233/233 - 44s - loss: 15.0064 - val_loss: 12.9878 - lr: 5.8935e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.88e-04, weight decay: 2.94e-05\n",
            "Epoch 669/1500\n",
            "Val unfiltered loss: 17.751659393310547\n",
            "233/233 - 44s - loss: 14.9466 - val_loss: 12.9822 - lr: 5.8832e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.87e-04, weight decay: 2.94e-05\n",
            "Epoch 670/1500\n",
            "Val unfiltered loss: 17.601152420043945\n",
            "233/233 - 44s - loss: 14.9828 - val_loss: 13.0507 - lr: 5.8728e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 5.86e-04, weight decay: 2.93e-05\n",
            "Epoch 671/1500\n",
            "Val unfiltered loss: 17.463916778564453\n",
            "233/233 - 44s - loss: 14.9631 - val_loss: 12.8928 - lr: 5.8625e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.85e-04, weight decay: 2.93e-05\n",
            "Epoch 672/1500\n",
            "Val unfiltered loss: 17.284818649291992\n",
            "233/233 - 44s - loss: 14.9544 - val_loss: 12.6816 - lr: 5.8521e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.84e-04, weight decay: 2.92e-05\n",
            "Epoch 673/1500\n",
            "Val unfiltered loss: 17.657808303833008\n",
            "233/233 - 44s - loss: 14.9277 - val_loss: 12.9251 - lr: 5.8418e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 5.83e-04, weight decay: 2.92e-05\n",
            "Epoch 674/1500\n",
            "Val unfiltered loss: 17.424034118652344\n",
            "233/233 - 44s - loss: 14.8318 - val_loss: 12.8162 - lr: 5.8314e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.82e-04, weight decay: 2.91e-05\n",
            "Epoch 675/1500\n",
            "Val unfiltered loss: 17.773820877075195\n",
            "233/233 - 44s - loss: 14.8702 - val_loss: 13.0178 - lr: 5.8211e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.81e-04, weight decay: 2.91e-05\n",
            "Epoch 676/1500\n",
            "Val unfiltered loss: 17.8011474609375\n",
            "233/233 - 44s - loss: 14.8389 - val_loss: 12.8575 - lr: 5.8107e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.80e-04, weight decay: 2.90e-05\n",
            "Epoch 677/1500\n",
            "Val unfiltered loss: 17.65052604675293\n",
            "233/233 - 44s - loss: 14.8064 - val_loss: 12.7904 - lr: 5.8003e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.79e-04, weight decay: 2.89e-05\n",
            "Epoch 678/1500\n",
            "Val unfiltered loss: 17.61201286315918\n",
            "233/233 - 44s - loss: 14.9141 - val_loss: 12.8590 - lr: 5.7900e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.78e-04, weight decay: 2.89e-05\n",
            "Epoch 679/1500\n",
            "Val unfiltered loss: 17.558364868164062\n",
            "233/233 - 44s - loss: 14.8500 - val_loss: 12.8673 - lr: 5.7796e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.77e-04, weight decay: 2.88e-05\n",
            "Epoch 680/1500\n",
            "Val unfiltered loss: 17.499361038208008\n",
            "233/233 - 44s - loss: 15.0064 - val_loss: 13.0167 - lr: 5.7692e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.76e-04, weight decay: 2.88e-05\n",
            "Epoch 681/1500\n",
            "Val unfiltered loss: 17.883424758911133\n",
            "233/233 - 45s - loss: 14.9604 - val_loss: 13.1147 - lr: 5.7588e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 5.75e-04, weight decay: 2.87e-05\n",
            "Epoch 682/1500\n",
            "Val unfiltered loss: 17.58883285522461\n",
            "233/233 - 44s - loss: 14.8919 - val_loss: 12.9508 - lr: 5.7484e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.74e-04, weight decay: 2.87e-05\n",
            "Epoch 683/1500\n",
            "Val unfiltered loss: 17.52665901184082\n",
            "233/233 - 44s - loss: 14.8503 - val_loss: 12.9472 - lr: 5.7380e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.73e-04, weight decay: 2.86e-05\n",
            "Epoch 684/1500\n",
            "Val unfiltered loss: 17.506502151489258\n",
            "233/233 - 44s - loss: 14.8785 - val_loss: 12.8990 - lr: 5.7276e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.72e-04, weight decay: 2.86e-05\n",
            "Epoch 685/1500\n",
            "Val unfiltered loss: 17.435396194458008\n",
            "233/233 - 44s - loss: 14.8476 - val_loss: 12.7960 - lr: 5.7172e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.71e-04, weight decay: 2.85e-05\n",
            "Epoch 686/1500\n",
            "Val unfiltered loss: 17.715553283691406\n",
            "233/233 - 44s - loss: 14.9088 - val_loss: 12.7985 - lr: 5.7068e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.70e-04, weight decay: 2.85e-05\n",
            "Epoch 687/1500\n",
            "Val unfiltered loss: 17.89092445373535\n",
            "233/233 - 44s - loss: 14.9670 - val_loss: 13.0642 - lr: 5.6964e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.69e-04, weight decay: 2.84e-05\n",
            "Epoch 688/1500\n",
            "Val unfiltered loss: 17.828397750854492\n",
            "233/233 - 45s - loss: 14.9234 - val_loss: 12.8466 - lr: 5.6860e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 5.68e-04, weight decay: 2.84e-05\n",
            "Epoch 689/1500\n",
            "Val unfiltered loss: 17.687103271484375\n",
            "233/233 - 44s - loss: 14.8702 - val_loss: 12.9643 - lr: 5.6756e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.67e-04, weight decay: 2.83e-05\n",
            "Epoch 690/1500\n",
            "Val unfiltered loss: 17.55348777770996\n",
            "233/233 - 44s - loss: 14.8582 - val_loss: 12.8530 - lr: 5.6652e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.65e-04, weight decay: 2.83e-05\n",
            "Epoch 691/1500\n",
            "Val unfiltered loss: 17.54401969909668\n",
            "233/233 - 44s - loss: 14.8133 - val_loss: 12.9435 - lr: 5.6548e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.64e-04, weight decay: 2.82e-05\n",
            "Epoch 692/1500\n",
            "Val unfiltered loss: 17.42060089111328\n",
            "233/233 - 44s - loss: 14.8136 - val_loss: 12.8024 - lr: 5.6444e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.63e-04, weight decay: 2.82e-05\n",
            "Epoch 693/1500\n",
            "Val unfiltered loss: 17.709970474243164\n",
            "233/233 - 44s - loss: 14.7885 - val_loss: 12.8429 - lr: 5.6340e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.62e-04, weight decay: 2.81e-05\n",
            "Epoch 694/1500\n",
            "Val unfiltered loss: 17.666624069213867\n",
            "233/233 - 44s - loss: 14.8203 - val_loss: 13.0802 - lr: 5.6235e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.61e-04, weight decay: 2.81e-05\n",
            "Epoch 695/1500\n",
            "Val unfiltered loss: 17.359169006347656\n",
            "233/233 - 44s - loss: 14.7399 - val_loss: 12.8769 - lr: 5.6131e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.60e-04, weight decay: 2.80e-05\n",
            "Epoch 696/1500\n",
            "Val unfiltered loss: 17.38612937927246\n",
            "233/233 - 44s - loss: 14.7327 - val_loss: 12.8024 - lr: 5.6027e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.59e-04, weight decay: 2.80e-05\n",
            "Epoch 697/1500\n",
            "Val unfiltered loss: 17.618318557739258\n",
            "233/233 - 44s - loss: 14.7350 - val_loss: 13.0072 - lr: 5.5923e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.58e-04, weight decay: 2.79e-05\n",
            "Epoch 698/1500\n",
            "Val unfiltered loss: 18.111284255981445\n",
            "233/233 - 44s - loss: 14.7293 - val_loss: 13.1820 - lr: 5.5818e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.57e-04, weight decay: 2.79e-05\n",
            "Epoch 699/1500\n",
            "Val unfiltered loss: 17.68870735168457\n",
            "233/233 - 44s - loss: 14.7584 - val_loss: 13.0047 - lr: 5.5714e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.56e-04, weight decay: 2.78e-05\n",
            "Epoch 700/1500\n",
            "Val unfiltered loss: 17.584182739257812\n",
            "Val filtered lev distance: 0.8565503089047526\n",
            "Val unfiltered lev distance: 0.8080547052041506\n",
            "Sub train lev distance: 0.947103384857906\n",
            "233/233 - 120s - loss: 14.7861 - val_loss: 12.8817 - lr: 5.5609e-04 - 120s/epoch - 516ms/step\n",
            "learning rate: 5.55e-04, weight decay: 2.78e-05\n",
            "Epoch 701/1500\n",
            "Val unfiltered loss: 17.83895492553711\n",
            "233/233 - 44s - loss: 14.6580 - val_loss: 13.0538 - lr: 5.5505e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.54e-04, weight decay: 2.77e-05\n",
            "Epoch 702/1500\n",
            "Val unfiltered loss: 17.830015182495117\n",
            "233/233 - 44s - loss: 14.6622 - val_loss: 12.8726 - lr: 5.5401e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 5.53e-04, weight decay: 2.76e-05\n",
            "Epoch 703/1500\n",
            "Val unfiltered loss: 17.648332595825195\n",
            "233/233 - 44s - loss: 14.7223 - val_loss: 12.8926 - lr: 5.5296e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.52e-04, weight decay: 2.76e-05\n",
            "Epoch 704/1500\n",
            "Val unfiltered loss: 17.74213409423828\n",
            "233/233 - 44s - loss: 14.7151 - val_loss: 12.9923 - lr: 5.5192e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.51e-04, weight decay: 2.75e-05\n",
            "Epoch 705/1500\n",
            "Val unfiltered loss: 17.827342987060547\n",
            "233/233 - 44s - loss: 14.7246 - val_loss: 13.0457 - lr: 5.5087e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.50e-04, weight decay: 2.75e-05\n",
            "Epoch 706/1500\n",
            "Val unfiltered loss: 17.765419006347656\n",
            "233/233 - 44s - loss: 14.7352 - val_loss: 12.9799 - lr: 5.4983e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.49e-04, weight decay: 2.74e-05\n",
            "Epoch 707/1500\n",
            "Val unfiltered loss: 17.699811935424805\n",
            "233/233 - 44s - loss: 14.7298 - val_loss: 12.8086 - lr: 5.4878e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.48e-04, weight decay: 2.74e-05\n",
            "Epoch 708/1500\n",
            "Val unfiltered loss: 18.08885955810547\n",
            "233/233 - 44s - loss: 14.6837 - val_loss: 13.1026 - lr: 5.4773e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.47e-04, weight decay: 2.73e-05\n",
            "Epoch 709/1500\n",
            "Val unfiltered loss: 17.91850471496582\n",
            "233/233 - 44s - loss: 14.6128 - val_loss: 13.0405 - lr: 5.4669e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.46e-04, weight decay: 2.73e-05\n",
            "Epoch 710/1500\n",
            "Val unfiltered loss: 17.886932373046875\n",
            "233/233 - 45s - loss: 14.6687 - val_loss: 12.8394 - lr: 5.4564e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 5.45e-04, weight decay: 2.72e-05\n",
            "Epoch 711/1500\n",
            "Val unfiltered loss: 17.576139450073242\n",
            "233/233 - 44s - loss: 14.6543 - val_loss: 12.8431 - lr: 5.4460e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.44e-04, weight decay: 2.72e-05\n",
            "Epoch 712/1500\n",
            "Val unfiltered loss: 17.46774673461914\n",
            "233/233 - 44s - loss: 14.6526 - val_loss: 12.7666 - lr: 5.4355e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.43e-04, weight decay: 2.71e-05\n",
            "Epoch 713/1500\n",
            "Val unfiltered loss: 17.902490615844727\n",
            "233/233 - 44s - loss: 14.5249 - val_loss: 12.9484 - lr: 5.4250e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.41e-04, weight decay: 2.71e-05\n",
            "Epoch 714/1500\n",
            "Val unfiltered loss: 17.564359664916992\n",
            "233/233 - 44s - loss: 14.6627 - val_loss: 12.8857 - lr: 5.4145e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.40e-04, weight decay: 2.70e-05\n",
            "Epoch 715/1500\n",
            "Val unfiltered loss: 18.17412567138672\n",
            "233/233 - 44s - loss: 14.5774 - val_loss: 13.1241 - lr: 5.4041e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.39e-04, weight decay: 2.70e-05\n",
            "Epoch 716/1500\n",
            "Val unfiltered loss: 18.153398513793945\n",
            "233/233 - 44s - loss: 14.6491 - val_loss: 13.0493 - lr: 5.3936e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.38e-04, weight decay: 2.69e-05\n",
            "Epoch 717/1500\n",
            "Val unfiltered loss: 17.776018142700195\n",
            "233/233 - 44s - loss: 14.6610 - val_loss: 12.9313 - lr: 5.3831e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.37e-04, weight decay: 2.69e-05\n",
            "Epoch 718/1500\n",
            "Val unfiltered loss: 18.321043014526367\n",
            "233/233 - 44s - loss: 14.5852 - val_loss: 13.3485 - lr: 5.3727e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.36e-04, weight decay: 2.68e-05\n",
            "Epoch 719/1500\n",
            "Val unfiltered loss: 18.015748977661133\n",
            "233/233 - 44s - loss: 14.4996 - val_loss: 13.0536 - lr: 5.3622e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.35e-04, weight decay: 2.68e-05\n",
            "Epoch 720/1500\n",
            "Val unfiltered loss: 17.855152130126953\n",
            "233/233 - 44s - loss: 14.5418 - val_loss: 13.0881 - lr: 5.3517e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.34e-04, weight decay: 2.67e-05\n",
            "Epoch 721/1500\n",
            "Val unfiltered loss: 18.292461395263672\n",
            "233/233 - 44s - loss: 14.4866 - val_loss: 13.3185 - lr: 5.3412e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.33e-04, weight decay: 2.67e-05\n",
            "Epoch 722/1500\n",
            "Val unfiltered loss: 17.969995498657227\n",
            "233/233 - 44s - loss: 14.5313 - val_loss: 13.0617 - lr: 5.3307e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.32e-04, weight decay: 2.66e-05\n",
            "Epoch 723/1500\n",
            "Val unfiltered loss: 17.949548721313477\n",
            "233/233 - 44s - loss: 14.5199 - val_loss: 13.2417 - lr: 5.3202e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.31e-04, weight decay: 2.65e-05\n",
            "Epoch 724/1500\n",
            "Val unfiltered loss: 17.789216995239258\n",
            "233/233 - 44s - loss: 14.5892 - val_loss: 12.9609 - lr: 5.3098e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.30e-04, weight decay: 2.65e-05\n",
            "Epoch 725/1500\n",
            "Val unfiltered loss: 17.590238571166992\n",
            "233/233 - 46s - loss: 14.5581 - val_loss: 12.9020 - lr: 5.2993e-04 - 46s/epoch - 196ms/step\n",
            "learning rate: 5.29e-04, weight decay: 2.64e-05\n",
            "Epoch 726/1500\n",
            "Val unfiltered loss: 17.801279067993164\n",
            "233/233 - 44s - loss: 14.4924 - val_loss: 13.1872 - lr: 5.2888e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.28e-04, weight decay: 2.64e-05\n",
            "Epoch 727/1500\n",
            "Val unfiltered loss: 18.106565475463867\n",
            "233/233 - 44s - loss: 14.4620 - val_loss: 13.1517 - lr: 5.2783e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.27e-04, weight decay: 2.63e-05\n",
            "Epoch 728/1500\n",
            "Val unfiltered loss: 17.851099014282227\n",
            "233/233 - 44s - loss: 14.4946 - val_loss: 13.1610 - lr: 5.2678e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.26e-04, weight decay: 2.63e-05\n",
            "Epoch 729/1500\n",
            "Val unfiltered loss: 17.637380599975586\n",
            "233/233 - 44s - loss: 14.5094 - val_loss: 12.8678 - lr: 5.2573e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.25e-04, weight decay: 2.62e-05\n",
            "Epoch 730/1500\n",
            "Val unfiltered loss: 17.738798141479492\n",
            "233/233 - 44s - loss: 14.5061 - val_loss: 13.0806 - lr: 5.2468e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.24e-04, weight decay: 2.62e-05\n",
            "Epoch 731/1500\n",
            "Val unfiltered loss: 18.076637268066406\n",
            "233/233 - 44s - loss: 14.5255 - val_loss: 13.1799 - lr: 5.2363e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.23e-04, weight decay: 2.61e-05\n",
            "Epoch 732/1500\n",
            "Val unfiltered loss: 17.842519760131836\n",
            "233/233 - 45s - loss: 14.4599 - val_loss: 13.0635 - lr: 5.2258e-04 - 45s/epoch - 195ms/step\n",
            "learning rate: 5.22e-04, weight decay: 2.61e-05\n",
            "Epoch 733/1500\n",
            "Val unfiltered loss: 17.741365432739258\n",
            "233/233 - 44s - loss: 14.4359 - val_loss: 12.8979 - lr: 5.2153e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.20e-04, weight decay: 2.60e-05\n",
            "Epoch 734/1500\n",
            "Val unfiltered loss: 17.761381149291992\n",
            "233/233 - 44s - loss: 14.4615 - val_loss: 13.0707 - lr: 5.2048e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.19e-04, weight decay: 2.60e-05\n",
            "Epoch 735/1500\n",
            "Val unfiltered loss: 17.6761417388916\n",
            "233/233 - 44s - loss: 14.4796 - val_loss: 13.0483 - lr: 5.1943e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.18e-04, weight decay: 2.59e-05\n",
            "Epoch 736/1500\n",
            "Val unfiltered loss: 17.38310432434082\n",
            "233/233 - 44s - loss: 14.4088 - val_loss: 12.8693 - lr: 5.1838e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.17e-04, weight decay: 2.59e-05\n",
            "Epoch 737/1500\n",
            "Val unfiltered loss: 18.02882194519043\n",
            "233/233 - 44s - loss: 14.4256 - val_loss: 13.4603 - lr: 5.1733e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.16e-04, weight decay: 2.58e-05\n",
            "Epoch 738/1500\n",
            "Val unfiltered loss: 17.744123458862305\n",
            "233/233 - 44s - loss: 14.4654 - val_loss: 13.1901 - lr: 5.1628e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.15e-04, weight decay: 2.58e-05\n",
            "Epoch 739/1500\n",
            "Val unfiltered loss: 17.835426330566406\n",
            "233/233 - 45s - loss: 14.4251 - val_loss: 13.2500 - lr: 5.1523e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 5.14e-04, weight decay: 2.57e-05\n",
            "Epoch 740/1500\n",
            "Val unfiltered loss: 17.84296226501465\n",
            "233/233 - 43s - loss: 14.3978 - val_loss: 13.1400 - lr: 5.1418e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 5.13e-04, weight decay: 2.57e-05\n",
            "Epoch 741/1500\n",
            "Val unfiltered loss: 17.326032638549805\n",
            "233/233 - 44s - loss: 14.4625 - val_loss: 12.7245 - lr: 5.1313e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.12e-04, weight decay: 2.56e-05\n",
            "Epoch 742/1500\n",
            "Val unfiltered loss: 17.928937911987305\n",
            "233/233 - 44s - loss: 14.3897 - val_loss: 13.0457 - lr: 5.1208e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.11e-04, weight decay: 2.56e-05\n",
            "Epoch 743/1500\n",
            "Val unfiltered loss: 17.928659439086914\n",
            "233/233 - 43s - loss: 14.4393 - val_loss: 13.2338 - lr: 5.1103e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 5.10e-04, weight decay: 2.55e-05\n",
            "Epoch 744/1500\n",
            "Val unfiltered loss: 18.03594398498535\n",
            "233/233 - 43s - loss: 14.3762 - val_loss: 13.1808 - lr: 5.0998e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 5.09e-04, weight decay: 2.54e-05\n",
            "Epoch 745/1500\n",
            "Val unfiltered loss: 17.84510040283203\n",
            "233/233 - 44s - loss: 14.4555 - val_loss: 13.0813 - lr: 5.0893e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.08e-04, weight decay: 2.54e-05\n",
            "Epoch 746/1500\n",
            "Val unfiltered loss: 17.88526153564453\n",
            "233/233 - 45s - loss: 14.3902 - val_loss: 13.1519 - lr: 5.0788e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 5.07e-04, weight decay: 2.53e-05\n",
            "Epoch 747/1500\n",
            "Val unfiltered loss: 17.564727783203125\n",
            "233/233 - 43s - loss: 14.3820 - val_loss: 13.0514 - lr: 5.0683e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 5.06e-04, weight decay: 2.53e-05\n",
            "Epoch 748/1500\n",
            "Val unfiltered loss: 17.628154754638672\n",
            "233/233 - 44s - loss: 14.4604 - val_loss: 13.0070 - lr: 5.0578e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.05e-04, weight decay: 2.52e-05\n",
            "Epoch 749/1500\n",
            "Val unfiltered loss: 17.84717559814453\n",
            "233/233 - 44s - loss: 14.4019 - val_loss: 13.1816 - lr: 5.0473e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.04e-04, weight decay: 2.52e-05\n",
            "Epoch 750/1500\n",
            "Val unfiltered loss: 17.76313018798828\n",
            "Val filtered lev distance: 0.8587115506363656\n",
            "Val unfiltered lev distance: 0.8105196199260526\n",
            "Sub train lev distance: 0.9537154617506678\n",
            "233/233 - 117s - loss: 14.3333 - val_loss: 13.1278 - lr: 5.0368e-04 - 117s/epoch - 500ms/step\n",
            "learning rate: 5.03e-04, weight decay: 2.51e-05\n",
            "Epoch 751/1500\n",
            "Val unfiltered loss: 17.823200225830078\n",
            "233/233 - 43s - loss: 14.3986 - val_loss: 13.1733 - lr: 5.0263e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 5.02e-04, weight decay: 2.51e-05\n",
            "Epoch 752/1500\n",
            "Val unfiltered loss: 17.511137008666992\n",
            "233/233 - 44s - loss: 14.4289 - val_loss: 12.9631 - lr: 5.0158e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.01e-04, weight decay: 2.50e-05\n",
            "Epoch 753/1500\n",
            "Val unfiltered loss: 17.65803337097168\n",
            "233/233 - 44s - loss: 14.2900 - val_loss: 12.9559 - lr: 5.0053e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.99e-04, weight decay: 2.50e-05\n",
            "Epoch 754/1500\n",
            "Val unfiltered loss: 17.66489028930664\n",
            "233/233 - 44s - loss: 14.2691 - val_loss: 13.1447 - lr: 4.9947e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.98e-04, weight decay: 2.49e-05\n",
            "Epoch 755/1500\n",
            "Val unfiltered loss: 18.23773765563965\n",
            "233/233 - 44s - loss: 14.2662 - val_loss: 13.2036 - lr: 4.9842e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.97e-04, weight decay: 2.49e-05\n",
            "Epoch 756/1500\n",
            "Val unfiltered loss: 18.337705612182617\n",
            "233/233 - 44s - loss: 14.2854 - val_loss: 13.4918 - lr: 4.9737e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.96e-04, weight decay: 2.48e-05\n",
            "Epoch 757/1500\n",
            "Val unfiltered loss: 18.119155883789062\n",
            "233/233 - 43s - loss: 14.3052 - val_loss: 13.2966 - lr: 4.9632e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 4.95e-04, weight decay: 2.48e-05\n",
            "Epoch 758/1500\n",
            "Val unfiltered loss: 17.862274169921875\n",
            "233/233 - 43s - loss: 14.3001 - val_loss: 13.2330 - lr: 4.9527e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.94e-04, weight decay: 2.47e-05\n",
            "Epoch 759/1500\n",
            "Val unfiltered loss: 17.94853401184082\n",
            "233/233 - 44s - loss: 14.2035 - val_loss: 13.2195 - lr: 4.9422e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 4.93e-04, weight decay: 2.47e-05\n",
            "Epoch 760/1500\n",
            "Val unfiltered loss: 18.057889938354492\n",
            "233/233 - 45s - loss: 14.2984 - val_loss: 13.3005 - lr: 4.9317e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 4.92e-04, weight decay: 2.46e-05\n",
            "Epoch 761/1500\n",
            "Val unfiltered loss: 18.097631454467773\n",
            "233/233 - 43s - loss: 14.2721 - val_loss: 13.2631 - lr: 4.9212e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.91e-04, weight decay: 2.46e-05\n",
            "Epoch 762/1500\n",
            "Val unfiltered loss: 17.81587028503418\n",
            "233/233 - 44s - loss: 14.2152 - val_loss: 13.1538 - lr: 4.9107e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.90e-04, weight decay: 2.45e-05\n",
            "Epoch 763/1500\n",
            "Val unfiltered loss: 17.962430953979492\n",
            "233/233 - 44s - loss: 14.2820 - val_loss: 13.2427 - lr: 4.9002e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.89e-04, weight decay: 2.44e-05\n",
            "Epoch 764/1500\n",
            "Val unfiltered loss: 18.226757049560547\n",
            "233/233 - 44s - loss: 14.2620 - val_loss: 13.4146 - lr: 4.8897e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.88e-04, weight decay: 2.44e-05\n",
            "Epoch 765/1500\n",
            "Val unfiltered loss: 17.820024490356445\n",
            "233/233 - 43s - loss: 14.2333 - val_loss: 13.1260 - lr: 4.8792e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.87e-04, weight decay: 2.43e-05\n",
            "Epoch 766/1500\n",
            "Val unfiltered loss: 18.29137420654297\n",
            "233/233 - 44s - loss: 14.2260 - val_loss: 13.3477 - lr: 4.8687e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.86e-04, weight decay: 2.43e-05\n",
            "Epoch 767/1500\n",
            "Val unfiltered loss: 17.772531509399414\n",
            "233/233 - 43s - loss: 14.2782 - val_loss: 13.0536 - lr: 4.8582e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.85e-04, weight decay: 2.42e-05\n",
            "Epoch 768/1500\n",
            "Val unfiltered loss: 18.292781829833984\n",
            "233/233 - 44s - loss: 14.2351 - val_loss: 13.3618 - lr: 4.8477e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.84e-04, weight decay: 2.42e-05\n",
            "Epoch 769/1500\n",
            "Val unfiltered loss: 17.65416717529297\n",
            "233/233 - 44s - loss: 14.2515 - val_loss: 12.9261 - lr: 4.8372e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.83e-04, weight decay: 2.41e-05\n",
            "Epoch 770/1500\n",
            "Val unfiltered loss: 18.118738174438477\n",
            "233/233 - 44s - loss: 14.1817 - val_loss: 13.3796 - lr: 4.8267e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.82e-04, weight decay: 2.41e-05\n",
            "Epoch 771/1500\n",
            "Val unfiltered loss: 18.233951568603516\n",
            "233/233 - 43s - loss: 14.1796 - val_loss: 13.4947 - lr: 4.8162e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.81e-04, weight decay: 2.40e-05\n",
            "Epoch 772/1500\n",
            "Val unfiltered loss: 18.027484893798828\n",
            "233/233 - 44s - loss: 14.1743 - val_loss: 13.2804 - lr: 4.8057e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.80e-04, weight decay: 2.40e-05\n",
            "Epoch 773/1500\n",
            "Val unfiltered loss: 17.738969802856445\n",
            "233/233 - 44s - loss: 14.2034 - val_loss: 12.9776 - lr: 4.7952e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.78e-04, weight decay: 2.39e-05\n",
            "Epoch 774/1500\n",
            "Val unfiltered loss: 17.929542541503906\n",
            "233/233 - 43s - loss: 14.1816 - val_loss: 13.2404 - lr: 4.7847e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.77e-04, weight decay: 2.39e-05\n",
            "Epoch 775/1500\n",
            "Val unfiltered loss: 18.13935661315918\n",
            "233/233 - 45s - loss: 14.1858 - val_loss: 13.4434 - lr: 4.7742e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 4.76e-04, weight decay: 2.38e-05\n",
            "Epoch 776/1500\n",
            "Val unfiltered loss: 18.095182418823242\n",
            "233/233 - 44s - loss: 14.1787 - val_loss: 13.3551 - lr: 4.7637e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.75e-04, weight decay: 2.38e-05\n",
            "Epoch 777/1500\n",
            "Val unfiltered loss: 17.978099822998047\n",
            "233/233 - 44s - loss: 14.1561 - val_loss: 13.2316 - lr: 4.7532e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.74e-04, weight decay: 2.37e-05\n",
            "Epoch 778/1500\n",
            "Val unfiltered loss: 18.188758850097656\n",
            "233/233 - 43s - loss: 14.1204 - val_loss: 13.3739 - lr: 4.7427e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 4.73e-04, weight decay: 2.37e-05\n",
            "Epoch 779/1500\n",
            "Val unfiltered loss: 18.529767990112305\n",
            "233/233 - 44s - loss: 14.1421 - val_loss: 13.5272 - lr: 4.7322e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.72e-04, weight decay: 2.36e-05\n",
            "Epoch 780/1500\n",
            "Val unfiltered loss: 18.293813705444336\n",
            "233/233 - 44s - loss: 14.1644 - val_loss: 13.5691 - lr: 4.7217e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.71e-04, weight decay: 2.36e-05\n",
            "Epoch 781/1500\n",
            "Val unfiltered loss: 18.32740020751953\n",
            "233/233 - 44s - loss: 14.1313 - val_loss: 13.5935 - lr: 4.7112e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.70e-04, weight decay: 2.35e-05\n",
            "Epoch 782/1500\n",
            "Val unfiltered loss: 18.404909133911133\n",
            "233/233 - 45s - loss: 14.1189 - val_loss: 13.5418 - lr: 4.7007e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 4.69e-04, weight decay: 2.35e-05\n",
            "Epoch 783/1500\n",
            "Val unfiltered loss: 18.334678649902344\n",
            "233/233 - 44s - loss: 14.1216 - val_loss: 13.2931 - lr: 4.6902e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.68e-04, weight decay: 2.34e-05\n",
            "Epoch 784/1500\n",
            "Val unfiltered loss: 18.297780990600586\n",
            "233/233 - 44s - loss: 14.1542 - val_loss: 13.3789 - lr: 4.6798e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.67e-04, weight decay: 2.33e-05\n",
            "Epoch 785/1500\n",
            "Val unfiltered loss: 18.388267517089844\n",
            "233/233 - 43s - loss: 14.1224 - val_loss: 13.4230 - lr: 4.6693e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.66e-04, weight decay: 2.33e-05\n",
            "Epoch 786/1500\n",
            "Val unfiltered loss: 18.110368728637695\n",
            "233/233 - 44s - loss: 14.0751 - val_loss: 13.2545 - lr: 4.6588e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.65e-04, weight decay: 2.32e-05\n",
            "Epoch 787/1500\n",
            "Val unfiltered loss: 18.62613868713379\n",
            "233/233 - 44s - loss: 14.1760 - val_loss: 13.6580 - lr: 4.6483e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.64e-04, weight decay: 2.32e-05\n",
            "Epoch 788/1500\n",
            "Val unfiltered loss: 18.01873016357422\n",
            "233/233 - 43s - loss: 14.1179 - val_loss: 13.2539 - lr: 4.6378e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 4.63e-04, weight decay: 2.31e-05\n",
            "Epoch 789/1500\n",
            "Val unfiltered loss: 17.929597854614258\n",
            "233/233 - 45s - loss: 14.0732 - val_loss: 13.1906 - lr: 4.6273e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 4.62e-04, weight decay: 2.31e-05\n",
            "Epoch 790/1500\n",
            "Val unfiltered loss: 18.60479736328125\n",
            "233/233 - 44s - loss: 14.0109 - val_loss: 13.6283 - lr: 4.6169e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.61e-04, weight decay: 2.30e-05\n",
            "Epoch 791/1500\n",
            "Val unfiltered loss: 18.24785614013672\n",
            "233/233 - 43s - loss: 14.0531 - val_loss: 13.3089 - lr: 4.6064e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.60e-04, weight decay: 2.30e-05\n",
            "Epoch 792/1500\n",
            "Val unfiltered loss: 18.399505615234375\n",
            "233/233 - 43s - loss: 14.0612 - val_loss: 13.4856 - lr: 4.5959e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.59e-04, weight decay: 2.29e-05\n",
            "Epoch 793/1500\n",
            "Val unfiltered loss: 18.262550354003906\n",
            "233/233 - 44s - loss: 14.1058 - val_loss: 13.4573 - lr: 4.5854e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.57e-04, weight decay: 2.29e-05\n",
            "Epoch 794/1500\n",
            "Val unfiltered loss: 18.143497467041016\n",
            "233/233 - 44s - loss: 14.0505 - val_loss: 13.2936 - lr: 4.5750e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.56e-04, weight decay: 2.28e-05\n",
            "Epoch 795/1500\n",
            "Val unfiltered loss: 18.15974235534668\n",
            "233/233 - 43s - loss: 14.0073 - val_loss: 13.3915 - lr: 4.5645e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.55e-04, weight decay: 2.28e-05\n",
            "Epoch 796/1500\n",
            "Val unfiltered loss: 18.040096282958984\n",
            "233/233 - 45s - loss: 14.0749 - val_loss: 13.2913 - lr: 4.5540e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 4.54e-04, weight decay: 2.27e-05\n",
            "Epoch 797/1500\n",
            "Val unfiltered loss: 18.013748168945312\n",
            "233/233 - 44s - loss: 14.0604 - val_loss: 13.2975 - lr: 4.5436e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.53e-04, weight decay: 2.27e-05\n",
            "Epoch 798/1500\n",
            "Val unfiltered loss: 18.345983505249023\n",
            "233/233 - 43s - loss: 13.9523 - val_loss: 13.3751 - lr: 4.5331e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 4.52e-04, weight decay: 2.26e-05\n",
            "Epoch 799/1500\n",
            "Val unfiltered loss: 18.142333984375\n",
            "233/233 - 43s - loss: 13.9820 - val_loss: 13.2361 - lr: 4.5227e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.51e-04, weight decay: 2.26e-05\n",
            "Epoch 800/1500\n",
            "Val unfiltered loss: 18.14851951599121\n",
            "Val filtered lev distance: 0.8588643657082978\n",
            "Val unfiltered lev distance: 0.810281079791675\n",
            "Sub train lev distance: 0.9569777116083549\n",
            "233/233 - 114s - loss: 13.9120 - val_loss: 13.2629 - lr: 4.5122e-04 - 114s/epoch - 491ms/step\n",
            "learning rate: 4.50e-04, weight decay: 2.25e-05\n",
            "Epoch 801/1500\n",
            "Val unfiltered loss: 18.308382034301758\n",
            "233/233 - 44s - loss: 13.9434 - val_loss: 13.5302 - lr: 4.5017e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.49e-04, weight decay: 2.25e-05\n",
            "Epoch 802/1500\n",
            "Val unfiltered loss: 18.26274871826172\n",
            "233/233 - 43s - loss: 14.0074 - val_loss: 13.2833 - lr: 4.4913e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.48e-04, weight decay: 2.24e-05\n",
            "Epoch 803/1500\n",
            "Val unfiltered loss: 18.325899124145508\n",
            "233/233 - 43s - loss: 13.9691 - val_loss: 13.3881 - lr: 4.4808e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 4.47e-04, weight decay: 2.24e-05\n",
            "Epoch 804/1500\n",
            "Val unfiltered loss: 17.8480167388916\n",
            "233/233 - 45s - loss: 14.0244 - val_loss: 13.1122 - lr: 4.4704e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 4.46e-04, weight decay: 2.23e-05\n",
            "Epoch 805/1500\n",
            "Val unfiltered loss: 18.432130813598633\n",
            "233/233 - 44s - loss: 13.9794 - val_loss: 13.4904 - lr: 4.4599e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.45e-04, weight decay: 2.22e-05\n",
            "Epoch 806/1500\n",
            "Val unfiltered loss: 18.23594856262207\n",
            "233/233 - 44s - loss: 13.9264 - val_loss: 13.4020 - lr: 4.4495e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.44e-04, weight decay: 2.22e-05\n",
            "Epoch 807/1500\n",
            "Val unfiltered loss: 18.374189376831055\n",
            "233/233 - 43s - loss: 14.0592 - val_loss: 13.3984 - lr: 4.4391e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.43e-04, weight decay: 2.21e-05\n",
            "Epoch 808/1500\n",
            "Val unfiltered loss: 18.33287811279297\n",
            "233/233 - 44s - loss: 13.9967 - val_loss: 13.4569 - lr: 4.4286e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.42e-04, weight decay: 2.21e-05\n",
            "Epoch 809/1500\n",
            "Val unfiltered loss: 18.274986267089844\n",
            "233/233 - 43s - loss: 14.0338 - val_loss: 13.3078 - lr: 4.4182e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.41e-04, weight decay: 2.20e-05\n",
            "Epoch 810/1500\n",
            "Val unfiltered loss: 18.230379104614258\n",
            "233/233 - 43s - loss: 13.9317 - val_loss: 13.2189 - lr: 4.4077e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.40e-04, weight decay: 2.20e-05\n",
            "Epoch 811/1500\n",
            "Val unfiltered loss: 18.709707260131836\n",
            "233/233 - 45s - loss: 13.9157 - val_loss: 13.6846 - lr: 4.3973e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 4.39e-04, weight decay: 2.19e-05\n",
            "Epoch 812/1500\n",
            "Val unfiltered loss: 18.236949920654297\n",
            "233/233 - 44s - loss: 13.9596 - val_loss: 13.3289 - lr: 4.3869e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.38e-04, weight decay: 2.19e-05\n",
            "Epoch 813/1500\n",
            "Val unfiltered loss: 18.09300422668457\n",
            "233/233 - 44s - loss: 13.9177 - val_loss: 13.2801 - lr: 4.3765e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.37e-04, weight decay: 2.18e-05\n",
            "Epoch 814/1500\n",
            "Val unfiltered loss: 18.71222496032715\n",
            "233/233 - 44s - loss: 13.8865 - val_loss: 13.6073 - lr: 4.3660e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.36e-04, weight decay: 2.18e-05\n",
            "Epoch 815/1500\n",
            "Val unfiltered loss: 18.37335968017578\n",
            "233/233 - 44s - loss: 13.8880 - val_loss: 13.4285 - lr: 4.3556e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.35e-04, weight decay: 2.17e-05\n",
            "Epoch 816/1500\n",
            "Val unfiltered loss: 18.475847244262695\n",
            "233/233 - 43s - loss: 13.8978 - val_loss: 13.4921 - lr: 4.3452e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.33e-04, weight decay: 2.17e-05\n",
            "Epoch 817/1500\n",
            "Val unfiltered loss: 18.716981887817383\n",
            "233/233 - 43s - loss: 13.8861 - val_loss: 13.4064 - lr: 4.3348e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.32e-04, weight decay: 2.16e-05\n",
            "Epoch 818/1500\n",
            "Val unfiltered loss: 18.220731735229492\n",
            "233/233 - 45s - loss: 13.8962 - val_loss: 13.2925 - lr: 4.3244e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 4.31e-04, weight decay: 2.16e-05\n",
            "Epoch 819/1500\n",
            "Val unfiltered loss: 18.378721237182617\n",
            "233/233 - 43s - loss: 13.9307 - val_loss: 13.3902 - lr: 4.3140e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.30e-04, weight decay: 2.15e-05\n",
            "Epoch 820/1500\n",
            "Val unfiltered loss: 18.63384437561035\n",
            "233/233 - 43s - loss: 13.8502 - val_loss: 13.6958 - lr: 4.3036e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.29e-04, weight decay: 2.15e-05\n",
            "Epoch 821/1500\n",
            "Val unfiltered loss: 18.148426055908203\n",
            "233/233 - 44s - loss: 13.7632 - val_loss: 13.3264 - lr: 4.2932e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.28e-04, weight decay: 2.14e-05\n",
            "Epoch 822/1500\n",
            "Val unfiltered loss: 18.4934139251709\n",
            "233/233 - 44s - loss: 13.7867 - val_loss: 13.5173 - lr: 4.2828e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.27e-04, weight decay: 2.14e-05\n",
            "Epoch 823/1500\n",
            "Val unfiltered loss: 18.49040412902832\n",
            "233/233 - 43s - loss: 13.8004 - val_loss: 13.6032 - lr: 4.2724e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.26e-04, weight decay: 2.13e-05\n",
            "Epoch 824/1500\n",
            "Val unfiltered loss: 18.452312469482422\n",
            "233/233 - 43s - loss: 13.8612 - val_loss: 13.4232 - lr: 4.2620e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.25e-04, weight decay: 2.13e-05\n",
            "Epoch 825/1500\n",
            "Val unfiltered loss: 18.76942253112793\n",
            "233/233 - 45s - loss: 13.8645 - val_loss: 13.5485 - lr: 4.2516e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 4.24e-04, weight decay: 2.12e-05\n",
            "Epoch 826/1500\n",
            "Val unfiltered loss: 18.162099838256836\n",
            "233/233 - 44s - loss: 13.8514 - val_loss: 13.5035 - lr: 4.2412e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.23e-04, weight decay: 2.12e-05\n",
            "Epoch 827/1500\n",
            "Val unfiltered loss: 18.620098114013672\n",
            "233/233 - 43s - loss: 13.7828 - val_loss: 13.5223 - lr: 4.2308e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.22e-04, weight decay: 2.11e-05\n",
            "Epoch 828/1500\n",
            "Val unfiltered loss: 18.495023727416992\n",
            "233/233 - 44s - loss: 13.7906 - val_loss: 13.5530 - lr: 4.2204e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.21e-04, weight decay: 2.11e-05\n",
            "Epoch 829/1500\n",
            "Val unfiltered loss: 18.364896774291992\n",
            "233/233 - 44s - loss: 13.7728 - val_loss: 13.3639 - lr: 4.2100e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.20e-04, weight decay: 2.10e-05\n",
            "Epoch 830/1500\n",
            "Val unfiltered loss: 18.485029220581055\n",
            "233/233 - 44s - loss: 13.7845 - val_loss: 13.5240 - lr: 4.1997e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.19e-04, weight decay: 2.09e-05\n",
            "Epoch 831/1500\n",
            "Val unfiltered loss: 18.617090225219727\n",
            "233/233 - 43s - loss: 13.9235 - val_loss: 13.5246 - lr: 4.1893e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 4.18e-04, weight decay: 2.09e-05\n",
            "Epoch 832/1500\n",
            "Val unfiltered loss: 18.546308517456055\n",
            "233/233 - 44s - loss: 13.8085 - val_loss: 13.5825 - lr: 4.1789e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.17e-04, weight decay: 2.08e-05\n",
            "Epoch 833/1500\n",
            "Val unfiltered loss: 18.473432540893555\n",
            "233/233 - 45s - loss: 13.7634 - val_loss: 13.4696 - lr: 4.1686e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 4.16e-04, weight decay: 2.08e-05\n",
            "Epoch 834/1500\n",
            "Val unfiltered loss: 18.750646591186523\n",
            "233/233 - 43s - loss: 13.7156 - val_loss: 13.6422 - lr: 4.1582e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.15e-04, weight decay: 2.07e-05\n",
            "Epoch 835/1500\n",
            "Val unfiltered loss: 18.537355422973633\n",
            "233/233 - 43s - loss: 13.7157 - val_loss: 13.4405 - lr: 4.1479e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 4.14e-04, weight decay: 2.07e-05\n",
            "Epoch 836/1500\n",
            "Val unfiltered loss: 18.571834564208984\n",
            "233/233 - 44s - loss: 13.7478 - val_loss: 13.5905 - lr: 4.1375e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.13e-04, weight decay: 2.06e-05\n",
            "Epoch 837/1500\n",
            "Val unfiltered loss: 18.402496337890625\n",
            "233/233 - 44s - loss: 13.7865 - val_loss: 13.3643 - lr: 4.1272e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.12e-04, weight decay: 2.06e-05\n",
            "Epoch 838/1500\n",
            "Val unfiltered loss: 18.85768699645996\n",
            "233/233 - 43s - loss: 13.7701 - val_loss: 13.7549 - lr: 4.1168e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 4.11e-04, weight decay: 2.05e-05\n",
            "Epoch 839/1500\n",
            "Val unfiltered loss: 18.73969078063965\n",
            "233/233 - 44s - loss: 13.7101 - val_loss: 13.6167 - lr: 4.1065e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.10e-04, weight decay: 2.05e-05\n",
            "Epoch 840/1500\n",
            "Val unfiltered loss: 18.610645294189453\n",
            "233/233 - 45s - loss: 13.8258 - val_loss: 13.6316 - lr: 4.0961e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 4.09e-04, weight decay: 2.04e-05\n",
            "Epoch 841/1500\n",
            "Val unfiltered loss: 18.703641891479492\n",
            "233/233 - 43s - loss: 13.8518 - val_loss: 13.6312 - lr: 4.0858e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.08e-04, weight decay: 2.04e-05\n",
            "Epoch 842/1500\n",
            "Val unfiltered loss: 18.549680709838867\n",
            "233/233 - 44s - loss: 13.6804 - val_loss: 13.5701 - lr: 4.0755e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.07e-04, weight decay: 2.03e-05\n",
            "Epoch 843/1500\n",
            "Val unfiltered loss: 18.472864151000977\n",
            "233/233 - 44s - loss: 13.6990 - val_loss: 13.5132 - lr: 4.0652e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.05e-04, weight decay: 2.03e-05\n",
            "Epoch 844/1500\n",
            "Val unfiltered loss: 18.644187927246094\n",
            "233/233 - 43s - loss: 13.6494 - val_loss: 13.7165 - lr: 4.0548e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.04e-04, weight decay: 2.02e-05\n",
            "Epoch 845/1500\n",
            "Val unfiltered loss: 18.49198341369629\n",
            "233/233 - 43s - loss: 13.7153 - val_loss: 13.5829 - lr: 4.0445e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.03e-04, weight decay: 2.02e-05\n",
            "Epoch 846/1500\n",
            "Val unfiltered loss: 18.424715042114258\n",
            "233/233 - 44s - loss: 13.6153 - val_loss: 13.4998 - lr: 4.0342e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.02e-04, weight decay: 2.01e-05\n",
            "Epoch 847/1500\n",
            "Val unfiltered loss: 18.65516471862793\n",
            "233/233 - 45s - loss: 13.6360 - val_loss: 13.6098 - lr: 4.0239e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 4.01e-04, weight decay: 2.01e-05\n",
            "Epoch 848/1500\n",
            "Val unfiltered loss: 18.58329963684082\n",
            "233/233 - 43s - loss: 13.7095 - val_loss: 13.6466 - lr: 4.0136e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.00e-04, weight decay: 2.00e-05\n",
            "Epoch 849/1500\n",
            "Val unfiltered loss: 18.652067184448242\n",
            "233/233 - 44s - loss: 13.6665 - val_loss: 13.6741 - lr: 4.0033e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.99e-04, weight decay: 2.00e-05\n",
            "Epoch 850/1500\n",
            "Val unfiltered loss: 18.780221939086914\n",
            "Val filtered lev distance: 0.8614622219311459\n",
            "Val unfiltered lev distance: 0.8132031964378007\n",
            "Sub train lev distance: 0.9615755134212024\n",
            "233/233 - 114s - loss: 13.6371 - val_loss: 13.7908 - lr: 3.9930e-04 - 114s/epoch - 491ms/step\n",
            "learning rate: 3.98e-04, weight decay: 1.99e-05\n",
            "Epoch 851/1500\n",
            "Val unfiltered loss: 18.596593856811523\n",
            "233/233 - 44s - loss: 13.6578 - val_loss: 13.6141 - lr: 3.9827e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.97e-04, weight decay: 1.99e-05\n",
            "Epoch 852/1500\n",
            "Val unfiltered loss: 18.601716995239258\n",
            "233/233 - 44s - loss: 13.6119 - val_loss: 13.6579 - lr: 3.9724e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.96e-04, weight decay: 1.98e-05\n",
            "Epoch 853/1500\n",
            "Val unfiltered loss: 18.720722198486328\n",
            "233/233 - 44s - loss: 13.6748 - val_loss: 13.7165 - lr: 3.9622e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.95e-04, weight decay: 1.98e-05\n",
            "Epoch 854/1500\n",
            "Val unfiltered loss: 18.25497817993164\n",
            "233/233 - 44s - loss: 13.7306 - val_loss: 13.3522 - lr: 3.9519e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.94e-04, weight decay: 1.97e-05\n",
            "Epoch 855/1500\n",
            "Val unfiltered loss: 18.75015640258789\n",
            "233/233 - 45s - loss: 13.6558 - val_loss: 13.7273 - lr: 3.9416e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 3.93e-04, weight decay: 1.97e-05\n",
            "Epoch 856/1500\n",
            "Val unfiltered loss: 18.426212310791016\n",
            "233/233 - 44s - loss: 13.6139 - val_loss: 13.5564 - lr: 3.9313e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.92e-04, weight decay: 1.96e-05\n",
            "Epoch 857/1500\n",
            "Val unfiltered loss: 18.569324493408203\n",
            "233/233 - 44s - loss: 13.6091 - val_loss: 13.6427 - lr: 3.9211e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.91e-04, weight decay: 1.96e-05\n",
            "Epoch 858/1500\n",
            "Val unfiltered loss: 18.904279708862305\n",
            "233/233 - 44s - loss: 13.6544 - val_loss: 13.8912 - lr: 3.9108e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.90e-04, weight decay: 1.95e-05\n",
            "Epoch 859/1500\n",
            "Val unfiltered loss: 18.886516571044922\n",
            "233/233 - 43s - loss: 13.6157 - val_loss: 13.8381 - lr: 3.9006e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.89e-04, weight decay: 1.95e-05\n",
            "Epoch 860/1500\n",
            "Val unfiltered loss: 19.03081512451172\n",
            "233/233 - 44s - loss: 13.6188 - val_loss: 13.8793 - lr: 3.8903e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.88e-04, weight decay: 1.94e-05\n",
            "Epoch 861/1500\n",
            "Val unfiltered loss: 18.742929458618164\n",
            "233/233 - 44s - loss: 13.7029 - val_loss: 13.6673 - lr: 3.8801e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.87e-04, weight decay: 1.93e-05\n",
            "Epoch 862/1500\n",
            "Val unfiltered loss: 18.668703079223633\n",
            "233/233 - 43s - loss: 13.6540 - val_loss: 13.6547 - lr: 3.8698e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.86e-04, weight decay: 1.93e-05\n",
            "Epoch 863/1500\n",
            "Val unfiltered loss: 18.580955505371094\n",
            "233/233 - 43s - loss: 13.5966 - val_loss: 13.5291 - lr: 3.8596e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.85e-04, weight decay: 1.92e-05\n",
            "Epoch 864/1500\n",
            "Val unfiltered loss: 18.65610694885254\n",
            "233/233 - 44s - loss: 13.5877 - val_loss: 13.7516 - lr: 3.8494e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.84e-04, weight decay: 1.92e-05\n",
            "Epoch 865/1500\n",
            "Val unfiltered loss: 18.31516456604004\n",
            "233/233 - 43s - loss: 13.6268 - val_loss: 13.5113 - lr: 3.8392e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.83e-04, weight decay: 1.91e-05\n",
            "Epoch 866/1500\n",
            "Val unfiltered loss: 18.34386444091797\n",
            "233/233 - 44s - loss: 13.6346 - val_loss: 13.4807 - lr: 3.8289e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.82e-04, weight decay: 1.91e-05\n",
            "Epoch 867/1500\n",
            "Val unfiltered loss: 18.483549118041992\n",
            "233/233 - 44s - loss: 13.5218 - val_loss: 13.6183 - lr: 3.8187e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.81e-04, weight decay: 1.90e-05\n",
            "Epoch 868/1500\n",
            "Val unfiltered loss: 18.53874397277832\n",
            "233/233 - 44s - loss: 13.6164 - val_loss: 13.6252 - lr: 3.8085e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.80e-04, weight decay: 1.90e-05\n",
            "Epoch 869/1500\n",
            "Val unfiltered loss: 18.5677433013916\n",
            "233/233 - 44s - loss: 13.5649 - val_loss: 13.4548 - lr: 3.7983e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 3.79e-04, weight decay: 1.89e-05\n",
            "Epoch 870/1500\n",
            "Val unfiltered loss: 18.525175094604492\n",
            "233/233 - 43s - loss: 13.4929 - val_loss: 13.7067 - lr: 3.7881e-04 - 43s/epoch - 185ms/step\n",
            "learning rate: 3.78e-04, weight decay: 1.89e-05\n",
            "Epoch 871/1500\n",
            "Val unfiltered loss: 18.75278663635254\n",
            "233/233 - 44s - loss: 13.6136 - val_loss: 13.7299 - lr: 3.7779e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.77e-04, weight decay: 1.88e-05\n",
            "Epoch 872/1500\n",
            "Val unfiltered loss: 18.473249435424805\n",
            "233/233 - 43s - loss: 13.5362 - val_loss: 13.6337 - lr: 3.7677e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.76e-04, weight decay: 1.88e-05\n",
            "Epoch 873/1500\n",
            "Val unfiltered loss: 18.760021209716797\n",
            "233/233 - 43s - loss: 13.5152 - val_loss: 13.8320 - lr: 3.7576e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.75e-04, weight decay: 1.87e-05\n",
            "Epoch 874/1500\n",
            "Val unfiltered loss: 18.937952041625977\n",
            "233/233 - 44s - loss: 13.6015 - val_loss: 13.7967 - lr: 3.7474e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.74e-04, weight decay: 1.87e-05\n",
            "Epoch 875/1500\n",
            "Val unfiltered loss: 18.647502899169922\n",
            "233/233 - 44s - loss: 13.5278 - val_loss: 13.7188 - lr: 3.7372e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.73e-04, weight decay: 1.86e-05\n",
            "Epoch 876/1500\n",
            "Val unfiltered loss: 19.046890258789062\n",
            "233/233 - 43s - loss: 13.5449 - val_loss: 13.9033 - lr: 3.7271e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 3.72e-04, weight decay: 1.86e-05\n",
            "Epoch 877/1500\n",
            "Val unfiltered loss: 18.674955368041992\n",
            "233/233 - 45s - loss: 13.5003 - val_loss: 13.6310 - lr: 3.7169e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 3.71e-04, weight decay: 1.85e-05\n",
            "Epoch 878/1500\n",
            "Val unfiltered loss: 18.78053092956543\n",
            "233/233 - 44s - loss: 13.4787 - val_loss: 13.8568 - lr: 3.7068e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.70e-04, weight decay: 1.85e-05\n",
            "Epoch 879/1500\n",
            "Val unfiltered loss: 18.921537399291992\n",
            "233/233 - 44s - loss: 13.4922 - val_loss: 13.7654 - lr: 3.6966e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.69e-04, weight decay: 1.84e-05\n",
            "Epoch 880/1500\n",
            "Val unfiltered loss: 18.95164680480957\n",
            "233/233 - 44s - loss: 13.4662 - val_loss: 13.9112 - lr: 3.6865e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.68e-04, weight decay: 1.84e-05\n",
            "Epoch 881/1500\n",
            "Val unfiltered loss: 18.6782283782959\n",
            "233/233 - 44s - loss: 13.5135 - val_loss: 13.7386 - lr: 3.6763e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.67e-04, weight decay: 1.83e-05\n",
            "Epoch 882/1500\n",
            "Val unfiltered loss: 18.997495651245117\n",
            "233/233 - 44s - loss: 13.5176 - val_loss: 14.0268 - lr: 3.6662e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.66e-04, weight decay: 1.83e-05\n",
            "Epoch 883/1500\n",
            "Val unfiltered loss: 18.71468162536621\n",
            "233/233 - 44s - loss: 13.4932 - val_loss: 13.6819 - lr: 3.6561e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.65e-04, weight decay: 1.82e-05\n",
            "Epoch 884/1500\n",
            "Val unfiltered loss: 18.991268157958984\n",
            "233/233 - 46s - loss: 13.4979 - val_loss: 13.7989 - lr: 3.6460e-04 - 46s/epoch - 197ms/step\n",
            "learning rate: 3.64e-04, weight decay: 1.82e-05\n",
            "Epoch 885/1500\n",
            "Val unfiltered loss: 18.606712341308594\n",
            "233/233 - 44s - loss: 13.4063 - val_loss: 13.6807 - lr: 3.6358e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.63e-04, weight decay: 1.81e-05\n",
            "Epoch 886/1500\n",
            "Val unfiltered loss: 18.673175811767578\n",
            "233/233 - 44s - loss: 13.4268 - val_loss: 13.5583 - lr: 3.6257e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.62e-04, weight decay: 1.81e-05\n",
            "Epoch 887/1500\n",
            "Val unfiltered loss: 19.15250015258789\n",
            "233/233 - 43s - loss: 13.4208 - val_loss: 13.9726 - lr: 3.6156e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 3.61e-04, weight decay: 1.80e-05\n",
            "Epoch 888/1500\n",
            "Val unfiltered loss: 19.038677215576172\n",
            "233/233 - 44s - loss: 13.3951 - val_loss: 13.8863 - lr: 3.6055e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.60e-04, weight decay: 1.80e-05\n",
            "Epoch 889/1500\n",
            "Val unfiltered loss: 19.14826202392578\n",
            "233/233 - 44s - loss: 13.4451 - val_loss: 13.8535 - lr: 3.5955e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.59e-04, weight decay: 1.79e-05\n",
            "Epoch 890/1500\n",
            "Val unfiltered loss: 18.435911178588867\n",
            "233/233 - 44s - loss: 13.5099 - val_loss: 13.5228 - lr: 3.5854e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.58e-04, weight decay: 1.79e-05\n",
            "Epoch 891/1500\n",
            "Val unfiltered loss: 19.13408088684082\n",
            "233/233 - 45s - loss: 13.4249 - val_loss: 14.0338 - lr: 3.5753e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 3.57e-04, weight decay: 1.78e-05\n",
            "Epoch 892/1500\n",
            "Val unfiltered loss: 18.741008758544922\n",
            "233/233 - 44s - loss: 13.4124 - val_loss: 13.6004 - lr: 3.5652e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.56e-04, weight decay: 1.78e-05\n",
            "Epoch 893/1500\n",
            "Val unfiltered loss: 18.214473724365234\n",
            "233/233 - 44s - loss: 13.4067 - val_loss: 13.2111 - lr: 3.5552e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.55e-04, weight decay: 1.77e-05\n",
            "Epoch 894/1500\n",
            "Val unfiltered loss: 18.537668228149414\n",
            "233/233 - 44s - loss: 13.3548 - val_loss: 13.5765 - lr: 3.5451e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.54e-04, weight decay: 1.77e-05\n",
            "Epoch 895/1500\n",
            "Val unfiltered loss: 18.984825134277344\n",
            "233/233 - 44s - loss: 13.4501 - val_loss: 13.9013 - lr: 3.5351e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.53e-04, weight decay: 1.76e-05\n",
            "Epoch 896/1500\n",
            "Val unfiltered loss: 19.014184951782227\n",
            "233/233 - 44s - loss: 13.3671 - val_loss: 13.8315 - lr: 3.5250e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.51e-04, weight decay: 1.76e-05\n",
            "Epoch 897/1500\n",
            "Val unfiltered loss: 18.802656173706055\n",
            "233/233 - 43s - loss: 13.4410 - val_loss: 13.7820 - lr: 3.5150e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.50e-04, weight decay: 1.75e-05\n",
            "Epoch 898/1500\n",
            "Val unfiltered loss: 18.627010345458984\n",
            "233/233 - 45s - loss: 13.3433 - val_loss: 13.7917 - lr: 3.5050e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 3.49e-04, weight decay: 1.75e-05\n",
            "Epoch 899/1500\n",
            "Val unfiltered loss: 18.321409225463867\n",
            "233/233 - 44s - loss: 13.3706 - val_loss: 13.5508 - lr: 3.4949e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.48e-04, weight decay: 1.74e-05\n",
            "Epoch 900/1500\n",
            "Val unfiltered loss: 18.674808502197266\n",
            "Val filtered lev distance: 0.8599559019363853\n",
            "Val unfiltered lev distance: 0.8119906174213811\n",
            "Sub train lev distance: 0.9645312431580331\n",
            "233/233 - 119s - loss: 13.3942 - val_loss: 13.7779 - lr: 3.4849e-04 - 119s/epoch - 512ms/step\n",
            "learning rate: 3.47e-04, weight decay: 1.74e-05\n",
            "Epoch 901/1500\n",
            "Val unfiltered loss: 18.86847496032715\n",
            "233/233 - 44s - loss: 13.4167 - val_loss: 13.9299 - lr: 3.4749e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.46e-04, weight decay: 1.73e-05\n",
            "Epoch 902/1500\n",
            "Val unfiltered loss: 18.64841079711914\n",
            "233/233 - 45s - loss: 13.3742 - val_loss: 13.8240 - lr: 3.4649e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 3.45e-04, weight decay: 1.73e-05\n",
            "Epoch 903/1500\n",
            "Val unfiltered loss: 18.866334915161133\n",
            "233/233 - 44s - loss: 13.3278 - val_loss: 13.8011 - lr: 3.4549e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.44e-04, weight decay: 1.72e-05\n",
            "Epoch 904/1500\n",
            "Val unfiltered loss: 18.716468811035156\n",
            "233/233 - 44s - loss: 13.4194 - val_loss: 13.7024 - lr: 3.4449e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.43e-04, weight decay: 1.72e-05\n",
            "Epoch 905/1500\n",
            "Val unfiltered loss: 19.18511199951172\n",
            "233/233 - 44s - loss: 13.3114 - val_loss: 13.9681 - lr: 3.4349e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.42e-04, weight decay: 1.71e-05\n",
            "Epoch 906/1500\n",
            "Val unfiltered loss: 18.899900436401367\n",
            "233/233 - 46s - loss: 13.3457 - val_loss: 13.8790 - lr: 3.4250e-04 - 46s/epoch - 197ms/step\n",
            "learning rate: 3.41e-04, weight decay: 1.71e-05\n",
            "Epoch 907/1500\n",
            "Val unfiltered loss: 18.51818084716797\n",
            "233/233 - 44s - loss: 13.3226 - val_loss: 13.7092 - lr: 3.4150e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.41e-04, weight decay: 1.70e-05\n",
            "Epoch 908/1500\n",
            "Val unfiltered loss: 19.263362884521484\n",
            "233/233 - 44s - loss: 13.3393 - val_loss: 14.1084 - lr: 3.4050e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 3.40e-04, weight decay: 1.70e-05\n",
            "Epoch 909/1500\n",
            "Val unfiltered loss: 19.110069274902344\n",
            "233/233 - 44s - loss: 13.3144 - val_loss: 13.9528 - lr: 3.3951e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.39e-04, weight decay: 1.69e-05\n",
            "Epoch 910/1500\n",
            "Val unfiltered loss: 18.757465362548828\n",
            "233/233 - 44s - loss: 13.2648 - val_loss: 13.8713 - lr: 3.3851e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.38e-04, weight decay: 1.69e-05\n",
            "Epoch 911/1500\n",
            "Val unfiltered loss: 19.485353469848633\n",
            "233/233 - 44s - loss: 13.3287 - val_loss: 14.3178 - lr: 3.3752e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.37e-04, weight decay: 1.68e-05\n",
            "Epoch 912/1500\n",
            "Val unfiltered loss: 19.23633575439453\n",
            "233/233 - 44s - loss: 13.3182 - val_loss: 13.9914 - lr: 3.3653e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.36e-04, weight decay: 1.68e-05\n",
            "Epoch 913/1500\n",
            "Val unfiltered loss: 18.93669319152832\n",
            "233/233 - 45s - loss: 13.3105 - val_loss: 13.8346 - lr: 3.3553e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 3.35e-04, weight decay: 1.67e-05\n",
            "Epoch 914/1500\n",
            "Val unfiltered loss: 18.876855850219727\n",
            "233/233 - 44s - loss: 13.2782 - val_loss: 13.8791 - lr: 3.3454e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.34e-04, weight decay: 1.67e-05\n",
            "Epoch 915/1500\n",
            "Val unfiltered loss: 19.064939498901367\n",
            "233/233 - 44s - loss: 13.2946 - val_loss: 13.9238 - lr: 3.3355e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.33e-04, weight decay: 1.66e-05\n",
            "Epoch 916/1500\n",
            "Val unfiltered loss: 19.2716121673584\n",
            "233/233 - 44s - loss: 13.3032 - val_loss: 14.0517 - lr: 3.3256e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.32e-04, weight decay: 1.66e-05\n",
            "Epoch 917/1500\n",
            "Val unfiltered loss: 19.174732208251953\n",
            "233/233 - 44s - loss: 13.2622 - val_loss: 14.0587 - lr: 3.3157e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.31e-04, weight decay: 1.65e-05\n",
            "Epoch 918/1500\n",
            "Val unfiltered loss: 18.802305221557617\n",
            "233/233 - 44s - loss: 13.2431 - val_loss: 13.7867 - lr: 3.3058e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.30e-04, weight decay: 1.65e-05\n",
            "Epoch 919/1500\n",
            "Val unfiltered loss: 19.446321487426758\n",
            "233/233 - 44s - loss: 13.2589 - val_loss: 14.2388 - lr: 3.2959e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.29e-04, weight decay: 1.64e-05\n",
            "Epoch 920/1500\n",
            "Val unfiltered loss: 19.247669219970703\n",
            "233/233 - 44s - loss: 13.2591 - val_loss: 14.0876 - lr: 3.2861e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.28e-04, weight decay: 1.64e-05\n",
            "Epoch 921/1500\n",
            "Val unfiltered loss: 18.98603057861328\n",
            "233/233 - 45s - loss: 13.2679 - val_loss: 13.8904 - lr: 3.2762e-04 - 45s/epoch - 195ms/step\n",
            "learning rate: 3.27e-04, weight decay: 1.63e-05\n",
            "Epoch 922/1500\n",
            "Val unfiltered loss: 18.564695358276367\n",
            "233/233 - 43s - loss: 13.2907 - val_loss: 13.6495 - lr: 3.2663e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.26e-04, weight decay: 1.63e-05\n",
            "Epoch 923/1500\n",
            "Val unfiltered loss: 18.64768409729004\n",
            "233/233 - 44s - loss: 13.3443 - val_loss: 13.7976 - lr: 3.2565e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.25e-04, weight decay: 1.62e-05\n",
            "Epoch 924/1500\n",
            "Val unfiltered loss: 18.70051383972168\n",
            "233/233 - 44s - loss: 13.2173 - val_loss: 13.7033 - lr: 3.2466e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.24e-04, weight decay: 1.62e-05\n",
            "Epoch 925/1500\n",
            "Val unfiltered loss: 19.037273406982422\n",
            "233/233 - 44s - loss: 13.2596 - val_loss: 13.9869 - lr: 3.2368e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.23e-04, weight decay: 1.61e-05\n",
            "Epoch 926/1500\n",
            "Val unfiltered loss: 19.083763122558594\n",
            "233/233 - 44s - loss: 13.2294 - val_loss: 14.0530 - lr: 3.2270e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.22e-04, weight decay: 1.61e-05\n",
            "Epoch 927/1500\n",
            "Val unfiltered loss: 19.05295181274414\n",
            "233/233 - 44s - loss: 13.2378 - val_loss: 14.0299 - lr: 3.2172e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.21e-04, weight decay: 1.60e-05\n",
            "Epoch 928/1500\n",
            "Val unfiltered loss: 18.96162223815918\n",
            "233/233 - 45s - loss: 13.2367 - val_loss: 13.8225 - lr: 3.2073e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 3.20e-04, weight decay: 1.60e-05\n",
            "Epoch 929/1500\n",
            "Val unfiltered loss: 18.967403411865234\n",
            "233/233 - 44s - loss: 13.1913 - val_loss: 13.8856 - lr: 3.1975e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.19e-04, weight decay: 1.59e-05\n",
            "Epoch 930/1500\n",
            "Val unfiltered loss: 19.164411544799805\n",
            "233/233 - 43s - loss: 13.1287 - val_loss: 13.9339 - lr: 3.1877e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.18e-04, weight decay: 1.59e-05\n",
            "Epoch 931/1500\n",
            "Val unfiltered loss: 19.49956703186035\n",
            "233/233 - 44s - loss: 13.1505 - val_loss: 14.0735 - lr: 3.1780e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.17e-04, weight decay: 1.58e-05\n",
            "Epoch 932/1500\n",
            "Val unfiltered loss: 19.231264114379883\n",
            "233/233 - 44s - loss: 13.2062 - val_loss: 13.8940 - lr: 3.1682e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.16e-04, weight decay: 1.58e-05\n",
            "Epoch 933/1500\n",
            "Val unfiltered loss: 19.162567138671875\n",
            "233/233 - 43s - loss: 13.2320 - val_loss: 13.8836 - lr: 3.1584e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.15e-04, weight decay: 1.57e-05\n",
            "Epoch 934/1500\n",
            "Val unfiltered loss: 19.039274215698242\n",
            "233/233 - 43s - loss: 13.1214 - val_loss: 13.8782 - lr: 3.1486e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.14e-04, weight decay: 1.57e-05\n",
            "Epoch 935/1500\n",
            "Val unfiltered loss: 19.267139434814453\n",
            "233/233 - 45s - loss: 13.1570 - val_loss: 13.9235 - lr: 3.1389e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 3.13e-04, weight decay: 1.56e-05\n",
            "Epoch 936/1500\n",
            "Val unfiltered loss: 19.348304748535156\n",
            "233/233 - 44s - loss: 13.1512 - val_loss: 14.2121 - lr: 3.1291e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.12e-04, weight decay: 1.56e-05\n",
            "Epoch 937/1500\n",
            "Val unfiltered loss: 18.93899154663086\n",
            "233/233 - 43s - loss: 13.1925 - val_loss: 13.9173 - lr: 3.1194e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.11e-04, weight decay: 1.55e-05\n",
            "Epoch 938/1500\n",
            "Val unfiltered loss: 18.921710968017578\n",
            "233/233 - 44s - loss: 13.1772 - val_loss: 13.8169 - lr: 3.1097e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.10e-04, weight decay: 1.55e-05\n",
            "Epoch 939/1500\n",
            "Val unfiltered loss: 19.020139694213867\n",
            "233/233 - 44s - loss: 13.2383 - val_loss: 13.9287 - lr: 3.0999e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.09e-04, weight decay: 1.55e-05\n",
            "Epoch 940/1500\n",
            "Val unfiltered loss: 18.963640213012695\n",
            "233/233 - 44s - loss: 13.1064 - val_loss: 13.8651 - lr: 3.0902e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.08e-04, weight decay: 1.54e-05\n",
            "Epoch 941/1500\n",
            "Val unfiltered loss: 19.189790725708008\n",
            "233/233 - 44s - loss: 13.1090 - val_loss: 14.0915 - lr: 3.0805e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.07e-04, weight decay: 1.54e-05\n",
            "Epoch 942/1500\n",
            "Val unfiltered loss: 19.378231048583984\n",
            "233/233 - 45s - loss: 13.1281 - val_loss: 14.2743 - lr: 3.0708e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 3.06e-04, weight decay: 1.53e-05\n",
            "Epoch 943/1500\n",
            "Val unfiltered loss: 18.94731330871582\n",
            "233/233 - 43s - loss: 13.1010 - val_loss: 13.9090 - lr: 3.0611e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.05e-04, weight decay: 1.53e-05\n",
            "Epoch 944/1500\n",
            "Val unfiltered loss: 19.361732482910156\n",
            "233/233 - 43s - loss: 13.0765 - val_loss: 14.1777 - lr: 3.0515e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.04e-04, weight decay: 1.52e-05\n",
            "Epoch 945/1500\n",
            "Val unfiltered loss: 18.971860885620117\n",
            "233/233 - 44s - loss: 13.0898 - val_loss: 13.8972 - lr: 3.0418e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.03e-04, weight decay: 1.52e-05\n",
            "Epoch 946/1500\n",
            "Val unfiltered loss: 18.945049285888672\n",
            "233/233 - 44s - loss: 13.1460 - val_loss: 13.8649 - lr: 3.0321e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.02e-04, weight decay: 1.51e-05\n",
            "Epoch 947/1500\n",
            "Val unfiltered loss: 19.24620819091797\n",
            "233/233 - 43s - loss: 13.1727 - val_loss: 13.9389 - lr: 3.0225e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.01e-04, weight decay: 1.51e-05\n",
            "Epoch 948/1500\n",
            "Val unfiltered loss: 19.080894470214844\n",
            "233/233 - 44s - loss: 13.1286 - val_loss: 13.9596 - lr: 3.0128e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.00e-04, weight decay: 1.50e-05\n",
            "Epoch 949/1500\n",
            "Val unfiltered loss: 19.050823211669922\n",
            "233/233 - 44s - loss: 13.1227 - val_loss: 13.9131 - lr: 3.0032e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.99e-04, weight decay: 1.50e-05\n",
            "Epoch 950/1500\n",
            "Val unfiltered loss: 19.33220672607422\n",
            "Val filtered lev distance: 0.8621171436679983\n",
            "Val unfiltered lev distance: 0.813898938496402\n",
            "Sub train lev distance: 0.9678810701931077\n",
            "233/233 - 114s - loss: 13.1011 - val_loss: 14.0051 - lr: 2.9935e-04 - 114s/epoch - 489ms/step\n",
            "learning rate: 2.98e-04, weight decay: 1.49e-05\n",
            "Epoch 951/1500\n",
            "Val unfiltered loss: 19.317970275878906\n",
            "233/233 - 45s - loss: 13.1059 - val_loss: 13.9376 - lr: 2.9839e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 2.97e-04, weight decay: 1.49e-05\n",
            "Epoch 952/1500\n",
            "Val unfiltered loss: 19.16948890686035\n",
            "233/233 - 44s - loss: 13.0608 - val_loss: 13.9768 - lr: 2.9743e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.96e-04, weight decay: 1.48e-05\n",
            "Epoch 953/1500\n",
            "Val unfiltered loss: 19.113414764404297\n",
            "233/233 - 44s - loss: 13.0093 - val_loss: 13.8481 - lr: 2.9647e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.96e-04, weight decay: 1.48e-05\n",
            "Epoch 954/1500\n",
            "Val unfiltered loss: 19.0196533203125\n",
            "233/233 - 43s - loss: 13.1110 - val_loss: 13.8601 - lr: 2.9551e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.95e-04, weight decay: 1.47e-05\n",
            "Epoch 955/1500\n",
            "Val unfiltered loss: 18.982736587524414\n",
            "233/233 - 44s - loss: 13.0504 - val_loss: 13.8352 - lr: 2.9455e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.94e-04, weight decay: 1.47e-05\n",
            "Epoch 956/1500\n",
            "Val unfiltered loss: 19.132400512695312\n",
            "233/233 - 44s - loss: 13.0515 - val_loss: 14.0170 - lr: 2.9360e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.93e-04, weight decay: 1.46e-05\n",
            "Epoch 957/1500\n",
            "Val unfiltered loss: 19.269105911254883\n",
            "233/233 - 44s - loss: 13.0847 - val_loss: 14.0788 - lr: 2.9264e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.92e-04, weight decay: 1.46e-05\n",
            "Epoch 958/1500\n",
            "Val unfiltered loss: 18.993955612182617\n",
            "233/233 - 45s - loss: 13.0248 - val_loss: 13.8534 - lr: 2.9168e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 2.91e-04, weight decay: 1.45e-05\n",
            "Epoch 959/1500\n",
            "Val unfiltered loss: 19.083555221557617\n",
            "233/233 - 44s - loss: 12.9947 - val_loss: 13.8750 - lr: 2.9073e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.90e-04, weight decay: 1.45e-05\n",
            "Epoch 960/1500\n",
            "Val unfiltered loss: 19.5162410736084\n",
            "233/233 - 44s - loss: 13.0827 - val_loss: 14.0761 - lr: 2.8978e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.89e-04, weight decay: 1.44e-05\n",
            "Epoch 961/1500\n",
            "Val unfiltered loss: 19.888193130493164\n",
            "233/233 - 44s - loss: 12.9664 - val_loss: 14.4439 - lr: 2.8882e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.88e-04, weight decay: 1.44e-05\n",
            "Epoch 962/1500\n",
            "Val unfiltered loss: 19.432798385620117\n",
            "233/233 - 44s - loss: 13.0541 - val_loss: 14.1837 - lr: 2.8787e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.87e-04, weight decay: 1.43e-05\n",
            "Epoch 963/1500\n",
            "Val unfiltered loss: 19.19791603088379\n",
            "233/233 - 44s - loss: 13.0183 - val_loss: 14.2103 - lr: 2.8692e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 2.86e-04, weight decay: 1.43e-05\n",
            "Epoch 964/1500\n",
            "Val unfiltered loss: 19.390769958496094\n",
            "233/233 - 43s - loss: 13.0019 - val_loss: 14.1271 - lr: 2.8597e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.85e-04, weight decay: 1.43e-05\n",
            "Epoch 965/1500\n",
            "Val unfiltered loss: 19.275476455688477\n",
            "233/233 - 45s - loss: 12.9429 - val_loss: 13.9945 - lr: 2.8502e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.84e-04, weight decay: 1.42e-05\n",
            "Epoch 966/1500\n",
            "Val unfiltered loss: 19.146745681762695\n",
            "233/233 - 44s - loss: 12.9546 - val_loss: 14.0880 - lr: 2.8407e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.83e-04, weight decay: 1.42e-05\n",
            "Epoch 967/1500\n",
            "Val unfiltered loss: 19.395751953125\n",
            "233/233 - 44s - loss: 13.0320 - val_loss: 14.2159 - lr: 2.8313e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.82e-04, weight decay: 1.41e-05\n",
            "Epoch 968/1500\n",
            "Val unfiltered loss: 18.980487823486328\n",
            "233/233 - 44s - loss: 12.9960 - val_loss: 13.9412 - lr: 2.8218e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.81e-04, weight decay: 1.41e-05\n",
            "Epoch 969/1500\n",
            "Val unfiltered loss: 19.418066024780273\n",
            "233/233 - 44s - loss: 13.0135 - val_loss: 14.1900 - lr: 2.8123e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.80e-04, weight decay: 1.40e-05\n",
            "Epoch 970/1500\n",
            "Val unfiltered loss: 19.599470138549805\n",
            "233/233 - 43s - loss: 13.0184 - val_loss: 14.3128 - lr: 2.8029e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.79e-04, weight decay: 1.40e-05\n",
            "Epoch 971/1500\n",
            "Val unfiltered loss: 19.398357391357422\n",
            "233/233 - 43s - loss: 12.9771 - val_loss: 14.0796 - lr: 2.7935e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.78e-04, weight decay: 1.39e-05\n",
            "Epoch 972/1500\n",
            "Val unfiltered loss: 19.478031158447266\n",
            "233/233 - 45s - loss: 12.9810 - val_loss: 14.0929 - lr: 2.7840e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.77e-04, weight decay: 1.39e-05\n",
            "Epoch 973/1500\n",
            "Val unfiltered loss: 19.476821899414062\n",
            "233/233 - 44s - loss: 12.9468 - val_loss: 14.0689 - lr: 2.7746e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.77e-04, weight decay: 1.38e-05\n",
            "Epoch 974/1500\n",
            "Val unfiltered loss: 19.269777297973633\n",
            "233/233 - 43s - loss: 13.0124 - val_loss: 13.9962 - lr: 2.7652e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.76e-04, weight decay: 1.38e-05\n",
            "Epoch 975/1500\n",
            "Val unfiltered loss: 19.356809616088867\n",
            "233/233 - 43s - loss: 12.9701 - val_loss: 14.1692 - lr: 2.7558e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.75e-04, weight decay: 1.37e-05\n",
            "Epoch 976/1500\n",
            "Val unfiltered loss: 19.1486873626709\n",
            "233/233 - 44s - loss: 12.8859 - val_loss: 13.9704 - lr: 2.7464e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.74e-04, weight decay: 1.37e-05\n",
            "Epoch 977/1500\n",
            "Val unfiltered loss: 19.27535629272461\n",
            "233/233 - 44s - loss: 12.9524 - val_loss: 13.9566 - lr: 2.7371e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.73e-04, weight decay: 1.36e-05\n",
            "Epoch 978/1500\n",
            "Val unfiltered loss: 19.589277267456055\n",
            "233/233 - 44s - loss: 12.9467 - val_loss: 14.2170 - lr: 2.7277e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.72e-04, weight decay: 1.36e-05\n",
            "Epoch 979/1500\n",
            "Val unfiltered loss: 19.384769439697266\n",
            "233/233 - 43s - loss: 12.9633 - val_loss: 14.0034 - lr: 2.7184e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.71e-04, weight decay: 1.35e-05\n",
            "Epoch 980/1500\n",
            "Val unfiltered loss: 19.229677200317383\n",
            "233/233 - 45s - loss: 12.9333 - val_loss: 14.1599 - lr: 2.7090e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 2.70e-04, weight decay: 1.35e-05\n",
            "Epoch 981/1500\n",
            "Val unfiltered loss: 19.11952781677246\n",
            "233/233 - 44s - loss: 12.9253 - val_loss: 14.0020 - lr: 2.6997e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.69e-04, weight decay: 1.35e-05\n",
            "Epoch 982/1500\n",
            "Val unfiltered loss: 19.290735244750977\n",
            "233/233 - 44s - loss: 12.8873 - val_loss: 14.0796 - lr: 2.6904e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.68e-04, weight decay: 1.34e-05\n",
            "Epoch 983/1500\n",
            "Val unfiltered loss: 19.272916793823242\n",
            "233/233 - 44s - loss: 12.9446 - val_loss: 13.9867 - lr: 2.6810e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.67e-04, weight decay: 1.34e-05\n",
            "Epoch 984/1500\n",
            "Val unfiltered loss: 19.239545822143555\n",
            "233/233 - 44s - loss: 12.9080 - val_loss: 14.0603 - lr: 2.6717e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.66e-04, weight decay: 1.33e-05\n",
            "Epoch 985/1500\n",
            "Val unfiltered loss: 19.394174575805664\n",
            "233/233 - 44s - loss: 12.9339 - val_loss: 14.0610 - lr: 2.6624e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.65e-04, weight decay: 1.33e-05\n",
            "Epoch 986/1500\n",
            "Val unfiltered loss: 19.094348907470703\n",
            "233/233 - 44s - loss: 12.8704 - val_loss: 13.9373 - lr: 2.6532e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.64e-04, weight decay: 1.32e-05\n",
            "Epoch 987/1500\n",
            "Val unfiltered loss: 19.29380989074707\n",
            "233/233 - 45s - loss: 12.9131 - val_loss: 14.1825 - lr: 2.6439e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 2.63e-04, weight decay: 1.32e-05\n",
            "Epoch 988/1500\n",
            "Val unfiltered loss: 19.083900451660156\n",
            "233/233 - 43s - loss: 12.8517 - val_loss: 14.0656 - lr: 2.6346e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.63e-04, weight decay: 1.31e-05\n",
            "Epoch 989/1500\n",
            "Val unfiltered loss: 19.05890464782715\n",
            "233/233 - 43s - loss: 12.9234 - val_loss: 13.8946 - lr: 2.6254e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.62e-04, weight decay: 1.31e-05\n",
            "Epoch 990/1500\n",
            "Val unfiltered loss: 19.199121475219727\n",
            "233/233 - 44s - loss: 12.8945 - val_loss: 13.9374 - lr: 2.6161e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.61e-04, weight decay: 1.30e-05\n",
            "Epoch 991/1500\n",
            "Val unfiltered loss: 19.741899490356445\n",
            "233/233 - 44s - loss: 12.9211 - val_loss: 14.2945 - lr: 2.6069e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.60e-04, weight decay: 1.30e-05\n",
            "Epoch 992/1500\n",
            "Val unfiltered loss: 19.488792419433594\n",
            "233/233 - 43s - loss: 12.8222 - val_loss: 14.1728 - lr: 2.5977e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.59e-04, weight decay: 1.29e-05\n",
            "Epoch 993/1500\n",
            "Val unfiltered loss: 19.30035400390625\n",
            "233/233 - 43s - loss: 12.8802 - val_loss: 14.1632 - lr: 2.5885e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.58e-04, weight decay: 1.29e-05\n",
            "Epoch 994/1500\n",
            "Val unfiltered loss: 19.60894012451172\n",
            "233/233 - 45s - loss: 12.8618 - val_loss: 14.2148 - lr: 2.5793e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 2.57e-04, weight decay: 1.29e-05\n",
            "Epoch 995/1500\n",
            "Val unfiltered loss: 19.55052375793457\n",
            "233/233 - 44s - loss: 12.8376 - val_loss: 14.3561 - lr: 2.5701e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.56e-04, weight decay: 1.28e-05\n",
            "Epoch 996/1500\n",
            "Val unfiltered loss: 19.599470138549805\n",
            "233/233 - 43s - loss: 12.9293 - val_loss: 14.3927 - lr: 2.5609e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.55e-04, weight decay: 1.28e-05\n",
            "Epoch 997/1500\n",
            "Val unfiltered loss: 19.294984817504883\n",
            "233/233 - 44s - loss: 12.8534 - val_loss: 14.1264 - lr: 2.5517e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.54e-04, weight decay: 1.27e-05\n",
            "Epoch 998/1500\n",
            "Val unfiltered loss: 19.763957977294922\n",
            "233/233 - 43s - loss: 12.8445 - val_loss: 14.5298 - lr: 2.5426e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.53e-04, weight decay: 1.27e-05\n",
            "Epoch 999/1500\n",
            "Val unfiltered loss: 19.45562744140625\n",
            "233/233 - 43s - loss: 12.7973 - val_loss: 14.2516 - lr: 2.5334e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.52e-04, weight decay: 1.26e-05\n",
            "Epoch 1000/1500\n",
            "Val unfiltered loss: 19.335926055908203\n",
            "Val filtered lev distance: 0.8627938961294125\n",
            "Val unfiltered lev distance: 0.8142766270424999\n",
            "Sub train lev distance: 0.9708149056355914\n",
            "233/233 - 117s - loss: 12.7535 - val_loss: 14.0567 - lr: 2.5243e-04 - 117s/epoch - 501ms/step\n",
            "learning rate: 2.52e-04, weight decay: 1.26e-05\n",
            "Epoch 1001/1500\n",
            "Val unfiltered loss: 18.912578582763672\n",
            "233/233 - 44s - loss: 12.7528 - val_loss: 13.9413 - lr: 2.5152e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.51e-04, weight decay: 1.25e-05\n",
            "Epoch 1002/1500\n",
            "Val unfiltered loss: 19.449434280395508\n",
            "233/233 - 45s - loss: 12.7585 - val_loss: 14.1741 - lr: 2.5061e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.50e-04, weight decay: 1.25e-05\n",
            "Epoch 1003/1500\n",
            "Val unfiltered loss: 19.016162872314453\n",
            "233/233 - 44s - loss: 12.8078 - val_loss: 13.8773 - lr: 2.4970e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.49e-04, weight decay: 1.24e-05\n",
            "Epoch 1004/1500\n",
            "Val unfiltered loss: 19.332923889160156\n",
            "233/233 - 44s - loss: 12.7832 - val_loss: 14.1480 - lr: 2.4879e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.48e-04, weight decay: 1.24e-05\n",
            "Epoch 1005/1500\n",
            "Val unfiltered loss: 19.471271514892578\n",
            "233/233 - 43s - loss: 12.8595 - val_loss: 14.1243 - lr: 2.4788e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.47e-04, weight decay: 1.23e-05\n",
            "Epoch 1006/1500\n",
            "Val unfiltered loss: 19.286775588989258\n",
            "233/233 - 44s - loss: 12.7940 - val_loss: 14.1541 - lr: 2.4697e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.46e-04, weight decay: 1.23e-05\n",
            "Epoch 1007/1500\n",
            "Val unfiltered loss: 19.136262893676758\n",
            "233/233 - 43s - loss: 12.8644 - val_loss: 13.9405 - lr: 2.4607e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.45e-04, weight decay: 1.23e-05\n",
            "Epoch 1008/1500\n",
            "Val unfiltered loss: 19.381635665893555\n",
            "233/233 - 44s - loss: 12.7889 - val_loss: 14.0701 - lr: 2.4516e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.44e-04, weight decay: 1.22e-05\n",
            "Epoch 1009/1500\n",
            "Val unfiltered loss: 19.37872886657715\n",
            "233/233 - 45s - loss: 12.8061 - val_loss: 14.1943 - lr: 2.4426e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.43e-04, weight decay: 1.22e-05\n",
            "Epoch 1010/1500\n",
            "Val unfiltered loss: 19.507596969604492\n",
            "233/233 - 43s - loss: 12.8161 - val_loss: 14.2244 - lr: 2.4336e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.42e-04, weight decay: 1.21e-05\n",
            "Epoch 1011/1500\n",
            "Val unfiltered loss: 19.636198043823242\n",
            "233/233 - 44s - loss: 12.7712 - val_loss: 14.2221 - lr: 2.4246e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 2.42e-04, weight decay: 1.21e-05\n",
            "Epoch 1012/1500\n",
            "Val unfiltered loss: 19.481101989746094\n",
            "233/233 - 44s - loss: 12.7328 - val_loss: 14.2615 - lr: 2.4156e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.41e-04, weight decay: 1.20e-05\n",
            "Epoch 1013/1500\n",
            "Val unfiltered loss: 19.477615356445312\n",
            "233/233 - 44s - loss: 12.7259 - val_loss: 14.3254 - lr: 2.4066e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.40e-04, weight decay: 1.20e-05\n",
            "Epoch 1014/1500\n",
            "Val unfiltered loss: 19.107484817504883\n",
            "233/233 - 44s - loss: 12.7612 - val_loss: 13.9472 - lr: 2.3976e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.39e-04, weight decay: 1.19e-05\n",
            "Epoch 1015/1500\n",
            "Val unfiltered loss: 19.555524826049805\n",
            "233/233 - 44s - loss: 12.7757 - val_loss: 14.1183 - lr: 2.3886e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.38e-04, weight decay: 1.19e-05\n",
            "Epoch 1016/1500\n",
            "Val unfiltered loss: 19.736351013183594\n",
            "233/233 - 45s - loss: 12.7763 - val_loss: 14.3404 - lr: 2.3797e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 2.37e-04, weight decay: 1.19e-05\n",
            "Epoch 1017/1500\n",
            "Val unfiltered loss: 19.36923599243164\n",
            "233/233 - 44s - loss: 12.8020 - val_loss: 14.0424 - lr: 2.3707e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.36e-04, weight decay: 1.18e-05\n",
            "Epoch 1018/1500\n",
            "Val unfiltered loss: 19.628868103027344\n",
            "233/233 - 44s - loss: 12.7170 - val_loss: 14.3256 - lr: 2.3618e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.35e-04, weight decay: 1.18e-05\n",
            "Epoch 1019/1500\n",
            "Val unfiltered loss: 19.32730484008789\n",
            "233/233 - 44s - loss: 12.7102 - val_loss: 14.0520 - lr: 2.3529e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.34e-04, weight decay: 1.17e-05\n",
            "Epoch 1020/1500\n",
            "Val unfiltered loss: 19.625577926635742\n",
            "233/233 - 44s - loss: 12.7334 - val_loss: 14.4175 - lr: 2.3440e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.34e-04, weight decay: 1.17e-05\n",
            "Epoch 1021/1500\n",
            "Val unfiltered loss: 19.614505767822266\n",
            "233/233 - 44s - loss: 12.7578 - val_loss: 14.2174 - lr: 2.3351e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.33e-04, weight decay: 1.16e-05\n",
            "Epoch 1022/1500\n",
            "Val unfiltered loss: 19.54999542236328\n",
            "233/233 - 43s - loss: 12.7311 - val_loss: 14.2884 - lr: 2.3262e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.32e-04, weight decay: 1.16e-05\n",
            "Epoch 1023/1500\n",
            "Val unfiltered loss: 19.614152908325195\n",
            "233/233 - 45s - loss: 12.7049 - val_loss: 14.2935 - lr: 2.3173e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 2.31e-04, weight decay: 1.15e-05\n",
            "Epoch 1024/1500\n",
            "Val unfiltered loss: 19.75037956237793\n",
            "233/233 - 44s - loss: 12.7312 - val_loss: 14.3295 - lr: 2.3085e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.30e-04, weight decay: 1.15e-05\n",
            "Epoch 1025/1500\n",
            "Val unfiltered loss: 19.599069595336914\n",
            "233/233 - 44s - loss: 12.7174 - val_loss: 14.3391 - lr: 2.2996e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.29e-04, weight decay: 1.15e-05\n",
            "Epoch 1026/1500\n",
            "Val unfiltered loss: 19.514205932617188\n",
            "233/233 - 43s - loss: 12.7283 - val_loss: 14.2064 - lr: 2.2908e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.28e-04, weight decay: 1.14e-05\n",
            "Epoch 1027/1500\n",
            "Val unfiltered loss: 19.65691375732422\n",
            "233/233 - 44s - loss: 12.7357 - val_loss: 14.3075 - lr: 2.2819e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.27e-04, weight decay: 1.14e-05\n",
            "Epoch 1028/1500\n",
            "Val unfiltered loss: 19.647443771362305\n",
            "233/233 - 44s - loss: 12.6905 - val_loss: 14.1935 - lr: 2.2731e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.26e-04, weight decay: 1.13e-05\n",
            "Epoch 1029/1500\n",
            "Val unfiltered loss: 19.77203369140625\n",
            "233/233 - 44s - loss: 12.7387 - val_loss: 14.3966 - lr: 2.2643e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.26e-04, weight decay: 1.13e-05\n",
            "Epoch 1030/1500\n",
            "Val unfiltered loss: 19.57859992980957\n",
            "233/233 - 44s - loss: 12.6923 - val_loss: 14.2936 - lr: 2.2555e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 2.25e-04, weight decay: 1.12e-05\n",
            "Epoch 1031/1500\n",
            "Val unfiltered loss: 19.471925735473633\n",
            "233/233 - 44s - loss: 12.6728 - val_loss: 14.2204 - lr: 2.2468e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.24e-04, weight decay: 1.12e-05\n",
            "Epoch 1032/1500\n",
            "Val unfiltered loss: 19.64893913269043\n",
            "233/233 - 44s - loss: 12.6499 - val_loss: 14.2631 - lr: 2.2380e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.23e-04, weight decay: 1.11e-05\n",
            "Epoch 1033/1500\n",
            "Val unfiltered loss: 19.72350311279297\n",
            "233/233 - 44s - loss: 12.7264 - val_loss: 14.2974 - lr: 2.2293e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.22e-04, weight decay: 1.11e-05\n",
            "Epoch 1034/1500\n",
            "Val unfiltered loss: 19.726659774780273\n",
            "233/233 - 44s - loss: 12.6993 - val_loss: 14.4952 - lr: 2.2205e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.21e-04, weight decay: 1.11e-05\n",
            "Epoch 1035/1500\n",
            "Val unfiltered loss: 19.293554306030273\n",
            "233/233 - 44s - loss: 12.6866 - val_loss: 14.0873 - lr: 2.2118e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.20e-04, weight decay: 1.10e-05\n",
            "Epoch 1036/1500\n",
            "Val unfiltered loss: 19.785688400268555\n",
            "233/233 - 44s - loss: 12.6782 - val_loss: 14.3606 - lr: 2.2031e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.19e-04, weight decay: 1.10e-05\n",
            "Epoch 1037/1500\n",
            "Val unfiltered loss: 19.639450073242188\n",
            "233/233 - 45s - loss: 12.6723 - val_loss: 14.1403 - lr: 2.1944e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.19e-04, weight decay: 1.09e-05\n",
            "Epoch 1038/1500\n",
            "Val unfiltered loss: 19.75702667236328\n",
            "233/233 - 44s - loss: 12.7104 - val_loss: 14.3773 - lr: 2.1857e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.18e-04, weight decay: 1.09e-05\n",
            "Epoch 1039/1500\n",
            "Val unfiltered loss: 19.50457763671875\n",
            "233/233 - 43s - loss: 12.6042 - val_loss: 14.2553 - lr: 2.1770e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.17e-04, weight decay: 1.08e-05\n",
            "Epoch 1040/1500\n",
            "Val unfiltered loss: 19.6428165435791\n",
            "233/233 - 43s - loss: 12.6427 - val_loss: 14.2813 - lr: 2.1683e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.16e-04, weight decay: 1.08e-05\n",
            "Epoch 1041/1500\n",
            "Val unfiltered loss: 19.619308471679688\n",
            "233/233 - 44s - loss: 12.5984 - val_loss: 14.3448 - lr: 2.1597e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.15e-04, weight decay: 1.08e-05\n",
            "Epoch 1042/1500\n",
            "Val unfiltered loss: 19.91615867614746\n",
            "233/233 - 44s - loss: 12.6019 - val_loss: 14.4109 - lr: 2.1510e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.14e-04, weight decay: 1.07e-05\n",
            "Epoch 1043/1500\n",
            "Val unfiltered loss: 19.446212768554688\n",
            "233/233 - 43s - loss: 12.6732 - val_loss: 14.1469 - lr: 2.1424e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.13e-04, weight decay: 1.07e-05\n",
            "Epoch 1044/1500\n",
            "Val unfiltered loss: 19.794281005859375\n",
            "233/233 - 45s - loss: 12.6446 - val_loss: 14.3771 - lr: 2.1338e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 2.13e-04, weight decay: 1.06e-05\n",
            "Epoch 1045/1500\n",
            "Val unfiltered loss: 19.729642868041992\n",
            "233/233 - 44s - loss: 12.6265 - val_loss: 14.2729 - lr: 2.1252e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.12e-04, weight decay: 1.06e-05\n",
            "Epoch 1046/1500\n",
            "Val unfiltered loss: 19.664291381835938\n",
            "233/233 - 43s - loss: 12.6720 - val_loss: 14.2040 - lr: 2.1166e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.11e-04, weight decay: 1.05e-05\n",
            "Epoch 1047/1500\n",
            "Val unfiltered loss: 19.81511688232422\n",
            "233/233 - 44s - loss: 12.6179 - val_loss: 14.2787 - lr: 2.1080e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.10e-04, weight decay: 1.05e-05\n",
            "Epoch 1048/1500\n",
            "Val unfiltered loss: 19.771095275878906\n",
            "233/233 - 44s - loss: 12.6150 - val_loss: 14.2665 - lr: 2.0995e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.09e-04, weight decay: 1.05e-05\n",
            "Epoch 1049/1500\n",
            "Val unfiltered loss: 19.643278121948242\n",
            "233/233 - 44s - loss: 12.5838 - val_loss: 14.1274 - lr: 2.0909e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.08e-04, weight decay: 1.04e-05\n",
            "Epoch 1050/1500\n",
            "Val unfiltered loss: 19.80203628540039\n",
            "Val filtered lev distance: 0.8626410810574803\n",
            "Val unfiltered lev distance: 0.8147537073112551\n",
            "Sub train lev distance: 0.9719971975303235\n",
            "233/233 - 119s - loss: 12.6139 - val_loss: 14.3343 - lr: 2.0824e-04 - 119s/epoch - 509ms/step\n",
            "learning rate: 2.07e-04, weight decay: 1.04e-05\n",
            "Epoch 1051/1500\n",
            "Val unfiltered loss: 19.869783401489258\n",
            "233/233 - 44s - loss: 12.5611 - val_loss: 14.3292 - lr: 2.0738e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.07e-04, weight decay: 1.03e-05\n",
            "Epoch 1052/1500\n",
            "Val unfiltered loss: 19.85700798034668\n",
            "233/233 - 44s - loss: 12.5953 - val_loss: 14.2521 - lr: 2.0653e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.06e-04, weight decay: 1.03e-05\n",
            "Epoch 1053/1500\n",
            "Val unfiltered loss: 19.99180793762207\n",
            "233/233 - 45s - loss: 12.5505 - val_loss: 14.5565 - lr: 2.0568e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.05e-04, weight decay: 1.02e-05\n",
            "Epoch 1054/1500\n",
            "Val unfiltered loss: 19.81696891784668\n",
            "233/233 - 44s - loss: 12.6125 - val_loss: 14.2531 - lr: 2.0483e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.04e-04, weight decay: 1.02e-05\n",
            "Epoch 1055/1500\n",
            "Val unfiltered loss: 19.52373504638672\n",
            "233/233 - 44s - loss: 12.5548 - val_loss: 14.2592 - lr: 2.0399e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.03e-04, weight decay: 1.02e-05\n",
            "Epoch 1056/1500\n",
            "Val unfiltered loss: 19.76588249206543\n",
            "233/233 - 43s - loss: 12.6022 - val_loss: 14.3879 - lr: 2.0314e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.02e-04, weight decay: 1.01e-05\n",
            "Epoch 1057/1500\n",
            "Val unfiltered loss: 19.821495056152344\n",
            "233/233 - 44s - loss: 12.5812 - val_loss: 14.3844 - lr: 2.0230e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.01e-04, weight decay: 1.01e-05\n",
            "Epoch 1058/1500\n",
            "Val unfiltered loss: 19.39934539794922\n",
            "233/233 - 44s - loss: 12.5855 - val_loss: 14.1761 - lr: 2.0145e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.01e-04, weight decay: 1.00e-05\n",
            "Epoch 1059/1500\n",
            "Val unfiltered loss: 19.675148010253906\n",
            "233/233 - 44s - loss: 12.5297 - val_loss: 14.2852 - lr: 2.0061e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.00e-04, weight decay: 9.99e-06\n",
            "Epoch 1060/1500\n",
            "Val unfiltered loss: 19.5809268951416\n",
            "233/233 - 45s - loss: 12.5512 - val_loss: 14.2596 - lr: 1.9977e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 1.99e-04, weight decay: 9.95e-06\n",
            "Epoch 1061/1500\n",
            "Val unfiltered loss: 19.53923797607422\n",
            "233/233 - 44s - loss: 12.5369 - val_loss: 14.1563 - lr: 1.9893e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.98e-04, weight decay: 9.90e-06\n",
            "Epoch 1062/1500\n",
            "Val unfiltered loss: 19.87847137451172\n",
            "233/233 - 44s - loss: 12.5579 - val_loss: 14.4218 - lr: 1.9809e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.97e-04, weight decay: 9.86e-06\n",
            "Epoch 1063/1500\n",
            "Val unfiltered loss: 19.71639060974121\n",
            "233/233 - 43s - loss: 12.5462 - val_loss: 14.5020 - lr: 1.9725e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.96e-04, weight decay: 9.82e-06\n",
            "Epoch 1064/1500\n",
            "Val unfiltered loss: 19.810012817382812\n",
            "233/233 - 44s - loss: 12.5088 - val_loss: 14.4551 - lr: 1.9642e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.96e-04, weight decay: 9.78e-06\n",
            "Epoch 1065/1500\n",
            "Val unfiltered loss: 19.788545608520508\n",
            "233/233 - 44s - loss: 12.5978 - val_loss: 14.4214 - lr: 1.9558e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.95e-04, weight decay: 9.74e-06\n",
            "Epoch 1066/1500\n",
            "Val unfiltered loss: 19.976119995117188\n",
            "233/233 - 44s - loss: 12.5152 - val_loss: 14.5724 - lr: 1.9475e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.94e-04, weight decay: 9.70e-06\n",
            "Epoch 1067/1500\n",
            "Val unfiltered loss: 19.62553596496582\n",
            "233/233 - 45s - loss: 12.5489 - val_loss: 14.2813 - lr: 1.9392e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 1.93e-04, weight decay: 9.65e-06\n",
            "Epoch 1068/1500\n",
            "Val unfiltered loss: 19.788572311401367\n",
            "233/233 - 44s - loss: 12.5924 - val_loss: 14.4443 - lr: 1.9309e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.92e-04, weight decay: 9.61e-06\n",
            "Epoch 1069/1500\n",
            "Val unfiltered loss: 19.69228172302246\n",
            "233/233 - 44s - loss: 12.5091 - val_loss: 14.4249 - lr: 1.9226e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.91e-04, weight decay: 9.57e-06\n",
            "Epoch 1070/1500\n",
            "Val unfiltered loss: 19.79503059387207\n",
            "233/233 - 43s - loss: 12.5264 - val_loss: 14.3471 - lr: 1.9143e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.91e-04, weight decay: 9.53e-06\n",
            "Epoch 1071/1500\n",
            "Val unfiltered loss: 19.735286712646484\n",
            "233/233 - 44s - loss: 12.5604 - val_loss: 14.3070 - lr: 1.9061e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.90e-04, weight decay: 9.49e-06\n",
            "Epoch 1072/1500\n",
            "Val unfiltered loss: 19.939109802246094\n",
            "233/233 - 44s - loss: 12.4623 - val_loss: 14.4217 - lr: 1.8978e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.89e-04, weight decay: 9.45e-06\n",
            "Epoch 1073/1500\n",
            "Val unfiltered loss: 19.97939109802246\n",
            "233/233 - 43s - loss: 12.4477 - val_loss: 14.5305 - lr: 1.8896e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.88e-04, weight decay: 9.41e-06\n",
            "Epoch 1074/1500\n",
            "Val unfiltered loss: 19.645856857299805\n",
            "233/233 - 43s - loss: 12.4654 - val_loss: 14.2691 - lr: 1.8814e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.87e-04, weight decay: 9.37e-06\n",
            "Epoch 1075/1500\n",
            "Val unfiltered loss: 19.984556198120117\n",
            "233/233 - 45s - loss: 12.5092 - val_loss: 14.4626 - lr: 1.8732e-04 - 45s/epoch - 194ms/step\n",
            "learning rate: 1.86e-04, weight decay: 9.32e-06\n",
            "Epoch 1076/1500\n",
            "Val unfiltered loss: 19.74384307861328\n",
            "233/233 - 44s - loss: 12.5019 - val_loss: 14.3617 - lr: 1.8650e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.86e-04, weight decay: 9.28e-06\n",
            "Epoch 1077/1500\n",
            "Val unfiltered loss: 19.97881317138672\n",
            "233/233 - 43s - loss: 12.5293 - val_loss: 14.5531 - lr: 1.8568e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.85e-04, weight decay: 9.24e-06\n",
            "Epoch 1078/1500\n",
            "Val unfiltered loss: 20.030874252319336\n",
            "233/233 - 43s - loss: 12.5293 - val_loss: 14.5858 - lr: 1.8486e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.84e-04, weight decay: 9.20e-06\n",
            "Epoch 1079/1500\n",
            "Val unfiltered loss: 20.305130004882812\n",
            "233/233 - 44s - loss: 12.5243 - val_loss: 14.6361 - lr: 1.8405e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.83e-04, weight decay: 9.16e-06\n",
            "Epoch 1080/1500\n",
            "Val unfiltered loss: 20.077560424804688\n",
            "233/233 - 43s - loss: 12.4856 - val_loss: 14.5245 - lr: 1.8324e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.82e-04, weight decay: 9.12e-06\n",
            "Epoch 1081/1500\n",
            "Val unfiltered loss: 19.83686065673828\n",
            "233/233 - 43s - loss: 12.4310 - val_loss: 14.5185 - lr: 1.8242e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.82e-04, weight decay: 9.08e-06\n",
            "Epoch 1082/1500\n",
            "Val unfiltered loss: 19.8646240234375\n",
            "233/233 - 44s - loss: 12.4401 - val_loss: 14.5322 - lr: 1.8161e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.81e-04, weight decay: 9.04e-06\n",
            "Epoch 1083/1500\n",
            "Val unfiltered loss: 19.879011154174805\n",
            "233/233 - 44s - loss: 12.4674 - val_loss: 14.4902 - lr: 1.8080e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.80e-04, weight decay: 9.00e-06\n",
            "Epoch 1084/1500\n",
            "Val unfiltered loss: 19.840919494628906\n",
            "233/233 - 44s - loss: 12.4405 - val_loss: 14.4350 - lr: 1.7999e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.79e-04, weight decay: 8.96e-06\n",
            "Epoch 1085/1500\n",
            "Val unfiltered loss: 20.036787033081055\n",
            "233/233 - 44s - loss: 12.4770 - val_loss: 14.5177 - lr: 1.7919e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.78e-04, weight decay: 8.92e-06\n",
            "Epoch 1086/1500\n",
            "Val unfiltered loss: 19.777172088623047\n",
            "233/233 - 44s - loss: 12.5700 - val_loss: 14.4271 - lr: 1.7838e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.78e-04, weight decay: 8.88e-06\n",
            "Epoch 1087/1500\n",
            "Val unfiltered loss: 20.048341751098633\n",
            "233/233 - 44s - loss: 12.4772 - val_loss: 14.6025 - lr: 1.7758e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.77e-04, weight decay: 8.84e-06\n",
            "Epoch 1088/1500\n",
            "Val unfiltered loss: 19.957178115844727\n",
            "233/233 - 43s - loss: 12.4637 - val_loss: 14.5413 - lr: 1.7678e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.76e-04, weight decay: 8.80e-06\n",
            "Epoch 1089/1500\n",
            "Val unfiltered loss: 20.038108825683594\n",
            "233/233 - 46s - loss: 12.4155 - val_loss: 14.6058 - lr: 1.7598e-04 - 46s/epoch - 195ms/step\n",
            "learning rate: 1.75e-04, weight decay: 8.76e-06\n",
            "Epoch 1090/1500\n",
            "Val unfiltered loss: 19.554224014282227\n",
            "233/233 - 44s - loss: 12.4434 - val_loss: 14.3052 - lr: 1.7518e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.74e-04, weight decay: 8.72e-06\n",
            "Epoch 1091/1500\n",
            "Val unfiltered loss: 19.96712303161621\n",
            "233/233 - 44s - loss: 12.4613 - val_loss: 14.6524 - lr: 1.7438e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.74e-04, weight decay: 8.68e-06\n",
            "Epoch 1092/1500\n",
            "Val unfiltered loss: 19.737558364868164\n",
            "233/233 - 44s - loss: 12.4108 - val_loss: 14.5163 - lr: 1.7358e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.73e-04, weight decay: 8.64e-06\n",
            "Epoch 1093/1500\n",
            "Val unfiltered loss: 19.82123565673828\n",
            "233/233 - 44s - loss: 12.4678 - val_loss: 14.5192 - lr: 1.7279e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.72e-04, weight decay: 8.60e-06\n",
            "Epoch 1094/1500\n",
            "Val unfiltered loss: 20.003740310668945\n",
            "233/233 - 44s - loss: 12.3988 - val_loss: 14.6514 - lr: 1.7199e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.71e-04, weight decay: 8.56e-06\n",
            "Epoch 1095/1500\n",
            "Val unfiltered loss: 19.871185302734375\n",
            "233/233 - 45s - loss: 12.4077 - val_loss: 14.4825 - lr: 1.7120e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.70e-04, weight decay: 8.52e-06\n",
            "Epoch 1096/1500\n",
            "Val unfiltered loss: 20.061580657958984\n",
            "233/233 - 44s - loss: 12.3990 - val_loss: 14.5792 - lr: 1.7041e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.70e-04, weight decay: 8.48e-06\n",
            "Epoch 1097/1500\n",
            "Val unfiltered loss: 20.05066680908203\n",
            "233/233 - 43s - loss: 12.4357 - val_loss: 14.6505 - lr: 1.6962e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.69e-04, weight decay: 8.44e-06\n",
            "Epoch 1098/1500\n",
            "Val unfiltered loss: 19.7405948638916\n",
            "233/233 - 43s - loss: 12.3974 - val_loss: 14.4040 - lr: 1.6883e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.68e-04, weight decay: 8.40e-06\n",
            "Epoch 1099/1500\n",
            "Val unfiltered loss: 19.910140991210938\n",
            "233/233 - 44s - loss: 12.4042 - val_loss: 14.4870 - lr: 1.6805e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.67e-04, weight decay: 8.36e-06\n",
            "Epoch 1100/1500\n",
            "Val unfiltered loss: 19.849287033081055\n",
            "Val filtered lev distance: 0.863274172069771\n",
            "Val unfiltered lev distance: 0.8149127340675069\n",
            "Sub train lev distance: 0.974777772912379\n",
            "233/233 - 117s - loss: 12.3970 - val_loss: 14.4216 - lr: 1.6726e-04 - 117s/epoch - 501ms/step\n",
            "learning rate: 1.66e-04, weight decay: 8.32e-06\n",
            "Epoch 1101/1500\n",
            "Val unfiltered loss: 19.96289825439453\n",
            "233/233 - 44s - loss: 12.3883 - val_loss: 14.5811 - lr: 1.6648e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.66e-04, weight decay: 8.28e-06\n",
            "Epoch 1102/1500\n",
            "Val unfiltered loss: 19.920026779174805\n",
            "233/233 - 43s - loss: 12.3564 - val_loss: 14.6005 - lr: 1.6570e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.65e-04, weight decay: 8.25e-06\n",
            "Epoch 1103/1500\n",
            "Val unfiltered loss: 19.737071990966797\n",
            "233/233 - 44s - loss: 12.3791 - val_loss: 14.3513 - lr: 1.6491e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.64e-04, weight decay: 8.21e-06\n",
            "Epoch 1104/1500\n",
            "Val unfiltered loss: 19.797780990600586\n",
            "233/233 - 45s - loss: 12.3752 - val_loss: 14.4864 - lr: 1.6414e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.63e-04, weight decay: 8.17e-06\n",
            "Epoch 1105/1500\n",
            "Val unfiltered loss: 19.676658630371094\n",
            "233/233 - 44s - loss: 12.3804 - val_loss: 14.4686 - lr: 1.6336e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.63e-04, weight decay: 8.13e-06\n",
            "Epoch 1106/1500\n",
            "Val unfiltered loss: 19.683673858642578\n",
            "233/233 - 44s - loss: 12.3877 - val_loss: 14.4480 - lr: 1.6258e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.62e-04, weight decay: 8.09e-06\n",
            "Epoch 1107/1500\n",
            "Val unfiltered loss: 19.943504333496094\n",
            "233/233 - 44s - loss: 12.3916 - val_loss: 14.6345 - lr: 1.6181e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.61e-04, weight decay: 8.05e-06\n",
            "Epoch 1108/1500\n",
            "Val unfiltered loss: 19.681957244873047\n",
            "233/233 - 43s - loss: 12.3914 - val_loss: 14.3605 - lr: 1.6103e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.60e-04, weight decay: 8.01e-06\n",
            "Epoch 1109/1500\n",
            "Val unfiltered loss: 19.752399444580078\n",
            "233/233 - 43s - loss: 12.3506 - val_loss: 14.3413 - lr: 1.6026e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.59e-04, weight decay: 7.97e-06\n",
            "Epoch 1110/1500\n",
            "Val unfiltered loss: 19.675718307495117\n",
            "233/233 - 44s - loss: 12.4287 - val_loss: 14.3012 - lr: 1.5949e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.59e-04, weight decay: 7.94e-06\n",
            "Epoch 1111/1500\n",
            "Val unfiltered loss: 19.988656997680664\n",
            "233/233 - 45s - loss: 12.3473 - val_loss: 14.4864 - lr: 1.5872e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.58e-04, weight decay: 7.90e-06\n",
            "Epoch 1112/1500\n",
            "Val unfiltered loss: 20.18207359313965\n",
            "233/233 - 44s - loss: 12.3512 - val_loss: 14.6527 - lr: 1.5796e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.57e-04, weight decay: 7.86e-06\n",
            "Epoch 1113/1500\n",
            "Val unfiltered loss: 20.244070053100586\n",
            "233/233 - 44s - loss: 12.3192 - val_loss: 14.5984 - lr: 1.5719e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.56e-04, weight decay: 7.82e-06\n",
            "Epoch 1114/1500\n",
            "Val unfiltered loss: 20.164501190185547\n",
            "233/233 - 44s - loss: 12.3245 - val_loss: 14.5229 - lr: 1.5643e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.56e-04, weight decay: 7.78e-06\n",
            "Epoch 1115/1500\n",
            "Val unfiltered loss: 20.05658721923828\n",
            "233/233 - 44s - loss: 12.3453 - val_loss: 14.5685 - lr: 1.5566e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.55e-04, weight decay: 7.75e-06\n",
            "Epoch 1116/1500\n",
            "Val unfiltered loss: 20.150075912475586\n",
            "233/233 - 44s - loss: 12.3323 - val_loss: 14.6046 - lr: 1.5490e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.54e-04, weight decay: 7.71e-06\n",
            "Epoch 1117/1500\n",
            "Val unfiltered loss: 20.02088737487793\n",
            "233/233 - 44s - loss: 12.2986 - val_loss: 14.6396 - lr: 1.5414e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.53e-04, weight decay: 7.67e-06\n",
            "Epoch 1118/1500\n",
            "Val unfiltered loss: 19.818946838378906\n",
            "233/233 - 45s - loss: 12.3298 - val_loss: 14.4435 - lr: 1.5339e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 1.53e-04, weight decay: 7.63e-06\n",
            "Epoch 1119/1500\n",
            "Val unfiltered loss: 19.662797927856445\n",
            "233/233 - 44s - loss: 12.3728 - val_loss: 14.3540 - lr: 1.5263e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.52e-04, weight decay: 7.59e-06\n",
            "Epoch 1120/1500\n",
            "Val unfiltered loss: 19.752714157104492\n",
            "233/233 - 44s - loss: 12.3338 - val_loss: 14.4910 - lr: 1.5187e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.51e-04, weight decay: 7.56e-06\n",
            "Epoch 1121/1500\n",
            "Val unfiltered loss: 20.047163009643555\n",
            "233/233 - 44s - loss: 12.3119 - val_loss: 14.6047 - lr: 1.5112e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.50e-04, weight decay: 7.52e-06\n",
            "Epoch 1122/1500\n",
            "Val unfiltered loss: 20.083097457885742\n",
            "233/233 - 44s - loss: 12.2948 - val_loss: 14.6879 - lr: 1.5037e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.50e-04, weight decay: 7.48e-06\n",
            "Epoch 1123/1500\n",
            "Val unfiltered loss: 20.04047203063965\n",
            "233/233 - 44s - loss: 12.3274 - val_loss: 14.5358 - lr: 1.4962e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.49e-04, weight decay: 7.44e-06\n",
            "Epoch 1124/1500\n",
            "Val unfiltered loss: 20.173532485961914\n",
            "233/233 - 44s - loss: 12.3054 - val_loss: 14.5974 - lr: 1.4887e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.48e-04, weight decay: 7.41e-06\n",
            "Epoch 1125/1500\n",
            "Val unfiltered loss: 20.078227996826172\n",
            "233/233 - 45s - loss: 12.2495 - val_loss: 14.4927 - lr: 1.4812e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 1.47e-04, weight decay: 7.37e-06\n",
            "Epoch 1126/1500\n",
            "Val unfiltered loss: 20.242992401123047\n",
            "233/233 - 44s - loss: 12.2626 - val_loss: 14.7104 - lr: 1.4738e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.47e-04, weight decay: 7.33e-06\n",
            "Epoch 1127/1500\n",
            "Val unfiltered loss: 20.012968063354492\n",
            "233/233 - 44s - loss: 12.3139 - val_loss: 14.5478 - lr: 1.4663e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.46e-04, weight decay: 7.29e-06\n",
            "Epoch 1128/1500\n",
            "Val unfiltered loss: 19.714801788330078\n",
            "233/233 - 44s - loss: 12.3076 - val_loss: 14.2473 - lr: 1.4589e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.45e-04, weight decay: 7.26e-06\n",
            "Epoch 1129/1500\n",
            "Val unfiltered loss: 19.87199592590332\n",
            "233/233 - 44s - loss: 12.3307 - val_loss: 14.4759 - lr: 1.4515e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.44e-04, weight decay: 7.22e-06\n",
            "Epoch 1130/1500\n",
            "Val unfiltered loss: 19.986833572387695\n",
            "233/233 - 44s - loss: 12.2481 - val_loss: 14.5492 - lr: 1.4441e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.44e-04, weight decay: 7.18e-06\n",
            "Epoch 1131/1500\n",
            "Val unfiltered loss: 19.94376564025879\n",
            "233/233 - 44s - loss: 12.2440 - val_loss: 14.5227 - lr: 1.4367e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.43e-04, weight decay: 7.15e-06\n",
            "Epoch 1132/1500\n",
            "Val unfiltered loss: 20.14929962158203\n",
            "233/233 - 45s - loss: 12.2488 - val_loss: 14.5981 - lr: 1.4294e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 1.42e-04, weight decay: 7.11e-06\n",
            "Epoch 1133/1500\n",
            "Val unfiltered loss: 20.06139373779297\n",
            "233/233 - 44s - loss: 12.2696 - val_loss: 14.5400 - lr: 1.4220e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.41e-04, weight decay: 7.07e-06\n",
            "Epoch 1134/1500\n",
            "Val unfiltered loss: 19.931425094604492\n",
            "233/233 - 44s - loss: 12.2438 - val_loss: 14.4072 - lr: 1.4147e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.41e-04, weight decay: 7.04e-06\n",
            "Epoch 1135/1500\n",
            "Val unfiltered loss: 20.081022262573242\n",
            "233/233 - 44s - loss: 12.2971 - val_loss: 14.4773 - lr: 1.4074e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.40e-04, weight decay: 7.00e-06\n",
            "Epoch 1136/1500\n",
            "Val unfiltered loss: 20.145036697387695\n",
            "233/233 - 44s - loss: 12.2440 - val_loss: 14.6017 - lr: 1.4001e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.39e-04, weight decay: 6.96e-06\n",
            "Epoch 1137/1500\n",
            "Val unfiltered loss: 20.229265213012695\n",
            "233/233 - 44s - loss: 12.2512 - val_loss: 14.5773 - lr: 1.3928e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.39e-04, weight decay: 6.93e-06\n",
            "Epoch 1138/1500\n",
            "Val unfiltered loss: 20.003896713256836\n",
            "233/233 - 44s - loss: 12.2486 - val_loss: 14.6733 - lr: 1.3855e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.38e-04, weight decay: 6.89e-06\n",
            "Epoch 1139/1500\n",
            "Val unfiltered loss: 19.92349624633789\n",
            "233/233 - 44s - loss: 12.2592 - val_loss: 14.4937 - lr: 1.3783e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.37e-04, weight decay: 6.86e-06\n",
            "Epoch 1140/1500\n",
            "Val unfiltered loss: 20.082365036010742\n",
            "233/233 - 44s - loss: 12.2467 - val_loss: 14.6486 - lr: 1.3710e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.36e-04, weight decay: 6.82e-06\n",
            "Epoch 1141/1500\n",
            "Val unfiltered loss: 20.058269500732422\n",
            "233/233 - 44s - loss: 12.2300 - val_loss: 14.5629 - lr: 1.3638e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.36e-04, weight decay: 6.78e-06\n",
            "Epoch 1142/1500\n",
            "Val unfiltered loss: 20.267545700073242\n",
            "233/233 - 44s - loss: 12.2417 - val_loss: 14.7060 - lr: 1.3566e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.35e-04, weight decay: 6.75e-06\n",
            "Epoch 1143/1500\n",
            "Val unfiltered loss: 20.035987854003906\n",
            "233/233 - 44s - loss: 12.2054 - val_loss: 14.4901 - lr: 1.3494e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.34e-04, weight decay: 6.71e-06\n",
            "Epoch 1144/1500\n",
            "Val unfiltered loss: 20.036577224731445\n",
            "233/233 - 44s - loss: 12.2143 - val_loss: 14.5199 - lr: 1.3422e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.34e-04, weight decay: 6.68e-06\n",
            "Epoch 1145/1500\n",
            "Val unfiltered loss: 20.243759155273438\n",
            "233/233 - 44s - loss: 12.2198 - val_loss: 14.6822 - lr: 1.3351e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.33e-04, weight decay: 6.64e-06\n",
            "Epoch 1146/1500\n",
            "Val unfiltered loss: 20.126930236816406\n",
            "233/233 - 45s - loss: 12.1974 - val_loss: 14.6017 - lr: 1.3279e-04 - 45s/epoch - 195ms/step\n",
            "learning rate: 1.32e-04, weight decay: 6.60e-06\n",
            "Epoch 1147/1500\n",
            "Val unfiltered loss: 19.87843132019043\n",
            "233/233 - 44s - loss: 12.2035 - val_loss: 14.3907 - lr: 1.3208e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.31e-04, weight decay: 6.57e-06\n",
            "Epoch 1148/1500\n",
            "Val unfiltered loss: 19.773954391479492\n",
            "233/233 - 44s - loss: 12.2858 - val_loss: 14.3572 - lr: 1.3137e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.31e-04, weight decay: 6.53e-06\n",
            "Epoch 1149/1500\n",
            "Val unfiltered loss: 20.055646896362305\n",
            "233/233 - 44s - loss: 12.2940 - val_loss: 14.5655 - lr: 1.3066e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.30e-04, weight decay: 6.50e-06\n",
            "Epoch 1150/1500\n",
            "Val unfiltered loss: 19.97905921936035\n",
            "Val filtered lev distance: 0.8634924793153885\n",
            "Val unfiltered lev distance: 0.8156482328151712\n",
            "Sub train lev distance: 0.9762446906336208\n",
            "233/233 - 123s - loss: 12.2140 - val_loss: 14.6062 - lr: 1.2995e-04 - 123s/epoch - 529ms/step\n",
            "learning rate: 1.29e-04, weight decay: 6.46e-06\n",
            "Epoch 1151/1500\n",
            "Val unfiltered loss: 20.01668930053711\n",
            "233/233 - 44s - loss: 12.2199 - val_loss: 14.5753 - lr: 1.2925e-04 - 44s/epoch - 191ms/step\n",
            "learning rate: 1.29e-04, weight decay: 6.43e-06\n",
            "Epoch 1152/1500\n",
            "Val unfiltered loss: 19.781396865844727\n",
            "233/233 - 44s - loss: 12.2112 - val_loss: 14.4929 - lr: 1.2854e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.28e-04, weight decay: 6.39e-06\n",
            "Epoch 1153/1500\n",
            "Val unfiltered loss: 20.04950714111328\n",
            "233/233 - 44s - loss: 12.2279 - val_loss: 14.6180 - lr: 1.2784e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.27e-04, weight decay: 6.36e-06\n",
            "Epoch 1154/1500\n",
            "Val unfiltered loss: 20.133455276489258\n",
            "233/233 - 44s - loss: 12.2277 - val_loss: 14.6562 - lr: 1.2714e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.26e-04, weight decay: 6.32e-06\n",
            "Epoch 1155/1500\n",
            "Val unfiltered loss: 20.179981231689453\n",
            "233/233 - 44s - loss: 12.1928 - val_loss: 14.6812 - lr: 1.2644e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.26e-04, weight decay: 6.29e-06\n",
            "Epoch 1156/1500\n",
            "Val unfiltered loss: 20.07108497619629\n",
            "233/233 - 44s - loss: 12.1756 - val_loss: 14.6231 - lr: 1.2574e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.25e-04, weight decay: 6.25e-06\n",
            "Epoch 1157/1500\n",
            "Val unfiltered loss: 19.899452209472656\n",
            "233/233 - 44s - loss: 12.1569 - val_loss: 14.4968 - lr: 1.2505e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.24e-04, weight decay: 6.22e-06\n",
            "Epoch 1158/1500\n",
            "Val unfiltered loss: 19.97102165222168\n",
            "233/233 - 44s - loss: 12.2027 - val_loss: 14.6720 - lr: 1.2435e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.24e-04, weight decay: 6.18e-06\n",
            "Epoch 1159/1500\n",
            "Val unfiltered loss: 20.082237243652344\n",
            "233/233 - 44s - loss: 12.1990 - val_loss: 14.6624 - lr: 1.2366e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.23e-04, weight decay: 6.15e-06\n",
            "Epoch 1160/1500\n",
            "Val unfiltered loss: 20.12666130065918\n",
            "233/233 - 44s - loss: 12.1314 - val_loss: 14.6846 - lr: 1.2297e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.22e-04, weight decay: 6.11e-06\n",
            "Epoch 1161/1500\n",
            "Val unfiltered loss: 20.042665481567383\n",
            "233/233 - 44s - loss: 12.1994 - val_loss: 14.5722 - lr: 1.2228e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.22e-04, weight decay: 6.08e-06\n",
            "Epoch 1162/1500\n",
            "Val unfiltered loss: 20.24567222595215\n",
            "233/233 - 43s - loss: 12.1990 - val_loss: 14.7482 - lr: 1.2159e-04 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.21e-04, weight decay: 6.05e-06\n",
            "Epoch 1163/1500\n",
            "Val unfiltered loss: 20.14979362487793\n",
            "233/233 - 45s - loss: 12.1881 - val_loss: 14.6142 - lr: 1.2091e-04 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.20e-04, weight decay: 6.01e-06\n",
            "Epoch 1164/1500\n",
            "Val unfiltered loss: 20.196990966796875\n",
            "233/233 - 44s - loss: 12.1500 - val_loss: 14.7883 - lr: 1.2022e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.20e-04, weight decay: 5.98e-06\n",
            "Epoch 1165/1500\n",
            "Val unfiltered loss: 20.303184509277344\n",
            "233/233 - 44s - loss: 12.1424 - val_loss: 14.8436 - lr: 1.1954e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.19e-04, weight decay: 5.94e-06\n",
            "Epoch 1166/1500\n",
            "Val unfiltered loss: 20.233964920043945\n",
            "233/233 - 44s - loss: 12.1319 - val_loss: 14.7058 - lr: 1.1886e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.18e-04, weight decay: 5.91e-06\n",
            "Epoch 1167/1500\n",
            "Val unfiltered loss: 20.137910842895508\n",
            "233/233 - 44s - loss: 12.1519 - val_loss: 14.6181 - lr: 1.1818e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.18e-04, weight decay: 5.88e-06\n",
            "Epoch 1168/1500\n",
            "Val unfiltered loss: 20.072490692138672\n",
            "233/233 - 44s - loss: 12.1583 - val_loss: 14.6537 - lr: 1.1750e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.17e-04, weight decay: 5.84e-06\n",
            "Epoch 1169/1500\n",
            "Val unfiltered loss: 19.984439849853516\n",
            "233/233 - 45s - loss: 12.1714 - val_loss: 14.5456 - lr: 1.1683e-04 - 45s/epoch - 193ms/step\n",
            "learning rate: 1.16e-04, weight decay: 5.81e-06\n",
            "Epoch 1170/1500\n",
            "Val unfiltered loss: 20.370973587036133\n",
            "233/233 - 44s - loss: 12.1401 - val_loss: 14.8791 - lr: 1.1615e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.15e-04, weight decay: 5.77e-06\n",
            "Epoch 1171/1500\n",
            "Val unfiltered loss: 20.267112731933594\n",
            "233/233 - 44s - loss: 12.1181 - val_loss: 14.8247 - lr: 1.1548e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.15e-04, weight decay: 5.74e-06\n",
            "Epoch 1172/1500\n",
            "Val unfiltered loss: 19.99483299255371\n",
            "233/233 - 43s - loss: 12.1331 - val_loss: 14.6369 - lr: 1.1481e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.14e-04, weight decay: 5.71e-06\n",
            "Epoch 1173/1500\n",
            "Val unfiltered loss: 20.240087509155273\n",
            "233/233 - 44s - loss: 12.1249 - val_loss: 14.7760 - lr: 1.1414e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.13e-04, weight decay: 5.67e-06\n",
            "Epoch 1174/1500\n",
            "Val unfiltered loss: 20.041364669799805\n",
            "233/233 - 44s - loss: 12.1017 - val_loss: 14.5798 - lr: 1.1347e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.13e-04, weight decay: 5.64e-06\n",
            "Epoch 1175/1500\n",
            "Val unfiltered loss: 20.359207153320312\n",
            "233/233 - 44s - loss: 12.1657 - val_loss: 14.7880 - lr: 1.1281e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.12e-04, weight decay: 5.61e-06\n",
            "Epoch 1176/1500\n",
            "Val unfiltered loss: 20.38136100769043\n",
            "233/233 - 44s - loss: 12.1659 - val_loss: 14.8141 - lr: 1.1214e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.11e-04, weight decay: 5.57e-06\n",
            "Epoch 1177/1500\n",
            "Val unfiltered loss: 20.14469337463379\n",
            "233/233 - 45s - loss: 12.1422 - val_loss: 14.6968 - lr: 1.1148e-04 - 45s/epoch - 191ms/step\n",
            "learning rate: 1.11e-04, weight decay: 5.54e-06\n",
            "Epoch 1178/1500\n",
            "Val unfiltered loss: 20.26104736328125\n",
            "233/233 - 44s - loss: 12.1323 - val_loss: 14.7490 - lr: 1.1082e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.10e-04, weight decay: 5.51e-06\n",
            "Epoch 1179/1500\n",
            "Val unfiltered loss: 20.10475730895996\n",
            "233/233 - 44s - loss: 12.1532 - val_loss: 14.6125 - lr: 1.1016e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.10e-04, weight decay: 5.48e-06\n",
            "Epoch 1180/1500\n",
            "Val unfiltered loss: 20.17806053161621\n",
            "233/233 - 44s - loss: 12.1395 - val_loss: 14.6529 - lr: 1.0951e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.09e-04, weight decay: 5.44e-06\n",
            "Epoch 1181/1500\n",
            "Val unfiltered loss: 19.900930404663086\n",
            "233/233 - 44s - loss: 12.1650 - val_loss: 14.4787 - lr: 1.0885e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.08e-04, weight decay: 5.41e-06\n",
            "Epoch 1182/1500\n",
            "Val unfiltered loss: 19.975221633911133\n",
            "233/233 - 44s - loss: 12.1266 - val_loss: 14.5986 - lr: 1.0820e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.08e-04, weight decay: 5.38e-06\n",
            "Epoch 1183/1500\n",
            "Val unfiltered loss: 20.06564712524414\n",
            "233/233 - 43s - loss: 12.0573 - val_loss: 14.5764 - lr: 1.0754e-04 - 43s/epoch - 186ms/step\n",
            "learning rate: 1.07e-04, weight decay: 5.34e-06\n",
            "Epoch 1184/1500\n",
            "Val unfiltered loss: 20.344459533691406\n",
            "233/233 - 46s - loss: 12.1062 - val_loss: 14.7770 - lr: 1.0689e-04 - 46s/epoch - 195ms/step\n",
            "learning rate: 1.06e-04, weight decay: 5.31e-06\n",
            "Epoch 1185/1500\n",
            "Val unfiltered loss: 20.467721939086914\n",
            "233/233 - 44s - loss: 12.1168 - val_loss: 14.8919 - lr: 1.0625e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.06e-04, weight decay: 5.28e-06\n",
            "Epoch 1186/1500\n",
            "Val unfiltered loss: 20.249277114868164\n",
            "233/233 - 44s - loss: 12.0438 - val_loss: 14.7472 - lr: 1.0560e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.05e-04, weight decay: 5.25e-06\n",
            "Epoch 1187/1500\n",
            "Val unfiltered loss: 20.133769989013672\n",
            "233/233 - 44s - loss: 12.1009 - val_loss: 14.6414 - lr: 1.0495e-04 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.04e-04, weight decay: 5.22e-06\n",
            "Epoch 1188/1500\n",
            "Val unfiltered loss: 19.989377975463867\n",
            "233/233 - 44s - loss: 12.0797 - val_loss: 14.5221 - lr: 1.0431e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.04e-04, weight decay: 5.18e-06\n",
            "Epoch 1189/1500\n",
            "Val unfiltered loss: 20.332590103149414\n",
            "233/233 - 44s - loss: 12.0284 - val_loss: 14.8069 - lr: 1.0367e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.03e-04, weight decay: 5.15e-06\n",
            "Epoch 1190/1500\n",
            "Val unfiltered loss: 20.204328536987305\n",
            "233/233 - 44s - loss: 12.1067 - val_loss: 14.7044 - lr: 1.0303e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.02e-04, weight decay: 5.12e-06\n",
            "Epoch 1191/1500\n",
            "Val unfiltered loss: 20.306215286254883\n",
            "233/233 - 46s - loss: 12.1097 - val_loss: 14.6761 - lr: 1.0239e-04 - 46s/epoch - 196ms/step\n",
            "learning rate: 1.02e-04, weight decay: 5.09e-06\n",
            "Epoch 1192/1500\n",
            "Val unfiltered loss: 20.181041717529297\n",
            "233/233 - 44s - loss: 12.0762 - val_loss: 14.6789 - lr: 1.0176e-04 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.01e-04, weight decay: 5.06e-06\n",
            "Epoch 1193/1500\n",
            "Val unfiltered loss: 20.530826568603516\n",
            "233/233 - 44s - loss: 12.1083 - val_loss: 14.8730 - lr: 1.0112e-04 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.00e-04, weight decay: 5.02e-06\n",
            "Epoch 1194/1500\n",
            "Val unfiltered loss: 20.101377487182617\n",
            "233/233 - 44s - loss: 12.0625 - val_loss: 14.5772 - lr: 1.0049e-04 - 44s/epoch - 190ms/step\n",
            "learning rate: 9.99e-05, weight decay: 4.99e-06\n",
            "Epoch 1195/1500\n",
            "Val unfiltered loss: 20.22319793701172\n",
            "233/233 - 44s - loss: 12.0061 - val_loss: 14.6912 - lr: 9.9858e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.92e-05, weight decay: 4.96e-06\n",
            "Epoch 1196/1500\n",
            "Val unfiltered loss: 20.41323471069336\n",
            "233/233 - 44s - loss: 12.0464 - val_loss: 14.8448 - lr: 9.9229e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.86e-05, weight decay: 4.93e-06\n",
            "Epoch 1197/1500\n",
            "Val unfiltered loss: 20.3740291595459\n",
            "233/233 - 46s - loss: 12.0748 - val_loss: 14.7157 - lr: 9.8602e-05 - 46s/epoch - 195ms/step\n",
            "learning rate: 9.80e-05, weight decay: 4.90e-06\n",
            "Epoch 1198/1500\n",
            "Val unfiltered loss: 20.44390106201172\n",
            "233/233 - 44s - loss: 12.0359 - val_loss: 14.8271 - lr: 9.7976e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.74e-05, weight decay: 4.87e-06\n",
            "Epoch 1199/1500\n",
            "Val unfiltered loss: 20.372875213623047\n",
            "233/233 - 44s - loss: 12.0635 - val_loss: 14.6852 - lr: 9.7352e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.67e-05, weight decay: 4.84e-06\n",
            "Epoch 1200/1500\n",
            "Val unfiltered loss: 20.35630989074707\n",
            "Val filtered lev distance: 0.863536140764512\n",
            "Val unfiltered lev distance: 0.8160855563948635\n",
            "Sub train lev distance: 0.9774269825283531\n",
            "233/233 - 119s - loss: 12.0729 - val_loss: 14.7717 - lr: 9.6730e-05 - 119s/epoch - 511ms/step\n",
            "learning rate: 9.61e-05, weight decay: 4.81e-06\n",
            "Epoch 1201/1500\n",
            "Val unfiltered loss: 20.295249938964844\n",
            "233/233 - 44s - loss: 12.0549 - val_loss: 14.6485 - lr: 9.6110e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.55e-05, weight decay: 4.77e-06\n",
            "Epoch 1202/1500\n",
            "Val unfiltered loss: 20.24494743347168\n",
            "233/233 - 44s - loss: 12.1035 - val_loss: 14.7547 - lr: 9.5492e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.49e-05, weight decay: 4.74e-06\n",
            "Epoch 1203/1500\n",
            "Val unfiltered loss: 20.388835906982422\n",
            "233/233 - 44s - loss: 12.1142 - val_loss: 14.7930 - lr: 9.4875e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.43e-05, weight decay: 4.71e-06\n",
            "Epoch 1204/1500\n",
            "Val unfiltered loss: 20.28539276123047\n",
            "233/233 - 44s - loss: 12.0075 - val_loss: 14.7227 - lr: 9.4260e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 9.36e-05, weight decay: 4.68e-06\n",
            "Epoch 1205/1500\n",
            "Val unfiltered loss: 20.30683135986328\n",
            "233/233 - 44s - loss: 12.0116 - val_loss: 14.7418 - lr: 9.3647e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.30e-05, weight decay: 4.65e-06\n",
            "Epoch 1206/1500\n",
            "Val unfiltered loss: 20.36943244934082\n",
            "233/233 - 45s - loss: 12.0085 - val_loss: 14.6857 - lr: 9.3035e-05 - 45s/epoch - 193ms/step\n",
            "learning rate: 9.24e-05, weight decay: 4.62e-06\n",
            "Epoch 1207/1500\n",
            "Val unfiltered loss: 20.339088439941406\n",
            "233/233 - 44s - loss: 12.0555 - val_loss: 14.7116 - lr: 9.2426e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.18e-05, weight decay: 4.59e-06\n",
            "Epoch 1208/1500\n",
            "Val unfiltered loss: 20.67339324951172\n",
            "233/233 - 43s - loss: 12.0306 - val_loss: 14.9952 - lr: 9.1818e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 9.12e-05, weight decay: 4.56e-06\n",
            "Epoch 1209/1500\n",
            "Val unfiltered loss: 20.377527236938477\n",
            "233/233 - 43s - loss: 12.0416 - val_loss: 14.7897 - lr: 9.1212e-05 - 43s/epoch - 186ms/step\n",
            "learning rate: 9.06e-05, weight decay: 4.53e-06\n",
            "Epoch 1210/1500\n",
            "Val unfiltered loss: 20.416669845581055\n",
            "233/233 - 44s - loss: 12.0240 - val_loss: 14.8412 - lr: 9.0608e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.00e-05, weight decay: 4.50e-06\n",
            "Epoch 1211/1500\n",
            "Val unfiltered loss: 20.371549606323242\n",
            "233/233 - 44s - loss: 12.0378 - val_loss: 14.7546 - lr: 9.0006e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.94e-05, weight decay: 4.47e-06\n",
            "Epoch 1212/1500\n",
            "Val unfiltered loss: 20.343994140625\n",
            "233/233 - 44s - loss: 12.0631 - val_loss: 14.7840 - lr: 8.9405e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.88e-05, weight decay: 4.44e-06\n",
            "Epoch 1213/1500\n",
            "Val unfiltered loss: 20.317171096801758\n",
            "233/233 - 45s - loss: 12.0038 - val_loss: 14.7667 - lr: 8.8807e-05 - 45s/epoch - 193ms/step\n",
            "learning rate: 8.82e-05, weight decay: 4.41e-06\n",
            "Epoch 1214/1500\n",
            "Val unfiltered loss: 20.06660270690918\n",
            "233/233 - 44s - loss: 12.0183 - val_loss: 14.5873 - lr: 8.8210e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.76e-05, weight decay: 4.38e-06\n",
            "Epoch 1215/1500\n",
            "Val unfiltered loss: 20.228437423706055\n",
            "233/233 - 43s - loss: 12.0208 - val_loss: 14.7279 - lr: 8.7615e-05 - 43s/epoch - 186ms/step\n",
            "learning rate: 8.70e-05, weight decay: 4.35e-06\n",
            "Epoch 1216/1500\n",
            "Val unfiltered loss: 20.206308364868164\n",
            "233/233 - 44s - loss: 12.0156 - val_loss: 14.7315 - lr: 8.7022e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.64e-05, weight decay: 4.32e-06\n",
            "Epoch 1217/1500\n",
            "Val unfiltered loss: 20.234214782714844\n",
            "233/233 - 44s - loss: 12.0138 - val_loss: 14.7806 - lr: 8.6430e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 8.58e-05, weight decay: 4.29e-06\n",
            "Epoch 1218/1500\n",
            "Val unfiltered loss: 20.308820724487305\n",
            "233/233 - 44s - loss: 11.9894 - val_loss: 14.7306 - lr: 8.5841e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.53e-05, weight decay: 4.26e-06\n",
            "Epoch 1219/1500\n",
            "Val unfiltered loss: 20.59979820251465\n",
            "233/233 - 43s - loss: 11.9551 - val_loss: 14.9233 - lr: 8.5253e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 8.47e-05, weight decay: 4.23e-06\n",
            "Epoch 1220/1500\n",
            "Val unfiltered loss: 20.546863555908203\n",
            "233/233 - 45s - loss: 12.0082 - val_loss: 14.8685 - lr: 8.4667e-05 - 45s/epoch - 195ms/step\n",
            "learning rate: 8.41e-05, weight decay: 4.20e-06\n",
            "Epoch 1221/1500\n",
            "Val unfiltered loss: 20.52248764038086\n",
            "233/233 - 44s - loss: 11.9800 - val_loss: 14.8052 - lr: 8.4083e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.35e-05, weight decay: 4.18e-06\n",
            "Epoch 1222/1500\n",
            "Val unfiltered loss: 20.638364791870117\n",
            "233/233 - 44s - loss: 12.0009 - val_loss: 14.9007 - lr: 8.3501e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.29e-05, weight decay: 4.15e-06\n",
            "Epoch 1223/1500\n",
            "Val unfiltered loss: 20.76492691040039\n",
            "233/233 - 44s - loss: 11.9928 - val_loss: 15.0745 - lr: 8.2920e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.23e-05, weight decay: 4.12e-06\n",
            "Epoch 1224/1500\n",
            "Val unfiltered loss: 20.48257827758789\n",
            "233/233 - 44s - loss: 11.9905 - val_loss: 14.8561 - lr: 8.2342e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 8.18e-05, weight decay: 4.09e-06\n",
            "Epoch 1225/1500\n",
            "Val unfiltered loss: 20.452669143676758\n",
            "233/233 - 44s - loss: 11.9591 - val_loss: 14.8591 - lr: 8.1765e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.12e-05, weight decay: 4.06e-06\n",
            "Epoch 1226/1500\n",
            "Val unfiltered loss: 20.457685470581055\n",
            "233/233 - 44s - loss: 11.9584 - val_loss: 14.8405 - lr: 8.1190e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 8.06e-05, weight decay: 4.03e-06\n",
            "Epoch 1227/1500\n",
            "Val unfiltered loss: 20.311140060424805\n",
            "233/233 - 44s - loss: 11.9641 - val_loss: 14.8191 - lr: 8.0617e-05 - 44s/epoch - 191ms/step\n",
            "learning rate: 8.00e-05, weight decay: 4.00e-06\n",
            "Epoch 1228/1500\n",
            "Val unfiltered loss: 20.440643310546875\n",
            "233/233 - 45s - loss: 11.9566 - val_loss: 14.7845 - lr: 8.0046e-05 - 45s/epoch - 192ms/step\n",
            "learning rate: 7.95e-05, weight decay: 3.97e-06\n",
            "Epoch 1229/1500\n",
            "Val unfiltered loss: 20.20413589477539\n",
            "233/233 - 44s - loss: 12.0130 - val_loss: 14.6277 - lr: 7.9477e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.89e-05, weight decay: 3.95e-06\n",
            "Epoch 1230/1500\n",
            "Val unfiltered loss: 20.501388549804688\n",
            "233/233 - 44s - loss: 11.9835 - val_loss: 14.8117 - lr: 7.8909e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.83e-05, weight decay: 3.92e-06\n",
            "Epoch 1231/1500\n",
            "Val unfiltered loss: 20.432098388671875\n",
            "233/233 - 44s - loss: 11.9701 - val_loss: 14.7856 - lr: 7.8343e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.78e-05, weight decay: 3.89e-06\n",
            "Epoch 1232/1500\n",
            "Val unfiltered loss: 20.542844772338867\n",
            "233/233 - 44s - loss: 11.9827 - val_loss: 14.7915 - lr: 7.7780e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.72e-05, weight decay: 3.86e-06\n",
            "Epoch 1233/1500\n",
            "Val unfiltered loss: 20.293413162231445\n",
            "233/233 - 44s - loss: 11.9811 - val_loss: 14.7815 - lr: 7.7218e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.67e-05, weight decay: 3.83e-06\n",
            "Epoch 1234/1500\n",
            "Val unfiltered loss: 20.352052688598633\n",
            "233/233 - 45s - loss: 12.0188 - val_loss: 14.7191 - lr: 7.6658e-05 - 45s/epoch - 192ms/step\n",
            "learning rate: 7.61e-05, weight decay: 3.80e-06\n",
            "Epoch 1235/1500\n",
            "Val unfiltered loss: 20.525951385498047\n",
            "233/233 - 44s - loss: 11.9624 - val_loss: 14.8094 - lr: 7.6100e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.55e-05, weight decay: 3.78e-06\n",
            "Epoch 1236/1500\n",
            "Val unfiltered loss: 20.401796340942383\n",
            "233/233 - 44s - loss: 11.9416 - val_loss: 14.7457 - lr: 7.5543e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.50e-05, weight decay: 3.75e-06\n",
            "Epoch 1237/1500\n",
            "Val unfiltered loss: 20.39520835876465\n",
            "233/233 - 44s - loss: 11.9474 - val_loss: 14.8007 - lr: 7.4989e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.44e-05, weight decay: 3.72e-06\n",
            "Epoch 1238/1500\n",
            "Val unfiltered loss: 20.22163200378418\n",
            "233/233 - 44s - loss: 12.0356 - val_loss: 14.6429 - lr: 7.4437e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.39e-05, weight decay: 3.69e-06\n",
            "Epoch 1239/1500\n",
            "Val unfiltered loss: 20.46124839782715\n",
            "233/233 - 43s - loss: 11.9735 - val_loss: 14.8349 - lr: 7.3886e-05 - 43s/epoch - 186ms/step\n",
            "learning rate: 7.33e-05, weight decay: 3.67e-06\n",
            "Epoch 1240/1500\n",
            "Val unfiltered loss: 20.581762313842773\n",
            "233/233 - 44s - loss: 12.0211 - val_loss: 14.8722 - lr: 7.3337e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.28e-05, weight decay: 3.64e-06\n",
            "Epoch 1241/1500\n",
            "Val unfiltered loss: 20.566139221191406\n",
            "233/233 - 44s - loss: 11.9420 - val_loss: 14.9423 - lr: 7.2790e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.22e-05, weight decay: 3.61e-06\n",
            "Epoch 1242/1500\n",
            "Val unfiltered loss: 20.669288635253906\n",
            "233/233 - 45s - loss: 11.9182 - val_loss: 14.9283 - lr: 7.2245e-05 - 45s/epoch - 193ms/step\n",
            "learning rate: 7.17e-05, weight decay: 3.59e-06\n",
            "Epoch 1243/1500\n",
            "Val unfiltered loss: 20.542268753051758\n",
            "233/233 - 44s - loss: 11.9464 - val_loss: 14.9027 - lr: 7.1702e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.12e-05, weight decay: 3.56e-06\n",
            "Epoch 1244/1500\n",
            "Val unfiltered loss: 20.49528694152832\n",
            "233/233 - 44s - loss: 11.8551 - val_loss: 14.8470 - lr: 7.1161e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.06e-05, weight decay: 3.53e-06\n",
            "Epoch 1245/1500\n",
            "Val unfiltered loss: 20.437192916870117\n",
            "233/233 - 44s - loss: 11.9764 - val_loss: 14.7292 - lr: 7.0622e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.01e-05, weight decay: 3.50e-06\n",
            "Epoch 1246/1500\n",
            "Val unfiltered loss: 20.584753036499023\n",
            "233/233 - 44s - loss: 11.9834 - val_loss: 14.8846 - lr: 7.0084e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.95e-05, weight decay: 3.48e-06\n",
            "Epoch 1247/1500\n",
            "Val unfiltered loss: 20.372163772583008\n",
            "233/233 - 44s - loss: 12.0029 - val_loss: 14.8079 - lr: 6.9549e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.90e-05, weight decay: 3.45e-06\n",
            "Epoch 1248/1500\n",
            "Val unfiltered loss: 20.402015686035156\n",
            "233/233 - 43s - loss: 11.9499 - val_loss: 14.8350 - lr: 6.9015e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 6.85e-05, weight decay: 3.42e-06\n",
            "Epoch 1249/1500\n",
            "Val unfiltered loss: 20.284584045410156\n",
            "233/233 - 45s - loss: 11.9319 - val_loss: 14.7738 - lr: 6.8483e-05 - 45s/epoch - 192ms/step\n",
            "learning rate: 6.80e-05, weight decay: 3.40e-06\n",
            "Epoch 1250/1500\n",
            "Val unfiltered loss: 20.490541458129883\n",
            "Val filtered lev distance: 0.8643875390224202\n",
            "Val unfiltered lev distance: 0.8169800818987795\n",
            "Sub train lev distance: 0.9786311687174323\n",
            "233/233 - 121s - loss: 11.9415 - val_loss: 14.8709 - lr: 6.7954e-05 - 121s/epoch - 520ms/step\n",
            "learning rate: 6.74e-05, weight decay: 3.37e-06\n",
            "Epoch 1251/1500\n",
            "Val unfiltered loss: 20.425504684448242\n",
            "233/233 - 44s - loss: 11.9383 - val_loss: 14.8001 - lr: 6.7426e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.69e-05, weight decay: 3.34e-06\n",
            "Epoch 1252/1500\n",
            "Val unfiltered loss: 20.689481735229492\n",
            "233/233 - 44s - loss: 11.8646 - val_loss: 14.9551 - lr: 6.6900e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.64e-05, weight decay: 3.32e-06\n",
            "Epoch 1253/1500\n",
            "Val unfiltered loss: 20.449369430541992\n",
            "233/233 - 44s - loss: 11.9116 - val_loss: 14.7998 - lr: 6.6376e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.59e-05, weight decay: 3.29e-06\n",
            "Epoch 1254/1500\n",
            "Val unfiltered loss: 20.505477905273438\n",
            "233/233 - 44s - loss: 11.8999 - val_loss: 14.8981 - lr: 6.5854e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.53e-05, weight decay: 3.27e-06\n",
            "Epoch 1255/1500\n",
            "Val unfiltered loss: 20.502599716186523\n",
            "233/233 - 44s - loss: 11.9077 - val_loss: 14.8650 - lr: 6.5333e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.48e-05, weight decay: 3.24e-06\n",
            "Epoch 1256/1500\n",
            "Val unfiltered loss: 20.443613052368164\n",
            "233/233 - 44s - loss: 11.9236 - val_loss: 14.7880 - lr: 6.4815e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.43e-05, weight decay: 3.21e-06\n",
            "Epoch 1257/1500\n",
            "Val unfiltered loss: 20.3199520111084\n",
            "233/233 - 45s - loss: 11.9551 - val_loss: 14.8078 - lr: 6.4299e-05 - 45s/epoch - 193ms/step\n",
            "learning rate: 6.38e-05, weight decay: 3.19e-06\n",
            "Epoch 1258/1500\n",
            "Val unfiltered loss: 20.352205276489258\n",
            "233/233 - 44s - loss: 11.9522 - val_loss: 14.8459 - lr: 6.3784e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.33e-05, weight decay: 3.16e-06\n",
            "Epoch 1259/1500\n",
            "Val unfiltered loss: 20.405439376831055\n",
            "233/233 - 44s - loss: 11.9075 - val_loss: 14.8733 - lr: 6.3272e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.28e-05, weight decay: 3.14e-06\n",
            "Epoch 1260/1500\n",
            "Val unfiltered loss: 20.54997444152832\n",
            "233/233 - 44s - loss: 11.9270 - val_loss: 14.9170 - lr: 6.2761e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.23e-05, weight decay: 3.11e-06\n",
            "Epoch 1261/1500\n",
            "Val unfiltered loss: 20.536882400512695\n",
            "233/233 - 44s - loss: 11.9095 - val_loss: 14.9576 - lr: 6.2252e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 6.17e-05, weight decay: 3.09e-06\n",
            "Epoch 1262/1500\n",
            "Val unfiltered loss: 20.621274948120117\n",
            "233/233 - 44s - loss: 11.8745 - val_loss: 14.9505 - lr: 6.1745e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.12e-05, weight decay: 3.06e-06\n",
            "Epoch 1263/1500\n",
            "Val unfiltered loss: 20.546283721923828\n",
            "233/233 - 44s - loss: 11.8524 - val_loss: 14.9592 - lr: 6.1241e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.07e-05, weight decay: 3.04e-06\n",
            "Epoch 1264/1500\n",
            "Val unfiltered loss: 20.51767349243164\n",
            "233/233 - 45s - loss: 11.8584 - val_loss: 14.9771 - lr: 6.0738e-05 - 45s/epoch - 192ms/step\n",
            "learning rate: 6.02e-05, weight decay: 3.01e-06\n",
            "Epoch 1265/1500\n",
            "Val unfiltered loss: 20.59833526611328\n",
            "233/233 - 44s - loss: 11.9118 - val_loss: 14.9651 - lr: 6.0237e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.97e-05, weight decay: 2.99e-06\n",
            "Epoch 1266/1500\n",
            "Val unfiltered loss: 20.600996017456055\n",
            "233/233 - 44s - loss: 11.9037 - val_loss: 14.9503 - lr: 5.9738e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.92e-05, weight decay: 2.96e-06\n",
            "Epoch 1267/1500\n",
            "Val unfiltered loss: 20.46634292602539\n",
            "233/233 - 44s - loss: 11.8953 - val_loss: 14.8663 - lr: 5.9241e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.87e-05, weight decay: 2.94e-06\n",
            "Epoch 1268/1500\n",
            "Val unfiltered loss: 20.445777893066406\n",
            "233/233 - 43s - loss: 11.9174 - val_loss: 14.9217 - lr: 5.8746e-05 - 43s/epoch - 186ms/step\n",
            "learning rate: 5.83e-05, weight decay: 2.91e-06\n",
            "Epoch 1269/1500\n",
            "Val unfiltered loss: 20.426250457763672\n",
            "233/233 - 44s - loss: 11.9013 - val_loss: 14.8973 - lr: 5.8252e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.78e-05, weight decay: 2.89e-06\n",
            "Epoch 1270/1500\n",
            "Val unfiltered loss: 20.460783004760742\n",
            "233/233 - 44s - loss: 11.8647 - val_loss: 14.8905 - lr: 5.7761e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.73e-05, weight decay: 2.86e-06\n",
            "Epoch 1271/1500\n",
            "Val unfiltered loss: 20.471294403076172\n",
            "233/233 - 44s - loss: 11.9086 - val_loss: 14.9049 - lr: 5.7272e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.68e-05, weight decay: 2.84e-06\n",
            "Epoch 1272/1500\n",
            "Val unfiltered loss: 20.463804244995117\n",
            "233/233 - 44s - loss: 11.9125 - val_loss: 14.9532 - lr: 5.6785e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.63e-05, weight decay: 2.81e-06\n",
            "Epoch 1273/1500\n",
            "Val unfiltered loss: 20.46845817565918\n",
            "233/233 - 44s - loss: 11.8756 - val_loss: 14.8771 - lr: 5.6299e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 5.58e-05, weight decay: 2.79e-06\n",
            "Epoch 1274/1500\n",
            "Val unfiltered loss: 20.58915901184082\n",
            "233/233 - 44s - loss: 11.8726 - val_loss: 14.9690 - lr: 5.5816e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.53e-05, weight decay: 2.77e-06\n",
            "Epoch 1275/1500\n",
            "Val unfiltered loss: 20.7105655670166\n",
            "233/233 - 44s - loss: 11.9455 - val_loss: 15.0449 - lr: 5.5335e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.49e-05, weight decay: 2.74e-06\n",
            "Epoch 1276/1500\n",
            "Val unfiltered loss: 20.765941619873047\n",
            "233/233 - 44s - loss: 11.8363 - val_loss: 15.0427 - lr: 5.4855e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.44e-05, weight decay: 2.72e-06\n",
            "Epoch 1277/1500\n",
            "Val unfiltered loss: 20.64604949951172\n",
            "233/233 - 44s - loss: 11.8955 - val_loss: 14.9622 - lr: 5.4378e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.39e-05, weight decay: 2.70e-06\n",
            "Epoch 1278/1500\n",
            "Val unfiltered loss: 20.533052444458008\n",
            "233/233 - 44s - loss: 11.8819 - val_loss: 14.9055 - lr: 5.3902e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.34e-05, weight decay: 2.67e-06\n",
            "Epoch 1279/1500\n",
            "Val unfiltered loss: 20.765275955200195\n",
            "233/233 - 44s - loss: 11.8904 - val_loss: 15.0599 - lr: 5.3428e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 5.30e-05, weight decay: 2.65e-06\n",
            "Epoch 1280/1500\n",
            "Val unfiltered loss: 20.518871307373047\n",
            "233/233 - 44s - loss: 11.8714 - val_loss: 14.9101 - lr: 5.2957e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.25e-05, weight decay: 2.62e-06\n",
            "Epoch 1281/1500\n",
            "Val unfiltered loss: 20.580440521240234\n",
            "233/233 - 44s - loss: 11.8959 - val_loss: 14.9179 - lr: 5.2487e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.20e-05, weight decay: 2.60e-06\n",
            "Epoch 1282/1500\n",
            "Val unfiltered loss: 20.61710548400879\n",
            "233/233 - 44s - loss: 11.8832 - val_loss: 14.9159 - lr: 5.2020e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.16e-05, weight decay: 2.58e-06\n",
            "Epoch 1283/1500\n",
            "Val unfiltered loss: 20.484275817871094\n",
            "233/233 - 44s - loss: 11.8651 - val_loss: 14.8410 - lr: 5.1554e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.11e-05, weight decay: 2.55e-06\n",
            "Epoch 1284/1500\n",
            "Val unfiltered loss: 20.582490921020508\n",
            "233/233 - 44s - loss: 11.8338 - val_loss: 14.8815 - lr: 5.1090e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.06e-05, weight decay: 2.53e-06\n",
            "Epoch 1285/1500\n",
            "Val unfiltered loss: 20.674062728881836\n",
            "233/233 - 44s - loss: 11.8203 - val_loss: 14.9624 - lr: 5.0629e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.02e-05, weight decay: 2.51e-06\n",
            "Epoch 1286/1500\n",
            "Val unfiltered loss: 20.742599487304688\n",
            "233/233 - 45s - loss: 11.8393 - val_loss: 15.0662 - lr: 5.0169e-05 - 45s/epoch - 195ms/step\n",
            "learning rate: 4.97e-05, weight decay: 2.49e-06\n",
            "Epoch 1287/1500\n",
            "Val unfiltered loss: 20.655780792236328\n",
            "233/233 - 44s - loss: 11.8533 - val_loss: 14.8998 - lr: 4.9711e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.93e-05, weight decay: 2.46e-06\n",
            "Epoch 1288/1500\n",
            "Val unfiltered loss: 20.66826629638672\n",
            "233/233 - 44s - loss: 11.8471 - val_loss: 14.9427 - lr: 4.9255e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.88e-05, weight decay: 2.44e-06\n",
            "Epoch 1289/1500\n",
            "Val unfiltered loss: 20.6700382232666\n",
            "233/233 - 45s - loss: 11.8957 - val_loss: 14.9481 - lr: 4.8802e-05 - 45s/epoch - 191ms/step\n",
            "learning rate: 4.83e-05, weight decay: 2.42e-06\n",
            "Epoch 1290/1500\n",
            "Val unfiltered loss: 20.733266830444336\n",
            "233/233 - 44s - loss: 11.8456 - val_loss: 15.0145 - lr: 4.8350e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.79e-05, weight decay: 2.40e-06\n",
            "Epoch 1291/1500\n",
            "Val unfiltered loss: 20.54065704345703\n",
            "233/233 - 44s - loss: 11.8693 - val_loss: 14.8749 - lr: 4.7900e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.75e-05, weight decay: 2.37e-06\n",
            "Epoch 1292/1500\n",
            "Val unfiltered loss: 20.485017776489258\n",
            "233/233 - 44s - loss: 11.8202 - val_loss: 14.9024 - lr: 4.7452e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.70e-05, weight decay: 2.35e-06\n",
            "Epoch 1293/1500\n",
            "Val unfiltered loss: 20.74997901916504\n",
            "233/233 - 45s - loss: 11.8682 - val_loss: 15.0634 - lr: 4.7007e-05 - 45s/epoch - 194ms/step\n",
            "learning rate: 4.66e-05, weight decay: 2.33e-06\n",
            "Epoch 1294/1500\n",
            "Val unfiltered loss: 20.564035415649414\n",
            "233/233 - 44s - loss: 11.8474 - val_loss: 14.9442 - lr: 4.6563e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.61e-05, weight decay: 2.31e-06\n",
            "Epoch 1295/1500\n",
            "Val unfiltered loss: 20.669862747192383\n",
            "233/233 - 44s - loss: 11.8208 - val_loss: 15.0166 - lr: 4.6121e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 4.57e-05, weight decay: 2.28e-06\n",
            "Epoch 1296/1500\n",
            "Val unfiltered loss: 20.437074661254883\n",
            "233/233 - 44s - loss: 11.8250 - val_loss: 14.7926 - lr: 4.5681e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.52e-05, weight decay: 2.26e-06\n",
            "Epoch 1297/1500\n",
            "Val unfiltered loss: 20.67052459716797\n",
            "233/233 - 44s - loss: 11.8064 - val_loss: 14.9312 - lr: 4.5244e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.48e-05, weight decay: 2.24e-06\n",
            "Epoch 1298/1500\n",
            "Val unfiltered loss: 20.65047836303711\n",
            "233/233 - 44s - loss: 11.8673 - val_loss: 14.9579 - lr: 4.4808e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.44e-05, weight decay: 2.22e-06\n",
            "Epoch 1299/1500\n",
            "Val unfiltered loss: 20.541601181030273\n",
            "233/233 - 44s - loss: 11.8458 - val_loss: 14.9109 - lr: 4.4374e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.39e-05, weight decay: 2.20e-06\n",
            "Epoch 1300/1500\n",
            "Val unfiltered loss: 20.486299514770508\n",
            "Val filtered lev distance: 0.8644748619206671\n",
            "Val unfiltered lev distance: 0.8172186220331571\n",
            "Sub train lev distance: 0.9792442089591452\n",
            "233/233 - 119s - loss: 11.8150 - val_loss: 14.8581 - lr: 4.3942e-05 - 119s/epoch - 511ms/step\n",
            "learning rate: 4.35e-05, weight decay: 2.18e-06\n",
            "Epoch 1301/1500\n",
            "Val unfiltered loss: 20.598909378051758\n",
            "233/233 - 43s - loss: 11.7731 - val_loss: 14.8943 - lr: 4.3513e-05 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.31e-05, weight decay: 2.15e-06\n",
            "Epoch 1302/1500\n",
            "Val unfiltered loss: 20.561399459838867\n",
            "233/233 - 44s - loss: 11.8466 - val_loss: 14.9593 - lr: 4.3085e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 4.27e-05, weight decay: 2.13e-06\n",
            "Epoch 1303/1500\n",
            "Val unfiltered loss: 20.583940505981445\n",
            "233/233 - 44s - loss: 11.8257 - val_loss: 14.9113 - lr: 4.2659e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.22e-05, weight decay: 2.11e-06\n",
            "Epoch 1304/1500\n",
            "Val unfiltered loss: 20.55150032043457\n",
            "233/233 - 44s - loss: 11.8172 - val_loss: 14.9885 - lr: 4.2236e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.18e-05, weight decay: 2.09e-06\n",
            "Epoch 1305/1500\n",
            "Val unfiltered loss: 20.46851348876953\n",
            "233/233 - 44s - loss: 11.8950 - val_loss: 14.8657 - lr: 4.1814e-05 - 44s/epoch - 191ms/step\n",
            "learning rate: 4.14e-05, weight decay: 2.07e-06\n",
            "Epoch 1306/1500\n",
            "Val unfiltered loss: 20.528892517089844\n",
            "233/233 - 44s - loss: 11.8257 - val_loss: 14.8975 - lr: 4.1394e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.10e-05, weight decay: 2.05e-06\n",
            "Epoch 1307/1500\n",
            "Val unfiltered loss: 20.688121795654297\n",
            "233/233 - 43s - loss: 11.7975 - val_loss: 14.9810 - lr: 4.0977e-05 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.06e-05, weight decay: 2.03e-06\n",
            "Epoch 1308/1500\n",
            "Val unfiltered loss: 20.524587631225586\n",
            "233/233 - 44s - loss: 11.8009 - val_loss: 14.8813 - lr: 4.0561e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.01e-05, weight decay: 2.01e-06\n",
            "Epoch 1309/1500\n",
            "Val unfiltered loss: 20.778583526611328\n",
            "233/233 - 44s - loss: 11.8192 - val_loss: 15.0719 - lr: 4.0148e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.97e-05, weight decay: 1.99e-06\n",
            "Epoch 1310/1500\n",
            "Val unfiltered loss: 20.657575607299805\n",
            "233/233 - 44s - loss: 11.8213 - val_loss: 14.9368 - lr: 3.9736e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.93e-05, weight decay: 1.97e-06\n",
            "Epoch 1311/1500\n",
            "Val unfiltered loss: 20.597074508666992\n",
            "233/233 - 44s - loss: 11.7678 - val_loss: 14.9373 - lr: 3.9327e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.89e-05, weight decay: 1.95e-06\n",
            "Epoch 1312/1500\n",
            "Val unfiltered loss: 20.677888870239258\n",
            "233/233 - 44s - loss: 11.8494 - val_loss: 14.9394 - lr: 3.8919e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.85e-05, weight decay: 1.93e-06\n",
            "Epoch 1313/1500\n",
            "Val unfiltered loss: 20.656755447387695\n",
            "233/233 - 44s - loss: 11.7702 - val_loss: 14.9791 - lr: 3.8514e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.81e-05, weight decay: 1.91e-06\n",
            "Epoch 1314/1500\n",
            "Val unfiltered loss: 20.58943748474121\n",
            "233/233 - 43s - loss: 11.7998 - val_loss: 14.9098 - lr: 3.8111e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 3.77e-05, weight decay: 1.89e-06\n",
            "Epoch 1315/1500\n",
            "Val unfiltered loss: 20.5783748626709\n",
            "233/233 - 44s - loss: 11.8163 - val_loss: 14.9199 - lr: 3.7709e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.73e-05, weight decay: 1.87e-06\n",
            "Epoch 1316/1500\n",
            "Val unfiltered loss: 20.52112579345703\n",
            "233/233 - 44s - loss: 11.8218 - val_loss: 14.8999 - lr: 3.7310e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.69e-05, weight decay: 1.85e-06\n",
            "Epoch 1317/1500\n",
            "Val unfiltered loss: 20.682538986206055\n",
            "233/233 - 44s - loss: 11.7764 - val_loss: 14.9911 - lr: 3.6913e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.65e-05, weight decay: 1.83e-06\n",
            "Epoch 1318/1500\n",
            "Val unfiltered loss: 20.57170295715332\n",
            "233/233 - 44s - loss: 11.7772 - val_loss: 14.8884 - lr: 3.6517e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.61e-05, weight decay: 1.81e-06\n",
            "Epoch 1319/1500\n",
            "Val unfiltered loss: 20.568727493286133\n",
            "233/233 - 44s - loss: 11.7919 - val_loss: 14.8696 - lr: 3.6124e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.57e-05, weight decay: 1.79e-06\n",
            "Epoch 1320/1500\n",
            "Val unfiltered loss: 20.779552459716797\n",
            "233/233 - 44s - loss: 11.7974 - val_loss: 15.0396 - lr: 3.5733e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.53e-05, weight decay: 1.77e-06\n",
            "Epoch 1321/1500\n",
            "Val unfiltered loss: 20.689599990844727\n",
            "233/233 - 44s - loss: 11.8164 - val_loss: 14.9379 - lr: 3.5344e-05 - 44s/epoch - 191ms/step\n",
            "learning rate: 3.50e-05, weight decay: 1.75e-06\n",
            "Epoch 1322/1500\n",
            "Val unfiltered loss: 20.717546463012695\n",
            "233/233 - 44s - loss: 11.7914 - val_loss: 14.9919 - lr: 3.4957e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.46e-05, weight decay: 1.73e-06\n",
            "Epoch 1323/1500\n",
            "Val unfiltered loss: 20.590551376342773\n",
            "233/233 - 44s - loss: 11.8189 - val_loss: 14.8909 - lr: 3.4572e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.42e-05, weight decay: 1.71e-06\n",
            "Epoch 1324/1500\n",
            "Val unfiltered loss: 20.623857498168945\n",
            "233/233 - 44s - loss: 11.7734 - val_loss: 14.9571 - lr: 3.4189e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.38e-05, weight decay: 1.69e-06\n",
            "Epoch 1325/1500\n",
            "Val unfiltered loss: 20.68402862548828\n",
            "233/233 - 44s - loss: 11.8141 - val_loss: 14.9952 - lr: 3.3809e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 3.34e-05, weight decay: 1.67e-06\n",
            "Epoch 1326/1500\n",
            "Val unfiltered loss: 20.60527801513672\n",
            "233/233 - 44s - loss: 11.8054 - val_loss: 14.9488 - lr: 3.3430e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.31e-05, weight decay: 1.65e-06\n",
            "Epoch 1327/1500\n",
            "Val unfiltered loss: 20.600461959838867\n",
            "233/233 - 43s - loss: 11.7125 - val_loss: 14.8974 - lr: 3.3053e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 3.27e-05, weight decay: 1.63e-06\n",
            "Epoch 1328/1500\n",
            "Val unfiltered loss: 20.49659538269043\n",
            "233/233 - 44s - loss: 11.7851 - val_loss: 14.8853 - lr: 3.2678e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.23e-05, weight decay: 1.62e-06\n",
            "Epoch 1329/1500\n",
            "Val unfiltered loss: 20.568326950073242\n",
            "233/233 - 43s - loss: 11.7844 - val_loss: 14.9026 - lr: 3.2306e-05 - 43s/epoch - 186ms/step\n",
            "learning rate: 3.19e-05, weight decay: 1.60e-06\n",
            "Epoch 1330/1500\n",
            "Val unfiltered loss: 20.54241371154785\n",
            "233/233 - 45s - loss: 11.8493 - val_loss: 14.8456 - lr: 3.1935e-05 - 45s/epoch - 192ms/step\n",
            "learning rate: 3.16e-05, weight decay: 1.58e-06\n",
            "Epoch 1331/1500\n",
            "Val unfiltered loss: 20.58251190185547\n",
            "233/233 - 44s - loss: 11.7737 - val_loss: 14.8683 - lr: 3.1567e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.12e-05, weight decay: 1.56e-06\n",
            "Epoch 1332/1500\n",
            "Val unfiltered loss: 20.61449432373047\n",
            "233/233 - 44s - loss: 11.7835 - val_loss: 14.9255 - lr: 3.1200e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.08e-05, weight decay: 1.54e-06\n",
            "Epoch 1333/1500\n",
            "Val unfiltered loss: 20.69025993347168\n",
            "233/233 - 43s - loss: 11.7633 - val_loss: 14.9503 - lr: 3.0836e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 3.05e-05, weight decay: 1.52e-06\n",
            "Epoch 1334/1500\n",
            "Val unfiltered loss: 20.711645126342773\n",
            "233/233 - 44s - loss: 11.8388 - val_loss: 14.9700 - lr: 3.0474e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.01e-05, weight decay: 1.51e-06\n",
            "Epoch 1335/1500\n",
            "Val unfiltered loss: 20.668495178222656\n",
            "233/233 - 44s - loss: 11.7636 - val_loss: 14.9235 - lr: 3.0114e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.98e-05, weight decay: 1.49e-06\n",
            "Epoch 1336/1500\n",
            "Val unfiltered loss: 20.640459060668945\n",
            "233/233 - 44s - loss: 11.7749 - val_loss: 14.9167 - lr: 2.9756e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.94e-05, weight decay: 1.47e-06\n",
            "Epoch 1337/1500\n",
            "Val unfiltered loss: 20.774198532104492\n",
            "233/233 - 45s - loss: 11.7950 - val_loss: 14.9746 - lr: 2.9400e-05 - 45s/epoch - 193ms/step\n",
            "learning rate: 2.90e-05, weight decay: 1.45e-06\n",
            "Epoch 1338/1500\n",
            "Val unfiltered loss: 20.723228454589844\n",
            "233/233 - 44s - loss: 11.7663 - val_loss: 14.9302 - lr: 2.9046e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 2.87e-05, weight decay: 1.43e-06\n",
            "Epoch 1339/1500\n",
            "Val unfiltered loss: 20.518056869506836\n",
            "233/233 - 44s - loss: 11.7788 - val_loss: 14.8355 - lr: 2.8694e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.83e-05, weight decay: 1.42e-06\n",
            "Epoch 1340/1500\n",
            "Val unfiltered loss: 20.68099594116211\n",
            "233/233 - 44s - loss: 11.7031 - val_loss: 14.9486 - lr: 2.8344e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.80e-05, weight decay: 1.40e-06\n",
            "Epoch 1341/1500\n",
            "Val unfiltered loss: 20.654470443725586\n",
            "233/233 - 44s - loss: 11.7539 - val_loss: 14.9920 - lr: 2.7996e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.77e-05, weight decay: 1.38e-06\n",
            "Epoch 1342/1500\n",
            "Val unfiltered loss: 20.639142990112305\n",
            "233/233 - 44s - loss: 11.7545 - val_loss: 15.0068 - lr: 2.7651e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.73e-05, weight decay: 1.37e-06\n",
            "Epoch 1343/1500\n",
            "Val unfiltered loss: 20.732511520385742\n",
            "233/233 - 43s - loss: 11.7870 - val_loss: 15.0194 - lr: 2.7307e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 2.70e-05, weight decay: 1.35e-06\n",
            "Epoch 1344/1500\n",
            "Val unfiltered loss: 20.699087142944336\n",
            "233/233 - 45s - loss: 11.7910 - val_loss: 14.9897 - lr: 2.6966e-05 - 45s/epoch - 194ms/step\n",
            "learning rate: 2.66e-05, weight decay: 1.33e-06\n",
            "Epoch 1345/1500\n",
            "Val unfiltered loss: 20.596704483032227\n",
            "233/233 - 44s - loss: 11.8013 - val_loss: 14.9457 - lr: 2.6626e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.63e-05, weight decay: 1.31e-06\n",
            "Epoch 1346/1500\n",
            "Val unfiltered loss: 20.53900718688965\n",
            "233/233 - 44s - loss: 11.7554 - val_loss: 14.8898 - lr: 2.6289e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.60e-05, weight decay: 1.30e-06\n",
            "Epoch 1347/1500\n",
            "Val unfiltered loss: 20.537994384765625\n",
            "233/233 - 44s - loss: 11.7958 - val_loss: 14.8892 - lr: 2.5954e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.56e-05, weight decay: 1.28e-06\n",
            "Epoch 1348/1500\n",
            "Val unfiltered loss: 20.594789505004883\n",
            "233/233 - 44s - loss: 11.7313 - val_loss: 14.9145 - lr: 2.5621e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.53e-05, weight decay: 1.26e-06\n",
            "Epoch 1349/1500\n",
            "Val unfiltered loss: 20.592309951782227\n",
            "233/233 - 44s - loss: 11.8287 - val_loss: 14.9159 - lr: 2.5290e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.50e-05, weight decay: 1.25e-06\n",
            "Epoch 1350/1500\n",
            "Val unfiltered loss: 20.5943660736084\n",
            "Val filtered lev distance: 0.8646058462680376\n",
            "Val unfiltered lev distance: 0.8171589869995627\n",
            "Sub train lev distance: 0.97970398914043\n",
            "233/233 - 120s - loss: 11.7288 - val_loss: 14.9001 - lr: 2.4961e-05 - 120s/epoch - 515ms/step\n",
            "learning rate: 2.46e-05, weight decay: 1.23e-06\n",
            "Epoch 1351/1500\n",
            "Val unfiltered loss: 20.620101928710938\n",
            "233/233 - 44s - loss: 11.7348 - val_loss: 14.9387 - lr: 2.4634e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 2.43e-05, weight decay: 1.22e-06\n",
            "Epoch 1352/1500\n",
            "Val unfiltered loss: 20.642366409301758\n",
            "233/233 - 44s - loss: 11.7251 - val_loss: 14.9614 - lr: 2.4310e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.40e-05, weight decay: 1.20e-06\n",
            "Epoch 1353/1500\n",
            "Val unfiltered loss: 20.682804107666016\n",
            "233/233 - 45s - loss: 11.7413 - val_loss: 14.9716 - lr: 2.3987e-05 - 45s/epoch - 193ms/step\n",
            "learning rate: 2.37e-05, weight decay: 1.18e-06\n",
            "Epoch 1354/1500\n",
            "Val unfiltered loss: 20.597999572753906\n",
            "233/233 - 44s - loss: 11.7224 - val_loss: 14.9116 - lr: 2.3667e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.33e-05, weight decay: 1.17e-06\n",
            "Epoch 1355/1500\n",
            "Val unfiltered loss: 20.60228729248047\n",
            "233/233 - 44s - loss: 11.7481 - val_loss: 14.9641 - lr: 2.3348e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.30e-05, weight decay: 1.15e-06\n",
            "Epoch 1356/1500\n",
            "Val unfiltered loss: 20.625364303588867\n",
            "233/233 - 44s - loss: 11.7909 - val_loss: 14.9702 - lr: 2.3032e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.27e-05, weight decay: 1.14e-06\n",
            "Epoch 1357/1500\n",
            "Val unfiltered loss: 20.588970184326172\n",
            "233/233 - 44s - loss: 11.8017 - val_loss: 14.9604 - lr: 2.2718e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.24e-05, weight decay: 1.12e-06\n",
            "Epoch 1358/1500\n",
            "Val unfiltered loss: 20.585494995117188\n",
            "233/233 - 44s - loss: 11.7447 - val_loss: 14.9831 - lr: 2.2406e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.21e-05, weight decay: 1.10e-06\n",
            "Epoch 1359/1500\n",
            "Val unfiltered loss: 20.611202239990234\n",
            "233/233 - 44s - loss: 11.7682 - val_loss: 14.9598 - lr: 2.2096e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.18e-05, weight decay: 1.09e-06\n",
            "Epoch 1360/1500\n",
            "Val unfiltered loss: 20.608469009399414\n",
            "233/233 - 45s - loss: 11.7085 - val_loss: 14.9653 - lr: 2.1788e-05 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.15e-05, weight decay: 1.07e-06\n",
            "Epoch 1361/1500\n",
            "Val unfiltered loss: 20.634510040283203\n",
            "233/233 - 45s - loss: 11.7458 - val_loss: 14.9477 - lr: 2.1482e-05 - 45s/epoch - 191ms/step\n",
            "learning rate: 2.12e-05, weight decay: 1.06e-06\n",
            "Epoch 1362/1500\n",
            "Val unfiltered loss: 20.67147445678711\n",
            "233/233 - 44s - loss: 11.7475 - val_loss: 14.9328 - lr: 2.1179e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.09e-05, weight decay: 1.04e-06\n",
            "Epoch 1363/1500\n",
            "Val unfiltered loss: 20.686006546020508\n",
            "233/233 - 44s - loss: 11.7180 - val_loss: 14.9723 - lr: 2.0877e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 2.06e-05, weight decay: 1.03e-06\n",
            "Epoch 1364/1500\n",
            "Val unfiltered loss: 20.712890625\n",
            "233/233 - 44s - loss: 11.7412 - val_loss: 14.9964 - lr: 2.0578e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.03e-05, weight decay: 1.01e-06\n",
            "Epoch 1365/1500\n",
            "Val unfiltered loss: 20.66356658935547\n",
            "233/233 - 45s - loss: 11.7787 - val_loss: 14.9918 - lr: 2.0280e-05 - 45s/epoch - 191ms/step\n",
            "learning rate: 2.00e-05, weight decay: 9.99e-07\n",
            "Epoch 1366/1500\n",
            "Val unfiltered loss: 20.61489486694336\n",
            "233/233 - 43s - loss: 11.7554 - val_loss: 14.9207 - lr: 1.9985e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.97e-05, weight decay: 9.85e-07\n",
            "Epoch 1367/1500\n",
            "Val unfiltered loss: 20.61862564086914\n",
            "233/233 - 46s - loss: 11.7440 - val_loss: 14.9862 - lr: 1.9692e-05 - 46s/epoch - 195ms/step\n",
            "learning rate: 1.94e-05, weight decay: 9.70e-07\n",
            "Epoch 1368/1500\n",
            "Val unfiltered loss: 20.51624298095703\n",
            "233/233 - 44s - loss: 11.7396 - val_loss: 14.9181 - lr: 1.9401e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.91e-05, weight decay: 9.56e-07\n",
            "Epoch 1369/1500\n",
            "Val unfiltered loss: 20.687715530395508\n",
            "233/233 - 44s - loss: 11.7479 - val_loss: 15.0014 - lr: 1.9113e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.88e-05, weight decay: 9.41e-07\n",
            "Epoch 1370/1500\n",
            "Val unfiltered loss: 20.649988174438477\n",
            "233/233 - 44s - loss: 11.7439 - val_loss: 14.9742 - lr: 1.8826e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.85e-05, weight decay: 9.27e-07\n",
            "Epoch 1371/1500\n",
            "Val unfiltered loss: 20.712623596191406\n",
            "233/233 - 44s - loss: 11.7366 - val_loss: 15.0304 - lr: 1.8541e-05 - 44s/epoch - 191ms/step\n",
            "learning rate: 1.83e-05, weight decay: 9.13e-07\n",
            "Epoch 1372/1500\n",
            "Val unfiltered loss: 20.5725154876709\n",
            "233/233 - 44s - loss: 11.7603 - val_loss: 14.9087 - lr: 1.8259e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.80e-05, weight decay: 8.99e-07\n",
            "Epoch 1373/1500\n",
            "Val unfiltered loss: 20.592924118041992\n",
            "233/233 - 43s - loss: 11.7695 - val_loss: 14.9460 - lr: 1.7979e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.77e-05, weight decay: 8.85e-07\n",
            "Epoch 1374/1500\n",
            "Val unfiltered loss: 20.566179275512695\n",
            "233/233 - 44s - loss: 11.7207 - val_loss: 14.9247 - lr: 1.7701e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.74e-05, weight decay: 8.71e-07\n",
            "Epoch 1375/1500\n",
            "Val unfiltered loss: 20.680461883544922\n",
            "233/233 - 44s - loss: 11.7153 - val_loss: 14.9842 - lr: 1.7424e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.72e-05, weight decay: 8.58e-07\n",
            "Epoch 1376/1500\n",
            "Val unfiltered loss: 20.685291290283203\n",
            "233/233 - 43s - loss: 11.7061 - val_loss: 14.9920 - lr: 1.7151e-05 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.69e-05, weight decay: 8.44e-07\n",
            "Epoch 1377/1500\n",
            "Val unfiltered loss: 20.68036460876465\n",
            "233/233 - 44s - loss: 11.7491 - val_loss: 15.0179 - lr: 1.6879e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.66e-05, weight decay: 8.30e-07\n",
            "Epoch 1378/1500\n",
            "Val unfiltered loss: 20.661766052246094\n",
            "233/233 - 44s - loss: 11.7537 - val_loss: 14.9741 - lr: 1.6609e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.63e-05, weight decay: 8.17e-07\n",
            "Epoch 1379/1500\n",
            "Val unfiltered loss: 20.569334030151367\n",
            "233/233 - 44s - loss: 11.7655 - val_loss: 14.9476 - lr: 1.6342e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.61e-05, weight decay: 8.04e-07\n",
            "Epoch 1380/1500\n",
            "Val unfiltered loss: 20.67896842956543\n",
            "233/233 - 44s - loss: 11.7619 - val_loss: 15.0206 - lr: 1.6076e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.58e-05, weight decay: 7.91e-07\n",
            "Epoch 1381/1500\n",
            "Val unfiltered loss: 20.720155715942383\n",
            "233/233 - 46s - loss: 11.7363 - val_loss: 15.0015 - lr: 1.5813e-05 - 46s/epoch - 196ms/step\n",
            "learning rate: 1.56e-05, weight decay: 7.78e-07\n",
            "Epoch 1382/1500\n",
            "Val unfiltered loss: 20.657594680786133\n",
            "233/233 - 44s - loss: 11.7326 - val_loss: 14.9677 - lr: 1.5552e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.53e-05, weight decay: 7.65e-07\n",
            "Epoch 1383/1500\n",
            "Val unfiltered loss: 20.717805862426758\n",
            "233/233 - 44s - loss: 11.7882 - val_loss: 15.0009 - lr: 1.5293e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.50e-05, weight decay: 7.52e-07\n",
            "Epoch 1384/1500\n",
            "Val unfiltered loss: 20.722862243652344\n",
            "233/233 - 44s - loss: 11.6924 - val_loss: 15.0145 - lr: 1.5036e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.48e-05, weight decay: 7.39e-07\n",
            "Epoch 1385/1500\n",
            "Val unfiltered loss: 20.704023361206055\n",
            "233/233 - 44s - loss: 11.7254 - val_loss: 15.0353 - lr: 1.4782e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.45e-05, weight decay: 7.26e-07\n",
            "Epoch 1386/1500\n",
            "Val unfiltered loss: 20.61141586303711\n",
            "233/233 - 44s - loss: 11.7040 - val_loss: 14.9211 - lr: 1.4529e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.43e-05, weight decay: 7.14e-07\n",
            "Epoch 1387/1500\n",
            "Val unfiltered loss: 20.616514205932617\n",
            "233/233 - 44s - loss: 11.7064 - val_loss: 14.9411 - lr: 1.4279e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.40e-05, weight decay: 7.02e-07\n",
            "Epoch 1388/1500\n",
            "Val unfiltered loss: 20.64246368408203\n",
            "233/233 - 44s - loss: 11.6935 - val_loss: 14.9263 - lr: 1.4030e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.38e-05, weight decay: 6.89e-07\n",
            "Epoch 1389/1500\n",
            "Val unfiltered loss: 20.640703201293945\n",
            "233/233 - 45s - loss: 11.6864 - val_loss: 14.9602 - lr: 1.3784e-05 - 45s/epoch - 193ms/step\n",
            "learning rate: 1.35e-05, weight decay: 6.77e-07\n",
            "Epoch 1390/1500\n",
            "Val unfiltered loss: 20.724998474121094\n",
            "233/233 - 44s - loss: 11.6743 - val_loss: 15.0473 - lr: 1.3540e-05 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.33e-05, weight decay: 6.65e-07\n",
            "Epoch 1391/1500\n",
            "Val unfiltered loss: 20.70887565612793\n",
            "233/233 - 44s - loss: 11.7326 - val_loss: 15.0083 - lr: 1.3299e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.31e-05, weight decay: 6.53e-07\n",
            "Epoch 1392/1500\n",
            "Val unfiltered loss: 20.639768600463867\n",
            "233/233 - 44s - loss: 11.6997 - val_loss: 14.9589 - lr: 1.3059e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.28e-05, weight decay: 6.41e-07\n",
            "Epoch 1393/1500\n",
            "Val unfiltered loss: 20.6883487701416\n",
            "233/233 - 44s - loss: 11.6655 - val_loss: 14.9698 - lr: 1.2822e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.26e-05, weight decay: 6.29e-07\n",
            "Epoch 1394/1500\n",
            "Val unfiltered loss: 20.656373977661133\n",
            "233/233 - 44s - loss: 11.7574 - val_loss: 14.9696 - lr: 1.2586e-05 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.24e-05, weight decay: 6.18e-07\n",
            "Epoch 1395/1500\n",
            "Val unfiltered loss: 20.69593620300293\n",
            "233/233 - 44s - loss: 11.6981 - val_loss: 14.9752 - lr: 1.2353e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.21e-05, weight decay: 6.06e-07\n",
            "Epoch 1396/1500\n",
            "Val unfiltered loss: 20.625513076782227\n",
            "233/233 - 45s - loss: 11.7392 - val_loss: 14.9394 - lr: 1.2122e-05 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.19e-05, weight decay: 5.95e-07\n",
            "Epoch 1397/1500\n",
            "Val unfiltered loss: 20.723339080810547\n",
            "233/233 - 45s - loss: 11.6873 - val_loss: 14.9830 - lr: 1.1893e-05 - 45s/epoch - 191ms/step\n",
            "learning rate: 1.17e-05, weight decay: 5.83e-07\n",
            "Epoch 1398/1500\n",
            "Val unfiltered loss: 20.684009552001953\n",
            "233/233 - 44s - loss: 11.7507 - val_loss: 14.9736 - lr: 1.1666e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.14e-05, weight decay: 5.72e-07\n",
            "Epoch 1399/1500\n",
            "Val unfiltered loss: 20.597532272338867\n",
            "233/233 - 44s - loss: 11.6735 - val_loss: 14.9166 - lr: 1.1442e-05 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.12e-05, weight decay: 5.61e-07\n",
            "Epoch 1400/1500\n",
            "Val unfiltered loss: 20.574169158935547\n",
            "Val filtered lev distance: 0.8650424607592726\n",
            "Val unfiltered lev distance: 0.8173180137558144\n",
            "Sub train lev distance: 0.9798134606121645\n",
            "233/233 - 122s - loss: 11.7271 - val_loss: 14.9017 - lr: 1.1219e-05 - 122s/epoch - 523ms/step\n",
            "learning rate: 1.10e-05, weight decay: 5.50e-07\n",
            "Epoch 1401/1500\n",
            "Val unfiltered loss: 20.64568519592285\n",
            "233/233 - 44s - loss: 11.7276 - val_loss: 14.9532 - lr: 1.0999e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.08e-05, weight decay: 5.39e-07\n",
            "Epoch 1402/1500\n",
            "Val unfiltered loss: 20.6155948638916\n",
            "233/233 - 44s - loss: 11.7288 - val_loss: 14.9320 - lr: 1.0781e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.06e-05, weight decay: 5.28e-07\n",
            "Epoch 1403/1500\n",
            "Val unfiltered loss: 20.597240447998047\n",
            "233/233 - 45s - loss: 11.6837 - val_loss: 14.9281 - lr: 1.0565e-05 - 45s/epoch - 191ms/step\n",
            "learning rate: 1.04e-05, weight decay: 5.18e-07\n",
            "Epoch 1404/1500\n",
            "Val unfiltered loss: 20.660865783691406\n",
            "233/233 - 44s - loss: 11.7116 - val_loss: 15.0061 - lr: 1.0351e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.01e-05, weight decay: 5.07e-07\n",
            "Epoch 1405/1500\n",
            "Val unfiltered loss: 20.684492111206055\n",
            "233/233 - 44s - loss: 11.7593 - val_loss: 14.9458 - lr: 1.0140e-05 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.93e-06, weight decay: 4.97e-07\n",
            "Epoch 1406/1500\n",
            "Val unfiltered loss: 20.702253341674805\n",
            "233/233 - 44s - loss: 11.6802 - val_loss: 14.9662 - lr: 9.9303e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 9.72e-06, weight decay: 4.86e-07\n",
            "Epoch 1407/1500\n",
            "Val unfiltered loss: 20.65951919555664\n",
            "233/233 - 44s - loss: 11.7394 - val_loss: 14.9191 - lr: 9.7230e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.52e-06, weight decay: 4.76e-07\n",
            "Epoch 1408/1500\n",
            "Val unfiltered loss: 20.599119186401367\n",
            "233/233 - 44s - loss: 11.7052 - val_loss: 14.8850 - lr: 9.5179e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.31e-06, weight decay: 4.66e-07\n",
            "Epoch 1409/1500\n",
            "Val unfiltered loss: 20.5424747467041\n",
            "233/233 - 44s - loss: 11.6953 - val_loss: 14.8697 - lr: 9.3149e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 9.11e-06, weight decay: 4.56e-07\n",
            "Epoch 1410/1500\n",
            "Val unfiltered loss: 20.721834182739258\n",
            "233/233 - 44s - loss: 11.7404 - val_loss: 14.9888 - lr: 9.1142e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.92e-06, weight decay: 4.46e-07\n",
            "Epoch 1411/1500\n",
            "Val unfiltered loss: 20.59653663635254\n",
            "233/233 - 44s - loss: 11.7372 - val_loss: 14.9243 - lr: 8.9155e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.72e-06, weight decay: 4.36e-07\n",
            "Epoch 1412/1500\n",
            "Val unfiltered loss: 20.608110427856445\n",
            "233/233 - 44s - loss: 11.6726 - val_loss: 14.9492 - lr: 8.7191e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.52e-06, weight decay: 4.26e-07\n",
            "Epoch 1413/1500\n",
            "Val unfiltered loss: 20.6253662109375\n",
            "233/233 - 44s - loss: 11.7257 - val_loss: 14.9118 - lr: 8.5248e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.33e-06, weight decay: 4.17e-07\n",
            "Epoch 1414/1500\n",
            "Val unfiltered loss: 20.648536682128906\n",
            "233/233 - 44s - loss: 11.7740 - val_loss: 14.9444 - lr: 8.3327e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 8.14e-06, weight decay: 4.07e-07\n",
            "Epoch 1415/1500\n",
            "Val unfiltered loss: 20.637847900390625\n",
            "233/233 - 44s - loss: 11.6979 - val_loss: 14.9057 - lr: 8.1428e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.96e-06, weight decay: 3.98e-07\n",
            "Epoch 1416/1500\n",
            "Val unfiltered loss: 20.650236129760742\n",
            "233/233 - 44s - loss: 11.7063 - val_loss: 14.9399 - lr: 7.9550e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.77e-06, weight decay: 3.88e-07\n",
            "Epoch 1417/1500\n",
            "Val unfiltered loss: 20.621971130371094\n",
            "233/233 - 44s - loss: 11.6977 - val_loss: 14.9144 - lr: 7.7694e-06 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.59e-06, weight decay: 3.79e-07\n",
            "Epoch 1418/1500\n",
            "Val unfiltered loss: 20.672382354736328\n",
            "233/233 - 44s - loss: 11.6717 - val_loss: 14.9585 - lr: 7.5860e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 7.40e-06, weight decay: 3.70e-07\n",
            "Epoch 1419/1500\n",
            "Val unfiltered loss: 20.633169174194336\n",
            "233/233 - 45s - loss: 11.6921 - val_loss: 14.9390 - lr: 7.4047e-06 - 45s/epoch - 194ms/step\n",
            "learning rate: 7.23e-06, weight decay: 3.61e-07\n",
            "Epoch 1420/1500\n",
            "Val unfiltered loss: 20.619312286376953\n",
            "233/233 - 44s - loss: 11.7525 - val_loss: 14.9217 - lr: 7.2257e-06 - 44s/epoch - 190ms/step\n",
            "learning rate: 7.05e-06, weight decay: 3.52e-07\n",
            "Epoch 1421/1500\n",
            "Val unfiltered loss: 20.686845779418945\n",
            "233/233 - 44s - loss: 11.6858 - val_loss: 14.9719 - lr: 7.0488e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.87e-06, weight decay: 3.44e-07\n",
            "Epoch 1422/1500\n",
            "Val unfiltered loss: 20.67753028869629\n",
            "233/233 - 44s - loss: 11.7014 - val_loss: 14.9788 - lr: 6.8741e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.70e-06, weight decay: 3.35e-07\n",
            "Epoch 1423/1500\n",
            "Val unfiltered loss: 20.663118362426758\n",
            "233/233 - 44s - loss: 11.6796 - val_loss: 14.9702 - lr: 6.7015e-06 - 44s/epoch - 190ms/step\n",
            "learning rate: 6.53e-06, weight decay: 3.27e-07\n",
            "Epoch 1424/1500\n",
            "Val unfiltered loss: 20.67067527770996\n",
            "233/233 - 44s - loss: 11.7536 - val_loss: 14.9599 - lr: 6.5312e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.36e-06, weight decay: 3.18e-07\n",
            "Epoch 1425/1500\n",
            "Val unfiltered loss: 20.71288299560547\n",
            "233/233 - 44s - loss: 11.6785 - val_loss: 15.0073 - lr: 6.3630e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.20e-06, weight decay: 3.10e-07\n",
            "Epoch 1426/1500\n",
            "Val unfiltered loss: 20.72685432434082\n",
            "233/233 - 45s - loss: 11.6807 - val_loss: 14.9602 - lr: 6.1970e-06 - 45s/epoch - 195ms/step\n",
            "learning rate: 6.03e-06, weight decay: 3.02e-07\n",
            "Epoch 1427/1500\n",
            "Val unfiltered loss: 20.741552352905273\n",
            "233/233 - 44s - loss: 11.6882 - val_loss: 14.9728 - lr: 6.0332e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.87e-06, weight decay: 2.94e-07\n",
            "Epoch 1428/1500\n",
            "Val unfiltered loss: 20.733455657958984\n",
            "233/233 - 44s - loss: 11.7039 - val_loss: 15.0071 - lr: 5.8715e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.71e-06, weight decay: 2.86e-07\n",
            "Epoch 1429/1500\n",
            "Val unfiltered loss: 20.72016143798828\n",
            "233/233 - 44s - loss: 11.6979 - val_loss: 14.9936 - lr: 5.7121e-06 - 44s/epoch - 191ms/step\n",
            "learning rate: 5.55e-06, weight decay: 2.78e-07\n",
            "Epoch 1430/1500\n",
            "Val unfiltered loss: 20.739702224731445\n",
            "233/233 - 44s - loss: 11.6506 - val_loss: 15.0076 - lr: 5.5548e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 5.40e-06, weight decay: 2.70e-07\n",
            "Epoch 1431/1500\n",
            "Val unfiltered loss: 20.721616744995117\n",
            "233/233 - 44s - loss: 11.6865 - val_loss: 14.9601 - lr: 5.3997e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.25e-06, weight decay: 2.62e-07\n",
            "Epoch 1432/1500\n",
            "Val unfiltered loss: 20.686037063598633\n",
            "233/233 - 44s - loss: 11.6986 - val_loss: 14.9610 - lr: 5.2468e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.10e-06, weight decay: 2.55e-07\n",
            "Epoch 1433/1500\n",
            "Val unfiltered loss: 20.737640380859375\n",
            "233/233 - 45s - loss: 11.7021 - val_loss: 14.9882 - lr: 5.0961e-06 - 45s/epoch - 195ms/step\n",
            "learning rate: 4.95e-06, weight decay: 2.47e-07\n",
            "Epoch 1434/1500\n",
            "Val unfiltered loss: 20.702180862426758\n",
            "233/233 - 44s - loss: 11.7223 - val_loss: 14.9512 - lr: 4.9475e-06 - 44s/epoch - 190ms/step\n",
            "learning rate: 4.80e-06, weight decay: 2.40e-07\n",
            "Epoch 1435/1500\n",
            "Val unfiltered loss: 20.696067810058594\n",
            "233/233 - 44s - loss: 11.7069 - val_loss: 14.9493 - lr: 4.8012e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.66e-06, weight decay: 2.33e-07\n",
            "Epoch 1436/1500\n",
            "Val unfiltered loss: 20.685758590698242\n",
            "233/233 - 44s - loss: 11.6671 - val_loss: 14.9233 - lr: 4.6570e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.52e-06, weight decay: 2.26e-07\n",
            "Epoch 1437/1500\n",
            "Val unfiltered loss: 20.65345001220703\n",
            "233/233 - 43s - loss: 11.7061 - val_loss: 14.9251 - lr: 4.5151e-06 - 43s/epoch - 186ms/step\n",
            "learning rate: 4.38e-06, weight decay: 2.19e-07\n",
            "Epoch 1438/1500\n",
            "Val unfiltered loss: 20.70131492614746\n",
            "233/233 - 44s - loss: 11.6752 - val_loss: 14.9706 - lr: 4.3753e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 4.24e-06, weight decay: 2.12e-07\n",
            "Epoch 1439/1500\n",
            "Val unfiltered loss: 20.662466049194336\n",
            "233/233 - 44s - loss: 11.6877 - val_loss: 14.9372 - lr: 4.2377e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 4.10e-06, weight decay: 2.05e-07\n",
            "Epoch 1440/1500\n",
            "Val unfiltered loss: 20.77354621887207\n",
            "233/233 - 45s - loss: 11.7143 - val_loss: 15.0202 - lr: 4.1023e-06 - 45s/epoch - 192ms/step\n",
            "learning rate: 3.97e-06, weight decay: 1.98e-07\n",
            "Epoch 1441/1500\n",
            "Val unfiltered loss: 20.719139099121094\n",
            "233/233 - 44s - loss: 11.6943 - val_loss: 15.0044 - lr: 3.9690e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.84e-06, weight decay: 1.92e-07\n",
            "Epoch 1442/1500\n",
            "Val unfiltered loss: 20.69866371154785\n",
            "233/233 - 44s - loss: 11.6748 - val_loss: 14.9488 - lr: 3.8380e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.71e-06, weight decay: 1.85e-07\n",
            "Epoch 1443/1500\n",
            "Val unfiltered loss: 20.71858024597168\n",
            "233/233 - 44s - loss: 11.7097 - val_loss: 14.9853 - lr: 3.7092e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.58e-06, weight decay: 1.79e-07\n",
            "Epoch 1444/1500\n",
            "Val unfiltered loss: 20.716054916381836\n",
            "233/233 - 44s - loss: 11.6727 - val_loss: 14.9720 - lr: 3.5825e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.46e-06, weight decay: 1.73e-07\n",
            "Epoch 1445/1500\n",
            "Val unfiltered loss: 20.735872268676758\n",
            "233/233 - 44s - loss: 11.6690 - val_loss: 14.9844 - lr: 3.4581e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.34e-06, weight decay: 1.67e-07\n",
            "Epoch 1446/1500\n",
            "Val unfiltered loss: 20.743152618408203\n",
            "233/233 - 44s - loss: 11.5716 - val_loss: 14.9938 - lr: 3.3358e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 3.22e-06, weight decay: 1.61e-07\n",
            "Epoch 1447/1500\n",
            "Val unfiltered loss: 20.727928161621094\n",
            "233/233 - 44s - loss: 11.7149 - val_loss: 14.9675 - lr: 3.2157e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.10e-06, weight decay: 1.55e-07\n",
            "Epoch 1448/1500\n",
            "Val unfiltered loss: 20.735261917114258\n",
            "233/233 - 45s - loss: 11.6788 - val_loss: 15.0056 - lr: 3.0978e-06 - 45s/epoch - 192ms/step\n",
            "learning rate: 2.98e-06, weight decay: 1.49e-07\n",
            "Epoch 1449/1500\n",
            "Val unfiltered loss: 20.666284561157227\n",
            "233/233 - 44s - loss: 11.7700 - val_loss: 14.9344 - lr: 2.9822e-06 - 44s/epoch - 190ms/step\n",
            "learning rate: 2.87e-06, weight decay: 1.43e-07\n",
            "Epoch 1450/1500\n",
            "Val unfiltered loss: 20.708154678344727\n",
            "Val filtered lev distance: 0.8646931691662846\n",
            "Val unfiltered lev distance: 0.817556553890192\n",
            "Sub train lev distance: 0.9798353549065114\n",
            "233/233 - 121s - loss: 11.7021 - val_loss: 14.9744 - lr: 2.8687e-06 - 121s/epoch - 519ms/step\n",
            "learning rate: 2.76e-06, weight decay: 1.38e-07\n",
            "Epoch 1451/1500\n",
            "Val unfiltered loss: 20.67042350769043\n",
            "233/233 - 44s - loss: 11.6639 - val_loss: 14.9683 - lr: 2.7574e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.65e-06, weight decay: 1.32e-07\n",
            "Epoch 1452/1500\n",
            "Val unfiltered loss: 20.704145431518555\n",
            "233/233 - 44s - loss: 11.6804 - val_loss: 14.9804 - lr: 2.6483e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.54e-06, weight decay: 1.27e-07\n",
            "Epoch 1453/1500\n",
            "Val unfiltered loss: 20.661787033081055\n",
            "233/233 - 43s - loss: 11.6919 - val_loss: 14.9664 - lr: 2.5414e-06 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.44e-06, weight decay: 1.22e-07\n",
            "Epoch 1454/1500\n",
            "Val unfiltered loss: 20.65643310546875\n",
            "233/233 - 43s - loss: 11.7543 - val_loss: 14.9505 - lr: 2.4367e-06 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.33e-06, weight decay: 1.17e-07\n",
            "Epoch 1455/1500\n",
            "Val unfiltered loss: 20.700864791870117\n",
            "233/233 - 44s - loss: 11.7223 - val_loss: 14.9613 - lr: 2.3342e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.23e-06, weight decay: 1.12e-07\n",
            "Epoch 1456/1500\n",
            "Val unfiltered loss: 20.69255256652832\n",
            "233/233 - 45s - loss: 11.7256 - val_loss: 14.9637 - lr: 2.2339e-06 - 45s/epoch - 194ms/step\n",
            "learning rate: 2.14e-06, weight decay: 1.07e-07\n",
            "Epoch 1457/1500\n",
            "Val unfiltered loss: 20.706336975097656\n",
            "233/233 - 44s - loss: 11.6827 - val_loss: 14.9878 - lr: 2.1358e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.04e-06, weight decay: 1.02e-07\n",
            "Epoch 1458/1500\n",
            "Val unfiltered loss: 20.686372756958008\n",
            "233/233 - 44s - loss: 11.6345 - val_loss: 14.9342 - lr: 2.0399e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.95e-06, weight decay: 9.73e-08\n",
            "Epoch 1459/1500\n",
            "Val unfiltered loss: 20.695714950561523\n",
            "233/233 - 44s - loss: 11.6897 - val_loss: 14.9720 - lr: 1.9461e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.85e-06, weight decay: 9.27e-08\n",
            "Epoch 1460/1500\n",
            "Val unfiltered loss: 20.715742111206055\n",
            "233/233 - 44s - loss: 11.7367 - val_loss: 14.9852 - lr: 1.8546e-06 - 44s/epoch - 187ms/step\n",
            "learning rate: 1.77e-06, weight decay: 8.83e-08\n",
            "Epoch 1461/1500\n",
            "Val unfiltered loss: 20.700803756713867\n",
            "233/233 - 44s - loss: 11.7189 - val_loss: 14.9831 - lr: 1.7653e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.68e-06, weight decay: 8.39e-08\n",
            "Epoch 1462/1500\n",
            "Val unfiltered loss: 20.694974899291992\n",
            "233/233 - 44s - loss: 11.6829 - val_loss: 14.9816 - lr: 1.6782e-06 - 44s/epoch - 189ms/step\n",
            "learning rate: 1.59e-06, weight decay: 7.97e-08\n",
            "Epoch 1463/1500\n",
            "Val unfiltered loss: 20.725358963012695\n",
            "233/233 - 45s - loss: 11.7345 - val_loss: 14.9859 - lr: 1.5933e-06 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.51e-06, weight decay: 7.55e-08\n",
            "Epoch 1464/1500\n",
            "Val unfiltered loss: 20.683408737182617\n",
            "233/233 - 44s - loss: 11.7256 - val_loss: 14.9609 - lr: 1.5106e-06 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.43e-06, weight decay: 7.15e-08\n",
            "Epoch 1465/1500\n",
            "Val unfiltered loss: 20.666099548339844\n",
            "233/233 - 45s - loss: 11.7016 - val_loss: 14.9620 - lr: 1.4301e-06 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.35e-06, weight decay: 6.76e-08\n",
            "Epoch 1466/1500\n",
            "Val unfiltered loss: 20.668540954589844\n",
            "233/233 - 44s - loss: 11.6900 - val_loss: 14.9466 - lr: 1.3518e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.28e-06, weight decay: 6.38e-08\n",
            "Epoch 1467/1500\n",
            "Val unfiltered loss: 20.70743751525879\n",
            "233/233 - 44s - loss: 11.6771 - val_loss: 14.9768 - lr: 1.2756e-06 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.20e-06, weight decay: 6.01e-08\n",
            "Epoch 1468/1500\n",
            "Val unfiltered loss: 20.719327926635742\n",
            "233/233 - 44s - loss: 11.7241 - val_loss: 15.0057 - lr: 1.2017e-06 - 44s/epoch - 190ms/step\n",
            "learning rate: 1.13e-06, weight decay: 5.65e-08\n",
            "Epoch 1469/1500\n",
            "Val unfiltered loss: 20.687685012817383\n",
            "233/233 - 45s - loss: 11.7541 - val_loss: 14.9930 - lr: 1.1300e-06 - 45s/epoch - 192ms/step\n",
            "learning rate: 1.06e-06, weight decay: 5.30e-08\n",
            "Epoch 1470/1500\n",
            "Val unfiltered loss: 20.6845760345459\n",
            "233/233 - 45s - loss: 11.6848 - val_loss: 14.9746 - lr: 1.0605e-06 - 45s/epoch - 192ms/step\n",
            "learning rate: 9.93e-07, weight decay: 4.97e-08\n",
            "Epoch 1471/1500\n",
            "Val unfiltered loss: 20.711894989013672\n",
            "233/233 - 44s - loss: 11.7002 - val_loss: 14.9870 - lr: 9.9324e-07 - 44s/epoch - 191ms/step\n",
            "learning rate: 9.28e-07, weight decay: 4.64e-08\n",
            "Epoch 1472/1500\n",
            "Val unfiltered loss: 20.67725944519043\n",
            "233/233 - 44s - loss: 11.6825 - val_loss: 15.0024 - lr: 9.2815e-07 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.65e-07, weight decay: 4.33e-08\n",
            "Epoch 1473/1500\n",
            "Val unfiltered loss: 20.698667526245117\n",
            "233/233 - 44s - loss: 11.6674 - val_loss: 14.9815 - lr: 8.6526e-07 - 44s/epoch - 189ms/step\n",
            "learning rate: 8.05e-07, weight decay: 4.02e-08\n",
            "Epoch 1474/1500\n",
            "Val unfiltered loss: 20.664365768432617\n",
            "233/233 - 44s - loss: 11.7342 - val_loss: 14.9757 - lr: 8.0458e-07 - 44s/epoch - 189ms/step\n",
            "learning rate: 7.46e-07, weight decay: 3.73e-08\n",
            "Epoch 1475/1500\n",
            "Val unfiltered loss: 20.692588806152344\n",
            "233/233 - 44s - loss: 11.6410 - val_loss: 14.9951 - lr: 7.4610e-07 - 44s/epoch - 189ms/step\n",
            "learning rate: 6.90e-07, weight decay: 3.45e-08\n",
            "Epoch 1476/1500\n",
            "Val unfiltered loss: 20.647157669067383\n",
            "233/233 - 44s - loss: 11.6552 - val_loss: 14.9595 - lr: 6.8982e-07 - 44s/epoch - 187ms/step\n",
            "learning rate: 6.36e-07, weight decay: 3.18e-08\n",
            "Epoch 1477/1500\n",
            "Val unfiltered loss: 20.66740608215332\n",
            "233/233 - 45s - loss: 11.7148 - val_loss: 14.9573 - lr: 6.3575e-07 - 45s/epoch - 195ms/step\n",
            "learning rate: 5.84e-07, weight decay: 2.92e-08\n",
            "Epoch 1478/1500\n",
            "Val unfiltered loss: 20.679277420043945\n",
            "233/233 - 44s - loss: 11.7369 - val_loss: 14.9888 - lr: 5.8389e-07 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.34e-07, weight decay: 2.67e-08\n",
            "Epoch 1479/1500\n",
            "Val unfiltered loss: 20.707801818847656\n",
            "233/233 - 44s - loss: 11.6536 - val_loss: 14.9787 - lr: 5.3423e-07 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.87e-07, weight decay: 2.43e-08\n",
            "Epoch 1480/1500\n",
            "Val unfiltered loss: 20.702896118164062\n",
            "233/233 - 44s - loss: 11.6466 - val_loss: 14.9957 - lr: 4.8677e-07 - 44s/epoch - 188ms/step\n",
            "learning rate: 4.42e-07, weight decay: 2.21e-08\n",
            "Epoch 1481/1500\n",
            "Val unfiltered loss: 20.693138122558594\n",
            "233/233 - 44s - loss: 11.6958 - val_loss: 14.9834 - lr: 4.4152e-07 - 44s/epoch - 191ms/step\n",
            "learning rate: 3.98e-07, weight decay: 1.99e-08\n",
            "Epoch 1482/1500\n",
            "Val unfiltered loss: 20.661914825439453\n",
            "233/233 - 44s - loss: 11.6708 - val_loss: 14.9503 - lr: 3.9848e-07 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.58e-07, weight decay: 1.79e-08\n",
            "Epoch 1483/1500\n",
            "Val unfiltered loss: 20.682680130004883\n",
            "233/233 - 44s - loss: 11.7200 - val_loss: 14.9429 - lr: 3.5764e-07 - 44s/epoch - 187ms/step\n",
            "learning rate: 3.19e-07, weight decay: 1.60e-08\n",
            "Epoch 1484/1500\n",
            "Val unfiltered loss: 20.726314544677734\n",
            "233/233 - 45s - loss: 11.6409 - val_loss: 14.9610 - lr: 3.1901e-07 - 45s/epoch - 195ms/step\n",
            "learning rate: 2.83e-07, weight decay: 1.41e-08\n",
            "Epoch 1485/1500\n",
            "Val unfiltered loss: 20.677000045776367\n",
            "233/233 - 44s - loss: 11.6726 - val_loss: 14.9743 - lr: 2.8259e-07 - 44s/epoch - 189ms/step\n",
            "learning rate: 2.48e-07, weight decay: 1.24e-08\n",
            "Epoch 1486/1500\n",
            "Val unfiltered loss: 20.689977645874023\n",
            "233/233 - 43s - loss: 11.7141 - val_loss: 14.9683 - lr: 2.4837e-07 - 43s/epoch - 186ms/step\n",
            "learning rate: 2.16e-07, weight decay: 1.08e-08\n",
            "Epoch 1487/1500\n",
            "Val unfiltered loss: 20.65049934387207\n",
            "233/233 - 44s - loss: 11.6851 - val_loss: 14.9821 - lr: 2.1636e-07 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.87e-07, weight decay: 9.33e-09\n",
            "Epoch 1488/1500\n",
            "Val unfiltered loss: 20.67985725402832\n",
            "233/233 - 44s - loss: 11.6431 - val_loss: 14.9809 - lr: 1.8656e-07 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.59e-07, weight decay: 7.95e-09\n",
            "Epoch 1489/1500\n",
            "Val unfiltered loss: 20.686939239501953\n",
            "233/233 - 44s - loss: 11.7051 - val_loss: 14.9577 - lr: 1.5896e-07 - 44s/epoch - 188ms/step\n",
            "learning rate: 1.34e-07, weight decay: 6.68e-09\n",
            "Epoch 1490/1500\n",
            "Val unfiltered loss: 20.683040618896484\n",
            "233/233 - 43s - loss: 11.6615 - val_loss: 14.9680 - lr: 1.3357e-07 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.10e-07, weight decay: 5.52e-09\n",
            "Epoch 1491/1500\n",
            "Val unfiltered loss: 20.67828941345215\n",
            "233/233 - 45s - loss: 11.6567 - val_loss: 14.9683 - lr: 1.1039e-07 - 45s/epoch - 195ms/step\n",
            "learning rate: 8.94e-08, weight decay: 4.47e-09\n",
            "Epoch 1492/1500\n",
            "Val unfiltered loss: 20.66523551940918\n",
            "233/233 - 44s - loss: 11.6915 - val_loss: 14.9568 - lr: 8.9419e-08 - 44s/epoch - 187ms/step\n",
            "learning rate: 7.07e-08, weight decay: 3.53e-09\n",
            "Epoch 1493/1500\n",
            "Val unfiltered loss: 20.67226791381836\n",
            "233/233 - 44s - loss: 11.6555 - val_loss: 14.9726 - lr: 7.0652e-08 - 44s/epoch - 188ms/step\n",
            "learning rate: 5.41e-08, weight decay: 2.70e-09\n",
            "Epoch 1494/1500\n",
            "Val unfiltered loss: 20.673080444335938\n",
            "233/233 - 44s - loss: 11.6500 - val_loss: 14.9702 - lr: 5.4094e-08 - 44s/epoch - 188ms/step\n",
            "learning rate: 3.97e-08, weight decay: 1.99e-09\n",
            "Epoch 1495/1500\n",
            "Val unfiltered loss: 20.711286544799805\n",
            "233/233 - 44s - loss: 11.6937 - val_loss: 14.9735 - lr: 3.9742e-08 - 44s/epoch - 188ms/step\n",
            "learning rate: 2.76e-08, weight decay: 1.38e-09\n",
            "Epoch 1496/1500\n",
            "Val unfiltered loss: 20.691448211669922\n",
            "233/233 - 43s - loss: 11.6758 - val_loss: 14.9637 - lr: 2.7599e-08 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.77e-08, weight decay: 8.83e-10\n",
            "Epoch 1497/1500\n",
            "Val unfiltered loss: 20.693872451782227\n",
            "233/233 - 44s - loss: 11.6496 - val_loss: 14.9587 - lr: 1.7663e-08 - 44s/epoch - 187ms/step\n",
            "learning rate: 9.94e-09, weight decay: 4.97e-10\n",
            "Epoch 1498/1500\n",
            "Val unfiltered loss: 20.703638076782227\n",
            "233/233 - 44s - loss: 11.6561 - val_loss: 14.9722 - lr: 9.9357e-09 - 44s/epoch - 190ms/step\n",
            "learning rate: 4.42e-09, weight decay: 2.21e-10\n",
            "Epoch 1499/1500\n",
            "Val unfiltered loss: 20.658662796020508\n",
            "233/233 - 43s - loss: 11.6920 - val_loss: 14.9653 - lr: 4.4159e-09 - 43s/epoch - 187ms/step\n",
            "learning rate: 1.10e-09, weight decay: 5.52e-11\n",
            "Epoch 1500/1500\n",
            "Val unfiltered loss: 20.72232437133789\n",
            "Val filtered lev distance: 0.8646276769925993\n",
            "Val unfiltered lev distance: 0.81725837872222\n",
            "Sub train lev distance: 0.9801637693217148\n",
            "233/233 - 116s - loss: 11.7124 - val_loss: 14.9913 - lr: 1.1040e-09 - 116s/epoch - 497ms/step\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS_to_fit = N_EPOCHS\n",
        "if DEBUG:\n",
        "  N_EPOCHS_to_fit = 3\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset_filtered,\n",
        "    epochs=N_EPOCHS_to_fit,\n",
        "    verbose = 2,\n",
        "    callbacks=[\n",
        "        save_model_callback(),\n",
        "        lr_callback,\n",
        "        WeightDecayCallback(),\n",
        "        val_lev_callback(),\n",
        "    ]\n",
        ")"
      ],
      "id": "3f6558e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IdGkYFjHyOH"
      },
      "outputs": [],
      "source": [
        "from contextlib import redirect_stdout\n",
        "\n",
        "with open(f'{save_folder}/modelsummary.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "id": "4IdGkYFjHyOH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljX1Kv1xH0iH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "861b2b37-fe89-4ead-9d40-a655b993b2f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79602acea140>]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "id": "ljX1Kv1xH0iH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWb1Fd-ZH2YH"
      },
      "outputs": [],
      "source": [
        "with open(f'{save_folder}/history.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        print(history.history)"
      ],
      "id": "uWb1Fd-ZH2YH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kjwCmqFcpEm"
      },
      "outputs": [],
      "source": [
        "with open(f'{save_folder}/lev_dist_val_filtered.txt', 'w') as f:\n",
        "  for item in lev_dist_val_filtered:\n",
        "    f.write(str(item)+\"\\n\")\n",
        "with open(f'{save_folder}/lev_dist_val_unfiltered.txt', 'w') as f:\n",
        "  for item in lev_dist_val_unfiltered:\n",
        "    f.write(str(item)+\"\\n\")\n",
        "with open(f'{save_folder}/lev_dist_sub_train.txt', 'w') as f:\n",
        "  for item in lev_dist_sub_train:\n",
        "    f.write(str(item)+\"\\n\")\n",
        "with open(f'{save_folder}/val_set_unfiltered_loss_list.txt', 'w') as f:\n",
        "  for item in val_set_unfiltered_loss_list:\n",
        "    f.write(str(item)+\"\\n\")"
      ],
      "id": "8kjwCmqFcpEm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XgZ3Om-flNC"
      },
      "outputs": [],
      "source": [
        "pickle.dump(lev_dist_val_filtered, open( f'{save_folder}/lev_dist_val_filtered.p', \"wb\" ) )\n",
        "pickle.dump(lev_dist_val_unfiltered, open( f'{save_folder}/lev_dist_val_unfiltered.p', \"wb\" ) )\n",
        "pickle.dump(lev_dist_sub_train, open( f'{save_folder}/lev_dist_sub_train.p', \"wb\" ) )\n",
        "pickle.dump(history.history, open( f'{save_folder}/history.p', \"wb\" ) )\n",
        "pickle.dump(val_set_unfiltered_loss_list, open( f'{save_folder}/val_set_unfiltered_loss_list.p', \"wb\" ) )"
      ],
      "id": "3XgZ3Om-flNC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6PxagQDdhHb"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "id": "j6PxagQDdhHb"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4846.417099,
      "end_time": "2023-08-14T17:07:53.504433",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-08-14T15:47:07.087334",
      "version": "2.4.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}